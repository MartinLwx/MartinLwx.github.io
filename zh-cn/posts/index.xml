<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>所有文章 - MartinLwx&#39;s Blog</title>
        <link>https://martinlwx.github.io/zh-cn/posts/</link>
        <description>所有文章 | MartinLwx&#39;s Blog</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>martinlwx@163.com (MartinLwx)</managingEditor>
            <webMaster>martinlwx@163.com (MartinLwx)</webMaster><copyright>&lt;a rel=&#34;license noopener&#34; href=&#34;https://creativecommons.org/licenses/by-nc-nd/4.0/&#34; target=&#34;_blank&#34;&gt;CC BY-NC-ND 4.0&lt;/a&gt;</copyright><lastBuildDate>Fri, 22 Mar 2024 12:13:53 &#43;0800</lastBuildDate><atom:link href="https://martinlwx.github.io/zh-cn/posts/" rel="self" type="application/rss+xml" /><item>
    <title>BPE 分词解密 - 实现方法与示例讲解</title>
    <link>https://martinlwx.github.io/zh-cn/the-bpe-tokenizer/</link>
    <pubDate>Thu, 24 Aug 2023 22:06:37 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/the-bpe-tokenizer/</guid>
    <description><![CDATA[BPE 简介在 NLP 里面，一个核心的问题是，如何对文本进行分词？从分类的角度上面来说，可以分为： Char level Word level Subword level 先看 Char level 分词，顾名思义，就是把文本拆分成一]]></description>
</item></channel>
</rss>
