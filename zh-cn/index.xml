<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>MartinLwx&#39;s Blog</title>
        <link>https://martinlwx.github.io/zh-cn/</link>
        <description>Welcome to my blog :)</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>martinlwx@163.com (MartinLwx)</managingEditor>
            <webMaster>martinlwx@163.com (MartinLwx)</webMaster><copyright>&lt;a rel=&#34;license noopener&#34; href=&#34;https://creativecommons.org/licenses/by-nc-nd/4.0/&#34; target=&#34;_blank&#34;&gt;CC BY-NC-ND 4.0&lt;/a&gt;</copyright><lastBuildDate>Sat, 07 Sep 2024 11:29:44 &#43;0800</lastBuildDate>
            <atom:link href="https://martinlwx.github.io/zh-cn/index.xml" rel="self" type="application/rss+xml" />
        <item>
    <title>Tree-sitter 以及它的 Query 功能</title>
    <link>https://martinlwx.github.io/zh-cn/tree-sitter-and-its-query/</link>
    <pubDate>Sat, 07 Sep 2024 11:29:44 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/tree-sitter-and-its-query/</guid>
    <description><![CDATA[<h2 id="引言" class="headerLink">
    <a href="#%e5%bc%95%e8%a8%80" class="header-mark" aria-label="Header mark for '引言'"></a>引言</h2><p>Tree-sitter 是一个 Parse Generator，也就是用来生成 Parser 的。除此之外，它还提供了一些额外的功能，比如今天要聊到的 Tree-sitter Query ，Query 提供了一套基于 S 表达式的 DSL（Domain Specific Language），可以查询 AST，获得你想要的信息，在正式学习如何使用 Query 前，我们先讲一些相关的背景知识，好让这个文章尽量是 Self-contained 的</p>]]></description>
</item><item>
    <title>@dataclass 简明教程（Python3.7）</title>
    <link>https://martinlwx.github.io/zh-cn/learn-to-use-dataclass-in-python/</link>
    <pubDate>Sat, 17 Aug 2024 12:30:43 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/learn-to-use-dataclass-in-python/</guid>
    <description><![CDATA[<h2 id="引言" class="headerLink">
    <a href="#%e5%bc%95%e8%a8%80" class="header-mark" aria-label="Header mark for '引言'"></a>引言</h2><p>Python 的 tuple 很好用，它可以让我们快速地将<em>不同类型</em>的值<em>封装</em>在一起，作为一个整体进行管理，自带的排序规则也十分直观，简单易用。但实际用下来我发现，一旦 tuple 的字段<em>比较多</em>，我就<em>被迫</em>要自己写一下注释注明一下<em>不同位置</em>的字段的具体含义是啥，比如</p>]]></description>
</item><item>
    <title>使用 GitHub Actions 自动化 Hugo 博客部署</title>
    <link>https://martinlwx.github.io/zh-cn/use-github-actions-to-automate-hugo-build/</link>
    <pubDate>Mon, 29 Jul 2024 23:35:53 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/use-github-actions-to-automate-hugo-build/</guid>
    <description><![CDATA[<h2 id="前言" class="headerLink">
    <a href="#%e5%89%8d%e8%a8%80" class="header-mark" aria-label="Header mark for '前言'"></a>前言</h2><p>最近在学习 GitHub Actions，GitHub Actions 是 GitHub 提供的一个特性，可以用来<em>自动化</em>执行一些步骤。在软件开发中，最常见的需要<em>自动化</em>的场景可能就是构建了。对于编译型的编程语言（比如 C/C++）编写的软件，通常需要编写对应的构建的脚本，软件构建的过程涉及到：环境准备、依赖下载、启动构建等。不过，利用 GitHub Actions 来<em>自动化</em>软件构建过程并不是本文的主题。在我思考我可以将 GitHub Actions 用于何处的时候，我想到了：利用 GitHub Actions 来自动化 Hugo 博客的部署。因为 Hugo 博客的部署也涉及到不少一系列固定的步骤 :)</p>]]></description>
</item><item>
    <title>尾调用与尾调用优化</title>
    <link>https://martinlwx.github.io/zh-cn/tail-call-and-tail-call-optimization/</link>
    <pubDate>Fri, 22 Mar 2024 12:13:53 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/tail-call-and-tail-call-optimization/</guid>
    <description><![CDATA[<h2 id="尾调用--尾递归" class="headerLink">
    <a href="#%e5%b0%be%e8%b0%83%e7%94%a8--%e5%b0%be%e9%80%92%e5%bd%92" class="header-mark" aria-label="Header mark for '尾调用 &amp; 尾递归'"></a>尾调用 &amp; 尾递归</h2><p>假设函数 <code>A</code> 调用了函数 <code>B</code>，我们称函数 <code>A</code> 为 <em>Caller</em>，函数 <code>B</code> 为 <em>Callee</em>。</p>]]></description>
</item><item>
    <title>学习使用 Vim&amp;Neovim 的 text-object</title>
    <link>https://martinlwx.github.io/zh-cn/learn-to-use-text-objects-in-vim/</link>
    <pubDate>Sun, 03 Mar 2024 19:46:48 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/learn-to-use-text-objects-in-vim/</guid>
    <description><![CDATA[<h2 id="引言" class="headerLink">
    <a href="#%e5%bc%95%e8%a8%80" class="header-mark" aria-label="Header mark for '引言'"></a>引言</h2><p>你可能不知道什么是 text-object，但我相信你<em>可能</em>已经在使用了只是你自己没有意识到。比如，在写代码的时候，我们经常想要修改函数调用的入参。比如我们在下面这段代码中，想要修改成 <code>bar(3, 2, 1)</code>，而你的光标停留在 <code>()</code> 里面</p>]]></description>
</item><item>
    <title>OCaml 的 Neovim 配置方案</title>
    <link>https://martinlwx.github.io/zh-cn/neovim-setup-for-ocaml/</link>
    <pubDate>Tue, 23 Jan 2024 00:03:55 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/neovim-setup-for-ocaml/</guid>
    <description><![CDATA[从零开始用 Neovim 配置 OCaml 的开发环境，包括 LSP、Formatter 等]]></description>
</item><item>
    <title>LLM 推理加速 - KV Cache</title>
    <link>https://martinlwx.github.io/zh-cn/llm-inference-optimization-kv-cache/</link>
    <pubDate>Thu, 12 Oct 2023 16:38:18 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/llm-inference-optimization-kv-cache/</guid>
    <description><![CDATA[<h2 id="背景" class="headerLink">
    <a href="#%e8%83%8c%e6%99%af" class="header-mark" aria-label="Header mark for '背景'"></a>背景</h2><p>LLM 用于推理的时候就是不断基于前面的所有 token 生成下一个 token</p>
<p><em>假设现在已经生成了 $t$ 个 token，用 $x_{1:t}$ 表示。在下一轮，LLM 会生成 $x_{1:t+1}$，注意他们的前 $t$ 个 token 是一样的</em></p>]]></description>
</item><item>
    <title>LoRA 微调</title>
    <link>https://martinlwx.github.io/zh-cn/lora-finetuning/</link>
    <pubDate>Thu, 14 Sep 2023 22:57:06 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/lora-finetuning/</guid>
    <description><![CDATA[<h2 id="什么是-lora" class="headerLink">
    <a href="#%e4%bb%80%e4%b9%88%e6%98%af-lora" class="header-mark" aria-label="Header mark for '什么是 LoRA'"></a>什么是 LoRA</h2><figure><img src="/img/lora.jpg">
</figure>

<p>自从 LLM 时代到来之后，如何微调 LLM 成为了一个难题，因为 LLM 的模型实在是太大了，很难做全量微调更新所有参数。可选的路线有：冻结整个模型做 Prompt tuning 或者 In-context Learning；冻结整个模型<em>但是</em>会插入可训练的模块。今天要介绍的 LoRA(<strong>Lo</strong>w-<strong>R</strong>ank <strong>A</strong>daptation) 就对应了后者的技术路线，这是微软团队的工作<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>]]></description>
</item><item>
    <title>下一个排列问题</title>
    <link>https://martinlwx.github.io/zh-cn/the-next-lexicographical-permutation-problem/</link>
    <pubDate>Wed, 06 Sep 2023 23:13:52 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/the-next-lexicographical-permutation-problem/</guid>
    <description><![CDATA[<h2 id="引言" class="headerLink">
    <a href="#%e5%bc%95%e8%a8%80" class="header-mark" aria-label="Header mark for '引言'"></a>引言</h2><p>有时候我们会想要生成一个序列的「下一个排列」或者是「上一个排列」，你会怎么做呢？如果你对 C++ 很熟悉的话，不难想到可以用 <code>next_permutation</code><sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> 和 <code>prev_permutation</code><sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>。但是 Python 并没有提供类似的 API。因此今天要探讨的就是如何用 Python 实现这 2 个 API，又因为「上一个排列」和「下一个排列」的方法其实大同小异，因此让我们聚焦其中的「下一个排列」问题</p>]]></description>
</item><item>
    <title>BPE 分词解密 - 实现方法与示例讲解</title>
    <link>https://martinlwx.github.io/zh-cn/the-bpe-tokenizer/</link>
    <pubDate>Thu, 24 Aug 2023 22:06:37 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/the-bpe-tokenizer/</guid>
    <description><![CDATA[<h2 id="bpe-简介" class="headerLink">
    <a href="#bpe-%e7%ae%80%e4%bb%8b" class="header-mark" aria-label="Header mark for 'BPE 简介'"></a>BPE 简介</h2><p>在 NLP 里面，一个核心的问题是，如何对文本进行分词？从分类的角度上面来说，可以分为：</p>]]></description>
</item></channel>
</rss>
