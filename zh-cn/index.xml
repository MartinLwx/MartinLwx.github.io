<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>MartinLwx&#39;s Blog</title>
        <link>https://martinlwx.github.io/zh-cn/</link>
        <description>Welcome to my blog :)</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><copyright>&lt;a rel=&#34;license noopener&#34; href=&#34;https://creativecommons.org/licenses/by-nc-nd/4.0/&#34; target=&#34;_blank&#34;&gt;CC BY-NC-ND 4.0&lt;/a&gt;</copyright><lastBuildDate>Sun, 20 Oct 2024 00:14:08 &#43;0800</lastBuildDate>
            <atom:link href="https://martinlwx.github.io/zh-cn/index.xml" rel="self" type="application/rss+xml" />
        <item>
    <title>为什么需要 Applicative Functor</title>
    <link>https://martinlwx.github.io/zh-cn/why-applicative-functor/</link>
    <pubDate>Sun, 20 Oct 2024 00:14:08 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/why-applicative-functor/</guid>
    <description><![CDATA[<div class="details admonition info open">
    <div class="details-summary admonition-title">
        <span class="icon"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z"/></svg></span>信息<span class="details-icon"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></span>
    </div>
    <div class="details-content">
        <div class="admonition-content">阅读本文之前，我假设你对 Functor 有很好的理解</div></div></div>
<h2 id="为啥需要-applicative-functor" class="headerLink">
    <a href="#%e4%b8%ba%e5%95%a5%e9%9c%80%e8%a6%81-applicative-functor" class="header-mark" aria-label="Header mark for '为啥需要 Applicative Functor'"></a>为啥需要 Applicative Functor</h2><p>在学习 Applicative Functor 之前，首先是一个关键的问题，为什么有了 Functor 我们还需要 Applicative Functor？</p>]]></description>
</item><item>
    <title>在 Neovim 里面使用 vim-fugitive 的工作流</title>
    <link>https://martinlwx.github.io/zh-cn/my-workflow-of-using-vim-fugitive-in-neovim/</link>
    <pubDate>Fri, 11 Oct 2024 00:16:14 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/my-workflow-of-using-vim-fugitive-in-neovim/</guid>
    <description><![CDATA[<h2 id="引言" class="headerLink">
    <a href="#%e5%bc%95%e8%a8%80" class="header-mark" aria-label="Header mark for '引言'"></a>引言</h2><p>最近在使用 Git + Neovim 的时候，发现我的工作流还是有一些不那么顺畅的地方。我习惯性<em>退出 Neovim</em>，然后在命令行写 Git 相关的命令，并且在提交代码变更前我习惯用 <a href="https://github.com/dandavison/delta" target="_blank" rel="noopener noreferrer">delta</a> 查看 diff 信息。为了减少要打的字符，我还开启了 <a href="https://github.com/ohmyzsh/ohmyzsh" target="_blank" rel="noopener noreferrer">Oh My Zsh</a> 的 <code>git</code> 插件，这样我就可以用一堆缩写了，比如 <code>ga = git add</code>、<code>gcmsg = git commit -m</code></p>]]></description>
</item><item>
    <title>Tree-sitter 以及它的 Query 功能</title>
    <link>https://martinlwx.github.io/zh-cn/tree-sitter-and-its-query/</link>
    <pubDate>Sat, 07 Sep 2024 11:29:44 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/tree-sitter-and-its-query/</guid>
    <description><![CDATA[<h2 id="引言" class="headerLink">
    <a href="#%e5%bc%95%e8%a8%80" class="header-mark" aria-label="Header mark for '引言'"></a>引言</h2><p>Tree-sitter 是一个 Parse Generator，也就是用来生成 Parser 的。除此之外，它还提供了一些额外的功能，比如今天要聊到的 Tree-sitter Query ，Query 提供了一套基于 S 表达式的 DSL（Domain Specific Language），可以查询 AST，获得你想要的信息，在正式学习如何使用 Query 前，我们先讲一些相关的背景知识，好让这个文章尽量是 Self-contained 的</p>]]></description>
</item><item>
    <title>@dataclass 简明教程（Python3.7）</title>
    <link>https://martinlwx.github.io/zh-cn/learn-to-use-dataclass-in-python/</link>
    <pubDate>Sat, 17 Aug 2024 12:30:43 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/learn-to-use-dataclass-in-python/</guid>
    <description><![CDATA[<h2 id="引言" class="headerLink">
    <a href="#%e5%bc%95%e8%a8%80" class="header-mark" aria-label="Header mark for '引言'"></a>引言</h2><p>Python 的 tuple 很好用，它可以让我们快速地将<em>不同类型</em>的值<em>封装</em>在一起，作为一个整体进行管理，自带的排序规则也十分直观，简单易用。但实际用下来我发现，一旦 tuple 的字段<em>比较多</em>，我就<em>被迫</em>要自己写一下注释注明一下<em>不同位置</em>的字段的具体含义是啥，比如</p>]]></description>
</item><item>
    <title>使用 GitHub Actions 自动化 Hugo 博客部署</title>
    <link>https://martinlwx.github.io/zh-cn/use-github-actions-to-automate-hugo-build/</link>
    <pubDate>Mon, 29 Jul 2024 23:35:53 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/use-github-actions-to-automate-hugo-build/</guid>
    <description><![CDATA[<h2 id="前言" class="headerLink">
    <a href="#%e5%89%8d%e8%a8%80" class="header-mark" aria-label="Header mark for '前言'"></a>前言</h2><p>最近在学习 GitHub Actions，GitHub Actions 是 GitHub 提供的一个特性，可以用来<em>自动化</em>执行一些步骤。在软件开发中，最常见的需要<em>自动化</em>的场景可能就是构建了。对于编译型的编程语言（比如 C/C++）编写的软件，通常需要编写对应的构建的脚本，软件构建的过程涉及到：环境准备、依赖下载、启动构建等。不过，利用 GitHub Actions 来<em>自动化</em>软件构建过程并不是本文的主题。在我思考我可以将 GitHub Actions 用于何处的时候，我想到了：利用 GitHub Actions 来自动化 Hugo 博客的部署。因为 Hugo 博客的部署也涉及到不少一系列固定的步骤 :)</p>]]></description>
</item><item>
    <title>尾调用与尾调用优化</title>
    <link>https://martinlwx.github.io/zh-cn/tail-call-and-tail-call-optimization/</link>
    <pubDate>Fri, 22 Mar 2024 12:13:53 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/tail-call-and-tail-call-optimization/</guid>
    <description><![CDATA[<h2 id="尾调用--尾递归" class="headerLink">
    <a href="#%e5%b0%be%e8%b0%83%e7%94%a8--%e5%b0%be%e9%80%92%e5%bd%92" class="header-mark" aria-label="Header mark for '尾调用 &amp; 尾递归'"></a>尾调用 &amp; 尾递归</h2><p>假设函数 <code>A</code> 调用了函数 <code>B</code>，我们称函数 <code>A</code> 为 <em>Caller</em>，函数 <code>B</code> 为 <em>Callee</em>。</p>
<p>尾调用（Tail-call）指的是：Caller <em>最后只需要</em>返回 Callee 这个函数调用的计算结果，其他运算<em>都</em>执行完成了<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>]]></description>
</item><item>
    <title>学习使用 Vim&amp;Neovim 的 text-object</title>
    <link>https://martinlwx.github.io/zh-cn/learn-to-use-text-objects-in-vim/</link>
    <pubDate>Sun, 03 Mar 2024 19:46:48 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/learn-to-use-text-objects-in-vim/</guid>
    <description><![CDATA[<h2 id="引言" class="headerLink">
    <a href="#%e5%bc%95%e8%a8%80" class="header-mark" aria-label="Header mark for '引言'"></a>引言</h2><p>你可能不知道什么是 text-object，但我相信你<em>可能</em>已经在使用了只是你自己没有意识到。比如，在写代码的时候，我们经常想要修改函数调用的入参。比如我们在下面这段代码中，想要修改成 <code>bar(3, 2, 1)</code>，而你的光标停留在 <code>()</code> 里面</p>]]></description>
</item><item>
    <title>OCaml 的 Neovim 配置方案</title>
    <link>https://martinlwx.github.io/zh-cn/neovim-setup-for-ocaml/</link>
    <pubDate>Tue, 23 Jan 2024 00:03:55 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/neovim-setup-for-ocaml/</guid>
    <description><![CDATA[<div class="details admonition info open">
    <div class="details-summary admonition-title">
        <span class="icon"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z"/></svg></span>信息<span class="details-icon"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></span>
    </div>
    <div class="details-content">
        <div class="admonition-content"><p><strong>更新说明</strong>:</p>]]></description>
</item><item>
    <title>LLM 推理加速 - KV Cache</title>
    <link>https://martinlwx.github.io/zh-cn/llm-inference-optimization-kv-cache/</link>
    <pubDate>Thu, 12 Oct 2023 16:38:18 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/llm-inference-optimization-kv-cache/</guid>
    <description><![CDATA[<h2 id="背景" class="headerLink">
    <a href="#%e8%83%8c%e6%99%af" class="header-mark" aria-label="Header mark for '背景'"></a>背景</h2><p>LLM 用于推理的时候就是不断基于前面的所有 token 生成下一个 token</p>
<p><em>假设现在已经生成了 $t$ 个 token，用 $x_{1:t}$ 表示。在下一轮，LLM 会生成 $x_{1:t+1}$，注意他们的前 $t$ 个 token 是一样的</em></p>]]></description>
</item><item>
    <title>LoRA 微调</title>
    <link>https://martinlwx.github.io/zh-cn/lora-finetuning/</link>
    <pubDate>Thu, 14 Sep 2023 22:57:06 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/zh-cn/lora-finetuning/</guid>
    <description><![CDATA[<h2 id="什么是-lora" class="headerLink">
    <a href="#%e4%bb%80%e4%b9%88%e6%98%af-lora" class="header-mark" aria-label="Header mark for '什么是 LoRA'"></a>什么是 LoRA</h2><figure><img src="/img/lora.jpg">
</figure>

<p>自从 LLM 时代到来之后，如何微调 LLM 成为了一个难题，因为 LLM 的模型实在是太大了，很难做全量微调更新所有参数。可选的路线有：冻结整个模型做 Prompt tuning 或者 In-context Learning；冻结整个模型<em>但是</em>会插入可训练的模块。今天要介绍的 LoRA(<strong>Lo</strong>w-<strong>R</strong>ank <strong>A</strong>daptation) 就对应了后者的技术路线，这是微软团队的工作<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>]]></description>
</item></channel>
</rss>
