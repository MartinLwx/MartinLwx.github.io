[{"categories":[],"content":"介绍了下一个排列问题的算法以及 Python 实现","date":"2023-09-06","objectID":"/zh-cn/the-next-lexicographical-permutation-problem/","tags":["Algorithm"],"title":"下一个排列问题","uri":"/zh-cn/the-next-lexicographical-permutation-problem/"},{"categories":[],"content":"引言 有时候我们会想要生成一个序列的「下一个排列」或者是「上一个排列」，你会怎么做呢？如果你对 C++ 很熟悉的话，不难想到可以用 next_permutation1 和 prev_permutation2。但是 Python 并没有提供类似的 API。因此今天要探讨的就是如何用 Python 实现这 2 个 API，又因为「上一个排列」和「下一个排列」的方法其实大同小异，因此让我们聚焦其中的「下一个排列」问题 ","date":"2023-09-06","objectID":"/zh-cn/the-next-lexicographical-permutation-problem/:1:0","tags":["Algorithm"],"title":"下一个排列问题","uri":"/zh-cn/the-next-lexicographical-permutation-problem/"},{"categories":[],"content":"算法流程 也许会让你感到意外的是，「下一个排列」问题在 14 世纪的时候就有人想出解决办法来了3，假设现在给定一个序列 a，下面是具体的算法步骤 找到最大的索引 k 使得 a[k] \u003c a[k + 1]，如果不存在这样的索引的话，那么说明当前的序列已经是最后一个排列了 找到最大的索引 l，l \u003e k 而且 a[k] \u003c a[l] 交换 a[k], a[l] 的值 翻转从 a[k + 1] 开始的部分 这样你就得到了「下一个排列」，但为什么这个算法是正确的？接下来我们逐步拆解一下这些步骤背后的原理 ","date":"2023-09-06","objectID":"/zh-cn/the-next-lexicographical-permutation-problem/:2:0","tags":["Algorithm"],"title":"下一个排列问题","uri":"/zh-cn/the-next-lexicographical-permutation-problem/"},{"categories":[],"content":"算法的理解 试问一个问题，在不知道这个算法之前，你会如何解决「下一个排列」问题？如果你对回溯算法很熟悉的话，应该不难想到我们可以干脆从第一个排列开始暴力枚举，逐个对比就容易定位到当前序列的下一个排列了。当然这个算法的复杂度太高，达到了 $O(N!)$。因此我们可以尝试优化一下，这就带来了第一个问题 Q1 - 用回溯算法生成当前序列的「下一个排列」的时候有什么特点？ 我们可以按顺序打出 [1, 2, 3, 4] 的所有排列并尝试找一下规律 [[1, 2, 3, 4], [1, 2, 4, 3], [1, 3, 2, 4], [1, 3, 4, 2], [1, 4, 2, 3], [1, 4, 3, 2], [2, 1, 3, 4], ... # omit [4, 3, 2, 1]] 就看其中一个例子好了，[1, 4, 3, 2] 为什么下一个排列是 [2, 1, 3, 4]？你能否发现什么规律？更确切地说，为什么第一位从 1 变成了 2？[1, 4, 3, 2] 这个序列有什么特点？可以看到末尾的 4, 3, 2 是最长非递增后缀的，那么这个规律适用任何情况吗？不妨再看另外一个例子，[1, 2, 4, 3] -\u003e [1, 3, 2, 4]，你会发现，同样的，我们仍然可以找到一个最长非递增后缀 [4, 3]，同时第二位的 2 变成了 3，把这些并排放在一起可能会更直观些： [1, 4, 3, 2] ^ # non-increasing suffix [2, 1, 3, 4] ^ # change this [1, 2, 4, 3] ^ # non-increasing suffix [1, 3, 2, 4] ^ # change this 所以结论似乎是——找到序列末尾的最长非递增后缀的开始位置 j，要生成下一个序列的话需要调大 j - 1 的位置的值。这恰恰是前面算法流程的第一步做的事情。如果从上面的观察导出这个结论无法说服你，那么可以从回溯的代码角度入手，什么时候会修改 j - 1 的值？答案是当我们已经枚举完 a[j:] 部分的所有排列的时候，那么这个时候 a[j:] 有什么特点？特点是，从 a[j:] 会是非递增的，因为我们回溯的时候是按照字典序从小到大枚举 indices: 0, 1, 2, ..., j - 1, j, ..., n - 1 # a[j - 1] \u003c a[j] A1 - 在生成下一个排列的时候，我们总是会调大末尾的最长非递增后缀的左边一个位置的元素 为了后续讨论方便，我们称前面找到的最长非递增后缀左边的位置为 pivot（也就是前面的 j - 1）。那么现在就引出了第二个问题 Q2 - a[pivot] 的值要怎么改变？ 因为要求解的是下一个排列，因此我们希望 a[pivot] 要增加，而且不要增加太多，应该增加“一点点”就好，那么什么是这个“一点点”？仍然从回溯的角度理解，我们会按照字典序从小到大枚举，因此 a[pivot] 应该要变成比它更大的下一个元素，那么这个下一个更大的元素去哪里找？答案是在 a[pivot + 1:] 里面找，换言之，我们要去 a[pivot + 1:] 里面找比 a[pivot] 大而且尽量小的元素 别忘了 a[pivot + 1:] 的特点：它是非递增的，因此我们可以从右到左检查 a[pivot + 1:] 这个部分的元素的值，找到第一个比 a[pivot] 大的，这又解释了前面算法的第二个步骤 A2 - 从右到左在 a[pivot + 1:] 里面找第一个值比 a[pivot] 大的索引（这个索引我们记作 r） 前面提到的算法还有最后两个步骤没有解释，这两个其实是互相关联的 Q3 - 为什么要交换 a[pivot] 和 a[r]，以及为什么随后要翻转 a[pivot + 1:]？ 理论上来说，我们修改了 a[pivot] 的值之后，a[pivot + 1:] 这个部分也需要修改，那么问题是如何修改？从回溯的角度来看，a[pivot + 1:] 应该从最小字典序开始枚举，这意味着 a[pivot + 1:] 应该是非递减的。有趣的是，交换 a[pivot] 和 a[r] 之后，a[pivot + 1:] 这个后缀仍然是非递增的，那么我们要把它变成非递减的只需要翻转一下这个部分就行，这就解释了前面算法的第三步和第四步 A3 - 交换 a[pivot] 和 a[r] 之后 a[pivot + 1:] 仍然是非递增，翻转操作把这个后缀变成了非递减 ","date":"2023-09-06","objectID":"/zh-cn/the-next-lexicographical-permutation-problem/:3:0","tags":["Algorithm"],"title":"下一个排列问题","uri":"/zh-cn/the-next-lexicographical-permutation-problem/"},{"categories":[],"content":"代码 Leetcode 有一道题目可以练习，推荐先按照自己的理解动手实现下再参考下面的代码 :) class Solution: def nextPermutation(self, nums: List[int]) -\u003e None: # Step 1. Find the rightmost i s.t. a[i] \u003e a[i - 1] # and set pivot to i - 1 pivot = -1 for i in reversed(range(len(nums))): if i - 1 \u003e= 0 and nums[i] \u003e nums[i - 1]: pivot = i - 1 break if pivot == -1: nums.reverse() return # Step 2. Find the rightmost value s.t. a[i] \u003e a[pivot] for i in reversed(range(len(nums))): if nums[i] \u003e nums[pivot]: nums[i], nums[pivot] = nums[pivot], nums[i] break # Step 3. Reverse the (pivot, len(nums)) part left, right = pivot + 1, len(nums) - 1 while left \u003c right: nums[left], nums[right] = nums[right], nums[left] left += 1 right -= 1 return None ","date":"2023-09-06","objectID":"/zh-cn/the-next-lexicographical-permutation-problem/:4:0","tags":["Algorithm"],"title":"下一个排列问题","uri":"/zh-cn/the-next-lexicographical-permutation-problem/"},{"categories":[],"content":"总结 从回溯的角度来理解「下一个排列」问题的算法就很自然了（起码对我来说），希望你也能有所收获 :) ","date":"2023-09-06","objectID":"/zh-cn/the-next-lexicographical-permutation-problem/:5:0","tags":["Algorithm"],"title":"下一个排列问题","uri":"/zh-cn/the-next-lexicographical-permutation-problem/"},{"categories":[],"content":"参考 std::next_permutation ↩︎ std::prev_permutation ↩︎ Permutation-Wiki ↩︎ ","date":"2023-09-06","objectID":"/zh-cn/the-next-lexicographical-permutation-problem/:6:0","tags":["Algorithm"],"title":"下一个排列问题","uri":"/zh-cn/the-next-lexicographical-permutation-problem/"},{"categories":["NLP"],"content":"介绍了 BPE 算法用来分词的原理","date":"2023-08-24","objectID":"/zh-cn/the-bpe-tokenizer/","tags":["NLP"],"title":"BPE 分词解密 - 实现方法与示例讲解","uri":"/zh-cn/the-bpe-tokenizer/"},{"categories":["NLP"],"content":"BPE 简介 在 NLP 里面，一个核心的问题是，如何对文本进行分词？从分类的角度上面来说，可以分为： Char level Word level Subword level 先看 Char level 分词，顾名思义，就是把文本拆分成一个个字符单独表示，比如 highest -\u003e h, i, g, h, e, s, t，一个显然的好处是，Vocab 不会太大，Vocab 的大小为字符集的大小，也不会遇到 Out-of-vocabulary(OOV) 的问题，但是字符本身并没有传达太多的语义，而且分词之后会有太多的 token，光是一个 highest 就可以得到 7 个 token，难以想象很长的文本分出来会有多少个😨 再看 Word level 分词，Word level 分词一般通过空格或者标点符号来把文本分成一个个单词，这样分词之后的 token 数量就不会太多，比如 Today is a good day -\u003e Today, is, a, good, day。但 Word level 分词也有问题，比如英文中的 high, higher, highest 这三个单词显然语义相似，因为另外两个只是比较级，但是 Word level 分词会把他们看成 3 个单独的单词 🤔️ 那么是否存在一种折中的办法，使得我们大概率不会遇到 OOV 的问题；分词得到的 token 数量又不能太多；而且分词能够考虑到复合词、时态变化、单复数呢？这就是 Subword level 做的事情，仍然是刚才的例子，根据英语的词根原理的话，我们可以把 higher 划分为 high, er，highest 划分为 highest，所以 Subword level 分词就是把一个单词用多个子词表示，今天要介绍的 BPE 就属于 Subword level 的一种 BPE 的全称是 Byte Pair Encoding，这里有个细节值得思考，什么是 Byte pair？ASCII 编码的话任何字符都是 1 byte，但如果是 utf-8 编码呢？一个字符不一定是 1 byte，它可以是 3 bytes 也可以是 4 bytes，🤔️ 那如果 BPE 用在 utf-8 的文本里面，byte pair 又是什么东西？所以我感觉这里是有点歧义性的，因此更好的理解方式也许是，byte pair 其实是 char pair，这里的 char 是 utf-8 的 char ","date":"2023-08-24","objectID":"/zh-cn/the-bpe-tokenizer/:1:0","tags":["NLP"],"title":"BPE 分词解密 - 实现方法与示例讲解","uri":"/zh-cn/the-bpe-tokenizer/"},{"categories":["NLP"],"content":"BPE 训练流程 然后开始正式介绍 BPE 算法的训练流程，假设我们手头有一堆文档 $D$ 把每个文档 $d$ 变成一个个单词，比如你可以简单用空格分词就好 统计每个单词 $w$ 在所有文档中的出现频率，并得到初始的字符集 alphabet 作为一开始的 Vocab（包括后面的 \u003c/w\u003e） 先将每个单词划分为一个个 utf-8 char，称为一个划分，比如 highest -\u003e h, i, g, h, e, s, t 然后，在每个单词的划分最后面加上 \u003c/w\u003e，那么现在 highest -\u003e h, i, g, h, e, s, t, \u003c/w\u003e 重复下面步骤直到满足两个条件中的任意一个：1）Vocab 达到上限。2）达到最大迭代次数 找到最经常一起出现的 pair，并记录这个合并规则放在 merge table 里面，同时把合并之后的结果放到 Vocab 里面 更新所有单词的划分，假设我们发现 (h, i) 最经常一起出现，那么 highest -\u003e hi, g, h, e, s, t, \u003c/w\u003e 你可能会有下面 3 个疑惑： 为什么要统计词频？因为统计词频会让找最经常出现的 pair 更简单 为什么要加 \u003c/w\u003e？因为我们希望能够还原输入，因此需要做个标记表示这是单词之间的边界 如果多个 pair 的词频一样怎么处理？这个不同实现可能不一样，但在我看来应该关系不大 💡 由此你可以发现，BPE 算法合并最经常一起出现的 pair 的时候，并不会跨越单词 ","date":"2023-08-24","objectID":"/zh-cn/the-bpe-tokenizer/:1:1","tags":["NLP"],"title":"BPE 分词解密 - 实现方法与示例讲解","uri":"/zh-cn/the-bpe-tokenizer/"},{"categories":["NLP"],"content":"BPE 应用流程 在 BPE 完成训练之后，我们会得到一个 merge table，也会得到一个 Vocab，假设现在要处理文本 s 和训练的时候采用一样的方法，先把 s 拆分成一个个单词，每个单词拆分为一个个 utf-8 char 遍历 merge table，并检查每个合并规则是否可以用来更新每个单词的划分，可以的话就合并更新 💡 这里有个细节，我们提取的 merge rule 其实是按照出现的频率降序，那么我们按顺序遍历 merge table 就已经隐含了「优先合并最经常出现的 pair」这件事了，注意体会 ","date":"2023-08-24","objectID":"/zh-cn/the-bpe-tokenizer/:1:2","tags":["NLP"],"title":"BPE 分词解密 - 实现方法与示例讲解","uri":"/zh-cn/the-bpe-tokenizer/"},{"categories":["NLP"],"content":"BPE 例子 停留在算法不提供例子的话，经常还是会云里雾里，所以现在来结合一个例子看 BPE 是如何工作的 比如语料库是 corpus = [\"highest\", \"higher\", \"lower\", \"lowest\", \"cooler\", \"coolest\"] 这里跳过统计词频，因为每一个都是 1。先把每个单词变成一个个 utf-8 字符然后加上 \u003c/w\u003e { \"highest\": [\"h\", \"i\", \"g\", \"h\", \"e\", \"s\", \"t\", \"\u003c/w\u003e\"], \"higher\": [\"h\", \"i\", \"g\", \"h\", \"e\", \"r\", \"\u003c/w\u003e\"], \"lower\": [\"l\", \"o\", \"w\", \"e\", \"r\", \"\u003c/w\u003e\"], \"lowest\": [\"l\", \"o\", \"w\", \"e\", \"s\", \"t\", \"\u003c/w\u003e\"], \"cooler\": [\"c\", \"o\", \"o\", \"l\", \"e\", \"r\", \"\u003c/w\u003e\"], \"collest\": [\"c\", \"o\", \"o\", \"l\", \"e\", \"s\", \"t\", \"\u003c/w\u003e\"], } 可以看到 (e, s) 总共出现了 3 次，是最多次的，然后根据这个重新划分。注意这里 (e, r) 其实也有一样的出现频率，所以选 (e, r) 合并也是可以的 { \"highest\": [\"h\", \"i\", \"g\", \"h\", \"es\", \"t\", \"\u003c/w\u003e\"], \"higher\": [\"h\", \"i\", \"g\", \"h\", \"e\", \"r\", \"\u003c/w\u003e\"], \"lower\": [\"l\", \"o\", \"w\", \"e\", \"r\", \"\u003c/w\u003e\"], \"lowest\": [\"l\", \"o\", \"w\", \"es\", \"t\", \"\u003c/w\u003e\"], \"cooler\": [\"c\", \"o\", \"o\", \"l\", \"e\", \"r\", \"\u003c/w\u003e\"], \"collest\": [\"c\", \"o\", \"o\", \"l\", \"es\", \"t\", \"\u003c/w\u003e\"], } 接下来发现最多的是 (es, t)，更新划分 { \"highest\": [\"h\", \"i\", \"g\", \"h\", \"est\", \"\u003c/w\u003e\"], \"higher\": [\"h\", \"i\", \"g\", \"h\", \"e\", \"r\", \"\u003c/w\u003e\"], \"lower\": [\"l\", \"o\", \"w\", \"e\", \"r\", \"\u003c/w\u003e\"], \"lowest\": [\"l\", \"o\", \"w\", \"est\", \"\u003c/w\u003e\"], \"cooler\": [\"c\", \"o\", \"o\", \"l\", \"e\", \"r\", \"\u003c/w\u003e\"], \"collest\": [\"c\", \"o\", \"o\", \"l\", \"est\", \"\u003c/w\u003e\"], } 接下来发现最多的是 (est, \u003c/w\u003e)，更新划分 { \"highest\": [\"h\", \"i\", \"g\", \"h\", \"est\u003c/w\u003e\"], \"higher\": [\"h\", \"i\", \"g\", \"h\", \"e\", \"r\", \"\u003c/w\u003e\"], \"lower\": [\"l\", \"o\", \"w\", \"e\", \"r\", \"\u003c/w\u003e\"], \"lowest\": [\"l\", \"o\", \"w\", \"est\u003c/w\u003e\"], \"cooler\": [\"c\", \"o\", \"o\", \"l\", \"e\", \"r\", \"\u003c/w\u003e\"], \"collest\": [\"c\", \"o\", \"o\", \"l\", \"est\u003c/w\u003e\"], } 接下来发现最多的是 (e, r)，更新划分 { \"highest\": [\"h\", \"i\", \"g\", \"h\", \"est\u003c/w\u003e\"], \"higher\": [\"h\", \"i\", \"g\", \"h\", \"er\", \"\u003c/w\u003e\"], \"lower\": [\"l\", \"o\", \"w\", \"er\", \"\u003c/w\u003e\"], \"lowest\": [\"l\", \"o\", \"w\", \"est\u003c/w\u003e\"], \"cooler\": [\"c\", \"o\", \"o\", \"l\", \"er\", \"\u003c/w\u003e\"], \"collest\": [\"c\", \"o\", \"o\", \"l\", \"est\u003c/w\u003e\"], } 接下来发现最多的是 (er, \u003c/w\u003e)，更新划分 { \"highest\": [\"h\", \"i\", \"g\", \"h\", \"est\u003c/w\u003e\"], \"higher\": [\"h\", \"i\", \"g\", \"h\", \"er\u003c/w\u003e\"], \"lower\": [\"l\", \"o\", \"w\", \"er\u003c/w\u003e\"], \"lowest\": [\"l\", \"o\", \"w\", \"est\u003c/w\u003e\"], \"cooler\": [\"c\", \"o\", \"o\", \"l\", \"er\u003c/w\u003e\"], \"collest\": [\"c\", \"o\", \"o\", \"l\", \"est\u003c/w\u003e\"], } 后面还可以继续迭代更新，这里就不展开了，相信上面的例子已经够清楚了。而且到这一步，我们已经得到了 er, est 这两个有意义的后缀 ","date":"2023-08-24","objectID":"/zh-cn/the-bpe-tokenizer/:1:3","tags":["NLP"],"title":"BPE 分词解密 - 实现方法与示例讲解","uri":"/zh-cn/the-bpe-tokenizer/"},{"categories":["NLP"],"content":"BPE 的 Huggingface 实现 Huggingface 提供的 API 还挺简单的，*可以注意到 CharBPETokenizer 的 Char，也证明了前面我说的 from tokenizers import CharBPETokenizer # Instantiate tokenizer tokenizer = CharBPETokenizer() tokenizer.train_from_iterator( corpus, vocab_size=17, min_frequency=2, ) ","date":"2023-08-24","objectID":"/zh-cn/the-bpe-tokenizer/:1:4","tags":["NLP"],"title":"BPE 分词解密 - 实现方法与示例讲解","uri":"/zh-cn/the-bpe-tokenizer/"},{"categories":["NLP"],"content":"手动实现 BPE 最好理解一个算法的办法永远都是尝试自己实现一个。我这里按照前面描述的算法流程实现了一个 BPE 类，如果初始化的时候设置 debug=False 就可以看到整个 BPE 是如何更新的 首先来看构造函数和用来训练的 train 方法 from collections import defaultdict, Counter from pprint import pprint class BPE: def __init__( self, corpus: list[str], vocab_size: int, max_iter: int | None = None, debug: bool = False, ): self.corpus = corpus self.vocab_size = vocab_size self.vocab = [] self.word_freq = Counter() self.splits = {} # e.g. highest: [high, est\u003c/w\u003e] self.merges = {} # e.g. [high, est\u003c/w\u003e]: highest self.max_iter = max_iter self.debug = debug def train(self): \"\"\"Train a BPE Tokenizer\"\"\" # count the word frequency for document in self.corpus: # split each document in corpus by whitespace words = document.split() self.word_freq += Counter(words) # initialize the self.splits for word in self.word_freq: self.splits[word] = list(word) + [\"\u003c/w\u003e\"] if self.debug: print(f\"Init splits: {self.splits}\") alphabet = set() for word in self.word_freq: alphabet |= set(list(word)) alphabet.add(\"\u003c/w\u003e\") self.vocab = list(alphabet) self.vocab.sort() cnt = 0 while len(self.vocab) \u003c self.vocab_size: if self.max_iter and cnt \u003e= self.max_iter: break # find the most frequent pair pair_freq = self.get_pairs_freq() if len(pair_freq) == 0: print(\"No pair available\") break pair = max(pair_freq, key=pair_freq.get) self.update_splits(pair[0], pair[1]) if self.debug: print(f\"Updated splits: {self.splits}\") self.merges[pair] = pair[0] + pair[1] self.vocab.append(pair[0] + pair[1]) if self.debug: print( f\"Most frequent pair({max(pair_freq.values())} times) \" f\"is : {pair[0]}, {pair[1]}. Vocab size: {len(self.vocab)}\" ) cnt += 1 流程还是挺清晰的，核心的几个函数实现如下 ... def update_splits(self, lhs: str, rhs: str): \"\"\"If we see lhs and rhs appear consecutively, we merge them\"\"\" for word, word_split in self.splits.items(): new_split = [] cursor = 0 while cursor \u003c len(word_split): if ( word_split[cursor] == lhs and cursor + 1 \u003c len(word_split) and word_split[cursor + 1] == rhs ): new_split.append(lhs + rhs) cursor += 2 else: new_split.append(word_split[cursor]) cursor += 1 self.splits[word] = new_split # if word_split != new_split: # print(f\"old: {word_split}\") # print(f\"new: {new_split}\") def get_pairs_freq(self) -\u003e dict: \"\"\"Compute the pair frequency\"\"\" pairs_freq = defaultdict(int) for word, freq in self.word_freq.items(): split = self.splits[word] for i in range(len(split)): if i + 1 \u003c len(split): pairs_freq[(split[i], split[i + 1])] += freq return pairs_freq 最后我们就可以写一个 tokenize 函数 ... def tokenize(self, s: str) -\u003e list[str]: splits = [list(t) + [\"\u003c/w\u003e\"] for t in s.split()] for lhs, rhs in self.merges: for idx, split in enumerate(splits): new_split = [] cursor = 0 while cursor \u003c len(split): if ( cursor + 1 \u003c len(split) and split[cursor] == lhs and split[cursor + 1] == rhs ): new_split.append(lhs + rhs) cursor += 2 else: new_split.append(split[cursor]) cursor += 1 assert \"\".join(new_split) == \"\".join(split) splits[idx] = new_split return sum(splits, []) 尝试用自己写的 BPE 对刚才的 corpus 进行分词 bpe = BPE(corpus, vocab_size=17, debug=False) bpe.train() bpe.tokenize(\" \". join(corpus)) 输出是： ['h', 'i', 'g', 'h', 'est\u003c/w\u003e', 'h', 'i', 'g', 'h', 'er\u003c/w\u003e', 'l', 'o', 'w', 'er\u003c/w\u003e', 'l', 'o', 'w', 'est\u003c/w\u003e', 'c', 'o', 'o', 'l', 'er\u003c/w\u003e', 'c', 'o', 'o', 'l', 'est\u003c/w\u003e'] 🤔️ 说明代码写对了，而且多亏了 \u003c/w\u003e，我们可以很清楚看到单词之间的边界，也可以还原出本来的输入 ","date":"2023-08-24","objectID":"/zh-cn/the-bpe-tokenizer/:1:5","tags":["NLP"],"title":"BPE 分词解密 - 实现方法与示例讲解","uri":"/zh-cn/the-bpe-tokenizer/"},{"categories":["NLP"],"content":"总结 BPE 算法简单而且很好用，但是当深入到实现的时候，你发现会有不少细节问题，但正是因为接触到这些细节才使得对 BPE 的理解更加深刻 这里可以讨论一下 BPE 的局限性，那就是你会发现把文档变成一个个单词我们这里用的是空格划分，但是像中文的话，空格并不是单词之间的边界，这就会让事情变得比较棘手了起来 ","date":"2023-08-24","objectID":"/zh-cn/the-bpe-tokenizer/:1:6","tags":["NLP"],"title":"BPE 分词解密 - 实现方法与示例讲解","uri":"/zh-cn/the-bpe-tokenizer/"},{"categories":["NLP"],"content":"介绍了 NLP 中的 TF-IDF 模型","date":"2023-08-16","objectID":"/zh-cn/an-introduction-of-tf-idf-model/","tags":["NLP","Machine-Learning"],"title":"TF-IDF 模型","uri":"/zh-cn/an-introduction-of-tf-idf-model/"},{"categories":["NLP"],"content":"什么是 TF-IDF 模型 在之前的文章中谈到了词袋模型，也讲到了它的许多不足，在今天的这篇文章中，我们要尝试解决词袋模型的缺点之一：每个词的重要性是一样的 💡 那么，核心问题就是————如何定义「单词的重要性」这个概念？ 一个想法是：一个单词在一个文档里面出现得越频繁，则这个单词对于这个文档来说越重要。比如一篇讨论狗的文章，大概率文章里面会出现很多「狗」，即词频高的单词反映了文档的主题 但如果这个词在语料库的所有文档中都出现得很频繁呢？比如「的」，在每个文档中，它的词频应该都不低，那能说这个单词更重要吗？显然是不行的，「的」更多是服务于语法结构而没包含太多的语义信息。于是我们有了另外一个线索：如果一个单词在每个文档中的词频都很高，那么这个单词的重要性应该就没那么重要 因此一个合理的解决方案应该考虑单词在「单个文档」的词频，但也应该考虑它在「多个文档」的词频，TF-IDF 就兼顾了这两点 概括来说，TF-IDF 的“直觉”理解就是————相似的文档用的词也许是差不多的，而不同的单词的重要性应该是不一样的 ","date":"2023-08-16","objectID":"/zh-cn/an-introduction-of-tf-idf-model/:1:0","tags":["NLP","Machine-Learning"],"title":"TF-IDF 模型","uri":"/zh-cn/an-introduction-of-tf-idf-model/"},{"categories":["NLP"],"content":"TF-IDF 模型细节 TF-IDF 由 2 个部分组成：词频（Term frequency，TF） + 逆文档频率（Inverse document frequency，IDF），先说 TF 再说 IDF ","date":"2023-08-16","objectID":"/zh-cn/an-introduction-of-tf-idf-model/:2:0","tags":["NLP","Machine-Learning"],"title":"TF-IDF 模型","uri":"/zh-cn/an-introduction-of-tf-idf-model/"},{"categories":["NLP"],"content":"TF 所谓 TF，可以看成是关于文档 $d$ 和单词 $w$ 的函数 $\\text{TF}(w, d)$，计算公式如下： $$\\text{TF}(w, d)=\\frac{\\text{frequency of}\\ w\\ \\text{in}\\ d}{\\text{word counts of } d}$$ 也就是统计文档 $d$ 的单词 $w$ 的词频，然后除以对应文档 $d$ 的总的单词数量即可 🐛 在 Scikit-Learn 框架中，TF 的计算不大一样，它并没有除文档的总的单词数量。其实除以文档的总的单词数量是为了让一个文档 $d$ 的所有单词的 $\\text{TF}(w, d)$ 加起来为一，起到一个归一化的作用。Scikit-Learn 是在 TF-IDF 计算完成之后才做归一化的。后面我们会用一个例子证明这点 ","date":"2023-08-16","objectID":"/zh-cn/an-introduction-of-tf-idf-model/:2:1","tags":["NLP","Machine-Learning"],"title":"TF-IDF 模型","uri":"/zh-cn/an-introduction-of-tf-idf-model/"},{"categories":["NLP"],"content":"IDF 在写下 IDF 的具体公式之前，别忘了我们的目的————降低每个文档都出现的常见词的重要性。所以 IDF 是一个关于单词 $w$ 和语料库 $corpus$ 的函数 $$ \\text{IDF}(w, corpus)=log\\ \\frac{\\text{document count of }corpus}{1+\\text{count of document which contains }w} $$ 注意分母位置的 1 避免了除 0 的情况 🤔️ corpus 一般是固定下来不变的，可以看成一个常量而不是自变量，那么就可以把 IDF 看成是只跟单词 $w$ 有关系 💡 注意一个问题，这里的 $log$ 是 $log_2$ 还是 $log_{10}$ 还是 $ln$ ？不同的框架的实现可能会有差异，Scikit-Learn 用的是自然对数 $ln$ 🐛 在 Scikit-Learn 框架中，IDF 的计算跟上面的公式并不一样，默认情况下 Scikit-Learn 的 IDF 是这样的1 $$ \\text{IDF}(w, corpus)=log\\ \\frac{1 + \\text{document count of }corpus}{1+\\text{count of document which contains }w} + 1 $$ 🤔️ 我个人理解的话就是，Scikit-Learn 做的改动使得 $\\text{IDF}(t)$ 不可能小于 1，而本来的公式如果一个单词 $w$ 在每个文档都出现了的话，$\\text{IDF}(w)$ 算出来会是负的，因此 Scikit-Learn 的改动感觉更实用了，不同单词的 IDF 比较起来就很直观 ","date":"2023-08-16","objectID":"/zh-cn/an-introduction-of-tf-idf-model/:2:2","tags":["NLP","Machine-Learning"],"title":"TF-IDF 模型","uri":"/zh-cn/an-introduction-of-tf-idf-model/"},{"categories":["NLP"],"content":"TF-IDF 把 TF 和 IDF 相乘，就得到了最后的 TF-IDF 表达式： $$ \\text{TF-IDF}(w, d, corpus)=\\text{TF}(w, d) * \\text{IDF}(d, corpus) $$ ","date":"2023-08-16","objectID":"/zh-cn/an-introduction-of-tf-idf-model/:2:3","tags":["NLP","Machine-Learning"],"title":"TF-IDF 模型","uri":"/zh-cn/an-introduction-of-tf-idf-model/"},{"categories":["NLP"],"content":"Scikit-Learn 的 TF-IDF 虽然 TF-IDF 实现起来很简单，但是实际用的时候，你多半还是不会自己实现 TF-IDF，而是直接用成熟的 Scikit-Learn 提供的 API。这里我们来研究一下 Scikit-Learn 怎么计算 TF-IDF。我们继续沿用 Scikit-Learn 的官方例子 toy_corpus = [ 'This is the first document.', 'This is the second second document.', 'And the third one.', 'Is this the first document?', ] tokenized_toy_corpus = [ ['this', 'is', 'the', 'first', 'document'], ['this', 'is', 'the', 'second', 'second', 'document'], ['and', 'the', 'third', 'one'], ['is', 'this', 'the', 'first', 'document'] ] 让我们先来看看 Scikit-Learn 里面如何计算 TF-IDF from sklearn.feature_extraction.text import TfidfVectorizer # set norm=None for comparison vectorizer = TfidfVectorizer(norm=None) X = vectorizer.fit_transform(toy_corpus) 通过 X.toarray() 就可以拿到 TF-IDF 矩阵，如下所示（注意我关闭了归一化，所以一个文档内的不同单词的 TF-IDF 值加起来不为 1） and document first is one second the third this document1 0.0 1.22314 1.51082 1.22314 0.0 0.0 1.0 0.0 1.22314 document2 0.0 1.22314 0.0 1.22314 0.0 3.83258 1.0 0.0 1.22314 document3 1.91629 0.0 0.0 0.0 1.91629 0.0 1.0 1.91629 0.0 document4 0.0 1.22314 1.51082 1.22314 0.0 0.0 1.0 0.0 1.22314 下面则是之前词袋模型的输出 and document first is one second the third this document1 0 1 1 1 0 0 1 0 1 document2 0 1 0 1 0 2 1 0 1 document3 1 0 0 0 1 0 1 1 0 document4 0 1 1 1 0 0 1 0 1 🤔️ 对比一下两者你会发现，现在 document1 文档里面 document，first 这两个单词的重要性不一样了：document 的 TF-IDF 是 1.22314，而 first 的 TF-IDF 是 1.51082，因为语料库中包含他们的文档数量并不相同。而词袋模型认识不到这点，认为两者都是 1 通过 vectorizer 的 idf_ 属性我们就能够拿到 Scikit-Learn 计算出来的每个单词的 IDF print(vectorizer.idf_) # [1.91629073 1.22314355 1.51082562 1.22314355 1.91629073 # 1.91629073 1. 1.91629073 1.22314355] 🤔️ 此时你要是把这个 IDF 向量乘以词袋模型输出的矩阵（注意向量会被广播），你就得到了 Scikit-Learn 算出来的 TF-IDF 矩阵，这验证了前面我们说的： Scikit-Learn 直接用词袋模型的输出当成 TF Scikit-Learn 的 IDF 计算跟标准的不一样 ","date":"2023-08-16","objectID":"/zh-cn/an-introduction-of-tf-idf-model/:3:0","tags":["NLP","Machine-Learning"],"title":"TF-IDF 模型","uri":"/zh-cn/an-introduction-of-tf-idf-model/"},{"categories":["NLP"],"content":"手动实现 TF-IDF 手动实现也并不复杂，下面假设语料库或者是文档都是分词好的，采用和 Scikit-Learn 一样的 TF-IDF 计算方式 🐛 注意下面的代码未经优化，只是为了演示 import math def TF(word: str, tokenized_document: list[str]) -\u003e float: return tokenized_document.count(word) def IDF(word: str, tokenized_corpus: list[list[str]]) -\u003e float: doc_count_contains_word = 0 for doc in tokenized_corpus: if word in doc: doc_count_contains_word += 1 return math.log((1 + len(tokenized_corpus)) / (1 + doc_count_contains_word)) + 1 def TF_IDF( word: str, tokenized_document: list[str], tokenized_corpus: list[list[str]] ) -\u003e float: return TF(word, tokenized_document) * IDF(word, tokenized_corpus) ","date":"2023-08-16","objectID":"/zh-cn/an-introduction-of-tf-idf-model/:4:0","tags":["NLP","Machine-Learning"],"title":"TF-IDF 模型","uri":"/zh-cn/an-introduction-of-tf-idf-model/"},{"categories":["NLP"],"content":"总结 在这篇文章中，我们研究了 TF-IDF 如何对词袋模型做出了改进：额外考虑一个单词在所有文档中的词频来调整它的重要性。通过分析官方的例子，我们也验证了确实单词的重要性现在是不一样的了，这是对词袋模型一个不错的改进 从实现的角度来说，TF-IDF 的计算只需要遍历语料库一次即可，在遍历的过程中额外维护几个变量：每个单词出现在了多少个文档里面；处理的文档数量等，Gensim 的 Dictionary 类就是这么设计的，感兴趣的话可以看下源代码 ","date":"2023-08-16","objectID":"/zh-cn/an-introduction-of-tf-idf-model/:5:0","tags":["NLP","Machine-Learning"],"title":"TF-IDF 模型","uri":"/zh-cn/an-introduction-of-tf-idf-model/"},{"categories":["NLP"],"content":"参考 TF-IDF term weighting ↩︎ ","date":"2023-08-16","objectID":"/zh-cn/an-introduction-of-tf-idf-model/:6:0","tags":["NLP","Machine-Learning"],"title":"TF-IDF 模型","uri":"/zh-cn/an-introduction-of-tf-idf-model/"},{"categories":["NLP"],"content":"词袋模型简介","date":"2023-08-11","objectID":"/zh-cn/an-introduction-of-bag-of-word-model/","tags":["NLP","Machine-Learning","AI4SE"],"title":"词袋模型","uri":"/zh-cn/an-introduction-of-bag-of-word-model/"},{"categories":["NLP"],"content":"什么是词袋模型 在 NLP 中，我们需要将文档（document）表示为向量，这是因为机器学习只能够处理数字。也就是说，我们要找到下面这么一个神奇的函数： $$ f(\\text{document}) = vector $$ 今天要讨论的是词袋模型（bag-of-word, BoW），词袋模型可以让我们把输入的文档转变成一个向量表示 💡 尽管词袋模型在 2023 年已经过时了，我仍然鼓励你学习词袋模型，并且思考下面几个重要问题： Motivation 是什么？ 优缺点是什么？ 如何把它变得更好？ ","date":"2023-08-11","objectID":"/zh-cn/an-introduction-of-bag-of-word-model/:1:0","tags":["NLP","Machine-Learning","AI4SE"],"title":"词袋模型","uri":"/zh-cn/an-introduction-of-bag-of-word-model/"},{"categories":["NLP"],"content":"词袋模型的 motivation 和直观理解 在了解词袋模型细节之前，我想先给你一个词袋模型可能是有用的直觉 —— 相似的文档用的词也许是差不多的 你可能持反对意见，并且可以给出许多反例。我承认，这也是为什么我们需要更加强大的模型 :) ","date":"2023-08-11","objectID":"/zh-cn/an-introduction-of-bag-of-word-model/:1:1","tags":["NLP","Machine-Learning","AI4SE"],"title":"词袋模型","uri":"/zh-cn/an-introduction-of-bag-of-word-model/"},{"categories":["NLP"],"content":"词袋模型细节 构造一个词袋模型只需要做两件事情 创建词汇表（Vocab），每个单词都在词汇表里面有一个独特的 ID（一般从 0 开始）。注意词袋模型输出的向量的长度等于词汇表的大小 遍历语料库中的每个文档，把这个文档新出现的单词添加到词汇表里面 在构造好词袋模型之后，就可以把任何文档都转变成向量表示了。方法也很简单，只要统计文档中每个单词出现的次数。值得一提的是，对于文档中不在词汇表里面的单词，一般直接就忽略不计 让我们来结合一个简单例子理解1 toy_corpus = [ 'This is the first document.', 'This is the second second document.', 'And the third one.', 'Is this the first document?', ] 删除标点符号，然后用空格分词，同时把所有的单词变成小写，预处理之后，我们就可以得到 tokenized_toy_corpus = [ ['this', 'is', 'the', 'first', 'document'], ['this', 'is', 'the', 'second', 'second', 'document'], ['and', 'the', 'third', 'one'], ['is', 'this', 'the', 'first', 'document'] ] 为了简单，我们这里考虑把所有文档的所有单词都包括在词汇表里面 flatten_list_as_set = set(sum(tokenized_toy_corpus, start=[])) print(f\"the toy vocab size: {len(flatten_list_as_set)}\") the toy vocab size: 9 💡 一个用 sum 函数摊平 list 的小技巧 :D 然后，让我们给词汇表里面的每个单词一个独特的 ID toy_token2id = {} for token in sorted(flatten_list_as_set): toy_token2id[token] = len(toy_token2id) print(toy_token2id) { 'and': 0, 'document': 1, 'first': 2, 'is': 3, 'one': 4, 'second': 5, 'the': 6, 'third': 7, 'this': 8 } 可以看到，词汇表的大小是 9，那么我们也就知道，每个文档可以用一个长度为 9 的向量表示 让我们手动计算一下每个文档的词袋模型向量来检查我们是否理解正确 BoW_matrix = [] for document in tokenized_toy_corpus: temp = [0] * 9 for token in document: temp[toy_token2id[token]] += 1 BoW_matrix.append(temp) print(BoW_matrix) [ [0, 1, 1, 1, 0, 0, 1, 0, 1], [0, 1, 0, 1, 0, 2, 1, 0, 1], [1, 0, 0, 0, 1, 0, 1, 1, 0], [0, 1, 1, 1, 0, 0, 1, 0, 1] ] 直接看数字的话不是很直观，可以多增加一行一列，就能把单词和词频对应上了。如果你检查答案1的话，你会发现和我们算出来的一模一样 and document first is one second the third this document1 0 1 1 1 0 0 1 0 1 document2 0 1 0 1 0 2 1 0 1 document3 1 0 0 0 1 0 1 1 0 document4 0 1 1 1 0 0 1 0 1 如何解读这个表格？ 每一行就是对应文档的词袋模型输出的向量表示，以 document2 为例，它包含了下面这些单词 document * 1 is * 1 second * 2 the * 1 this * 1 之前提到，分词之后的 document2 是 ['this', 'is', 'the', 'second', 'second', 'document']，显然和这个向量表示是对应的 现在你就知道如何解读这个了矩阵了 :D 🧐 你也许注意到了，这个矩阵中有很多 0。BoW 的矩阵确实是这样的，是一个稀疏矩阵，这也是它的缺点之一 from sklearn.metrics.pairwise import cosine_similarity 我们可以用向量内积计算 2 个向量之间的相似度 之前的 tokenized_toy_corpus 如下 tokenized_toy_corpus = [ ['this', 'is', 'the', 'first', 'document'], ['this', 'is', 'the', 'second', 'second', 'document'], ['and', 'the', 'third', 'one'], ['is', 'this', 'the', 'first', 'document'] ] 现在，假设查询（query）是最后一个文档 —— ['is', 'this', 'the', 'first', 'document']，前 3 个文档中哪一个跟它最像？ 我们可以一眼看出答案是第一个，那么机器能否也发现这点？ print( cosine_similarity([BoW_matrix[3]], [BoW_matrix[0]]), cosine_similarity([BoW_matrix[3]], [BoW_matrix[1]]), cosine_similarity([BoW_matrix[3]], [BoW_matrix[2]]), ) [[1.]] [[0.63245553]] [[0.2236068]] 🤔️ 机器也看出来了 ","date":"2023-08-11","objectID":"/zh-cn/an-introduction-of-bag-of-word-model/:1:2","tags":["NLP","Machine-Learning","AI4SE"],"title":"词袋模型","uri":"/zh-cn/an-introduction-of-bag-of-word-model/"},{"categories":["NLP"],"content":"更复杂的真实数据集 前面的例子太简单了，下面我会用一个更复杂的真实数据集 —— CodeSearchNet。它包含了许多编程语言的函数，这里我挑 Python 来展示 当然你也可以选择你感兴趣的编程语言 :) from datasets import load_dataset from gensim import corpora def process_data(partition: str) -\u003e list[str]: \"\"\" Get data from the datasets library from huggingface. Only keep the `whole_func_string` column Arg --- `partition`: train/validation/test Return ----- return a list of python functions \"\"\" raw_datasets = load_dataset(\"code_search_net\", \"python\") return raw_datasets[partition][\"whole_func_string\"] 取决于你的网络这可能得花上一点时间，压缩文件大小是 941MB # use the test dataset to speed up the process corpus = process_data(\"test\") 来看一下数据中的一个例子 print(corpus[0]) def get_vid_from_url(url): \"\"\"Extracts video ID from URL. \"\"\" return match1(url, r'youtu\\.be/([^?/]+)') or \\ match1(url, r'youtube\\.com/embed/([^/?]+)') or \\ match1(url, r'youtube\\.com/v/([^/?]+)') or \\ match1(url, r'youtube\\.com/watch/([^/?]+)') or \\ parse_query_param(url, 'v') or \\ parse_query_param(parse_query_param(url, 'u'), 'v') 在前面的英文分词中，我们删除了标点符号，用空格分词。代码的分词则比较不一样，编程语言有自己对应的语法（上下文无关文法），那么就可以用词法分析器拿到一个个 token。我这里用 Python 自带的 tokenize 简单实现了一下 下面的函数如果看不懂也没关系，可以直接跳过。用词法分析器分词只是为了得到更精确的分词结果 :) import ast from io import BytesIO import tokenize def get_token_stream(code: str) -\u003e list[str]: \"\"\" Tokenize the source code and return a token stream Note that the following token type will be removed: - COMMENT - NEWLINE - NL - INDENT - DEDENT - ENCODING - STRING \"\"\" # see https://docs.python.org/3/library/token.html useless_token_type = { tokenize.COMMENT, tokenize.NEWLINE, tokenize.NL, # non-terminating newline tokenize.INDENT, tokenize.DEDENT, tokenize.ENCODING, tokenize.STRING, } parse_tree = ast.parse(code) origin_tokens = tokenize.tokenize(BytesIO(code.encode(\"utf-8\")).readline) token_as_strlist = [ token.string for token in origin_tokens if token.type not in useless_token_type ] return token_as_strlist 注意两件事情： 我删除了所有的字符串，包括文档、f-string、普通字符串和注释等 我没有把变量名或者函数名根据 camelCase 或者 snake_case 这两种命名惯例进一步分词 首先，先用 get_token_stream 把数据中的 Python 代码都分词一下。注意数据中包含了 Python2 和 Python3，这里直接丢弃了 Python2 的代码 from tqdm.auto import tqdm py2_cnt, py3_cnt = 0, 0 new_corpus = [] codes = [] for code in tqdm(corpus): try: codes.append(get_token_stream(code)) new_corpus.append(code) py3_cnt += 1 except SyntaxError: py2_cnt += 1 print(f\"Python2: {py2_cnt}, Python3: {py3_cnt}\") corpus = new_corpus 让我们验证一下 get_token_stream 是否分词分对了 print(codes[0]) [ 'def', 'get_vid_from_url', '(', 'url', ')', ':', 'return', 'match1', '(', 'url', ',', ')', 'or', 'match1', '(', 'url', ',', ')', 'or', 'match1', '(', 'url', ',', ')', 'or', 'match1', '(', 'url', ',', ')', 'or', 'parse_query_param', '(', 'url', ',', ')', 'or', 'parse_query_param', '(', 'parse_query_param', '(', 'url', ',', ')', ',', ')', '' ] 现在，可以利用 Gensim 提供的 API 来创建词汇表 from gensim import corpora dictionary = corpora.Dictionary(codes) print(dictionary) Dictionary\u003c77242 unique tokens: ['', '(', ')', ',', ':']...\u003e 可以看到，词汇表太大了，让我们看看能否优化一下 一般来说，我们不会关心只出现一次的 token，因此，我们可以把他们删除掉 once_ids = [ token_id for token_id, doc_freq in dictionary.dfs.items() if doc_freq == 1 ] dictionary.filter_tokens(once_ids) dictionary.compactify() print(dictionary) Dictionary\u003c31933 unique tokens: ['', '(', ')', ',', ':']...\u003e 现在只剩下 31933 tokens 了，这已经好多了，我猜测 token 这么多的原因是有很多变量/函数名都不一样 🧐 Dictionary 提供了 most_common 方法可以找到词频最多的 token，让我们看下能否发现一些有意思的事情 dictionary.most_common(25) [ ('.', 202834), ('(', 199868), (')', 199868), (',', 162853), ('=', 142808), (':', 110829), ('self', 71699), ('[', 55736), (']', 55736), ('if', 40272), ('return', 24021), ('def', 23557), ('', 21948), ('None', 19797), ('in', 19437), ('for', 13509), ('1', 13345), ('0', 13213), ('not', 11826), ('else', 10634), ('+', 10617), ('==', 9323), ('name', 8290), ('is', 7601), ('-', 7544) ] 🧐 发现了一个有意思的现象，( 和 ) 的词频一样，[ 和 ] 也是的，因为代码的语法就是这么规定的 然后用 doc2bow API 就可以得到每个文档（代码）的词袋模型向量 BoW_matrix_for_code = [dictionary.doc2bow(d) for d in codes] print(BoW_matrix_for_code[0]) [ (0, 1), (1, 8), (2, 8), (3, 7), (4, 1), (5, 1), (6, 1), (7, 4), (8, 5), (9, 3), (","date":"2023-08-11","objectID":"/zh-cn/an-introduction-of-bag-of-word-model/:2:0","tags":["NLP","Machine-Learning","AI4SE"],"title":"词袋模型","uri":"/zh-cn/an-introduction-of-bag-of-word-model/"},{"categories":["NLP"],"content":"总结 现在，我们来总结一下 BoW 的一些缺点。你可能已经自己弄清楚了其中一些： 单词之间的顺序信息没有得到保留。The cat chased the dog 和 The dog chased the cat 意思完全不一样 没有语义信息。 词袋模型将每个单词视为一个独立的实体 词袋模型输出的向量是高维稀疏向量。 计算量很大，向量长度取决于你的词汇表大小 每个词都有相同的重要性。 但有些词可能提供更多信息 无法处理不在词汇表里面的单词。 如果文档包含很多不在词汇表中的单词要怎么办？ … 词袋模型有很多缺点，你可能只会在教程里面看到它。鉴于这些限制，后面人们又开发了 Word2Vec、GloVe 和基于 Transformer 的架构（例如 BERT、GPT）等更先进的模型来克服这些缺点 ","date":"2023-08-11","objectID":"/zh-cn/an-introduction-of-bag-of-word-model/:3:0","tags":["NLP","Machine-Learning","AI4SE"],"title":"词袋模型","uri":"/zh-cn/an-introduction-of-bag-of-word-model/"},{"categories":["NLP"],"content":"参考 CountVectorizer ↩︎ ↩︎ ","date":"2023-08-11","objectID":"/zh-cn/an-introduction-of-bag-of-word-model/:4:0","tags":["NLP","Machine-Learning","AI4SE"],"title":"词袋模型","uri":"/zh-cn/an-introduction-of-bag-of-word-model/"},{"categories":["ML-DL"],"content":"介绍了如何用维度分析技巧快速求解梯度","date":"2023-07-26","objectID":"/zh-cn/a-trick-to-calculating-partial-derivatives-in-ml/","tags":["Deep-Learning","Machine-Learning"],"title":"机器学习求解梯度的小技巧","uri":"/zh-cn/a-trick-to-calculating-partial-derivatives-in-ml/"},{"categories":["ML-DL"],"content":"引言 也许你和我一样在求解机器学习的梯度时有各种困难，即使看着相关的 Cookbook 一边推导依然是有困惑，今天我要分享的是最近学习到的一个实用技巧：在机器学习中，求解偏导数的时候可以先全部看成标量处理，最后让维度匹配即可 免责声明：运用如上的技巧并不保证梯度是正确的，可能维度是对的，但是梯度是错的，强调一下为了确保梯度计算正确请做好梯度检查 ","date":"2023-07-26","objectID":"/zh-cn/a-trick-to-calculating-partial-derivatives-in-ml/:1:0","tags":["Deep-Learning","Machine-Learning"],"title":"机器学习求解梯度的小技巧","uri":"/zh-cn/a-trick-to-calculating-partial-derivatives-in-ml/"},{"categories":["ML-DL"],"content":"应用 💡 大写的黑色粗体字母表示矩阵，不加粗的字母都是标量 ","date":"2023-07-26","objectID":"/zh-cn/a-trick-to-calculating-partial-derivatives-in-ml/:2:0","tags":["Deep-Learning","Machine-Learning"],"title":"机器学习求解梯度的小技巧","uri":"/zh-cn/a-trick-to-calculating-partial-derivatives-in-ml/"},{"categories":["ML-DL"],"content":"反向传播矩阵形式推导 在之前的 反向传播推导 过程中，我从标量角度来推导了反向传播，因为这个比较好理解，但如果你尝试实现反向传播或者是前向传播，你会发现都是用矩阵形式，我们总是把它变成矩阵乘法，因为矩阵乘法会快很多。因此需要弄清楚「反向传播的矩阵形式」是如何进行的，下面我将利用前面提到的技巧来进行推导 为了公式简洁，下面省略了 bias 只考虑 weight 考虑一个简单的 $L$ 层的 MLP 模型，用 $\\mathbf Z^l$ 表示 $l$ 层的输出，特别的，将输入层也用 $\\mathbf Z$ 表示，有 $$\\mathbf Z^0=\\mathbf X$$ 其中 $\\mathbf X\\in\\mathcal{R}^{m\\times d}$，$m$ 为样本数量，$d$ 为每个样本的特征长度 模型 $f_\\theta$ 的输出是 $$f_\\theta(\\mathbf X)=\\mathbf Z^{L}$$ 其中 $\\theta$ 表示模型的可学习参数 相邻两层之间的关系是 $$\\mathbf Z^{l+1}=\\sigma_{l+1}(\\mathbf Z^l\\mathbf W^{l+1}),l=0,…,L-1$$ 其中 $\\sigma_{l+1}$ 为 $l+1$ 层的激活函数 维度信息如下: $$\\mathbf Z^l\\in\\mathcal{R}^{m\\times n_l}$$ $$\\mathbf W^{l+1} \\in \\mathcal R^{n_l\\times n_{l+1}}$$ 其中 $n_l$ 用于表示 $l$ 层的神经元个数 我们想要确定损失 $J$ 对模型任意可学习参数的梯度（标量对矩阵求导），这样才能用梯度下降算法更新可学习参数，考虑我们要求解 $\\mathbf W^l$ 的梯度 $$ \\frac{\\partial J}{\\partial \\mathbf W^l}=\\frac{\\partial J}{\\partial\\mathbf Z^{L}}\\cdot \\frac{\\partial \\mathbf Z^{L}}{\\partial\\mathbf Z^{L-1}}\\cdot …\\cdot \\frac{\\partial \\mathbf Z^{l+1}}{\\partial\\mathbf Z^{l}}\\cdot\\frac{\\partial \\mathbf Z^{l}}{\\partial\\mathbf W^l} $$ 🤔️ 那如果求解的是关于 $\\mathbf W^{l+1}$ 的梯度呢？ $$ \\frac{\\partial J}{\\partial \\mathbf W^{l-1}}=\\frac{\\partial J}{\\partial\\mathbf Z^{L}}\\cdot \\frac{\\partial \\mathbf Z^{L}}{\\partial\\mathbf Z^{L-1}}\\cdot …\\cdot \\frac{\\partial \\mathbf Z^{l+1}}{\\partial\\mathbf Z^{l}} \\cdot \\frac{\\partial \\mathbf Z^{l}}{\\partial\\mathbf Z^{l-1}}\\cdot\\frac{\\partial \\mathbf Z^{l-1}}{\\partial\\mathbf W^{l-1}} $$ 你会发现，不同参数的梯度公式存在大量共同的部分，因此我们可以引入额外一个记号 $\\mathbf G^l$，表示损失对 $\\mathbf Z^l$ 的梯度 $$\\mathbf G^{l}=\\frac{\\partial J}{\\partial \\mathbf Z^{l}}$$ 下面我们就可以推导 $\\mathbf G^l$ 和 $\\mathbf G^{l+1}$ 的关系 $$ \\begin{equation} \\begin{aligned} \\mathbf G^{l} \u0026=\\frac{\\partial J}{\\partial \\mathbf Z^{l+1}}\\cdot\\frac{\\partial \\mathbf Z^{l+1}}{\\partial \\mathbf Z^l} \\\\\\ \u0026=\\mathbf G^{l+1}\\cdot \\frac{\\partial \\mathbf Z^{l+1}}{\\partial \\mathbf Z^l} \\\\\\ \u0026=\\mathbf G^{l+1}\\cdot \\frac{\\partial \\sigma_{l+1}(\\mathbf Z^{l}\\mathbf W^{l+1})}{\\partial \\mathbf Z^{l}\\mathbf W^{l+1}}\\cdot\\frac{\\partial \\mathbf Z^{l}\\mathbf W^{l+1}}{\\partial \\mathbf Z^l} \\\\\\ \u0026=\\mathbf G^{l+1}\\cdot \\sigma’(\\mathbf Z^{l}\\mathbf W^{l+1})\\cdot \\mathbf W^{l+1}\\ (cheat) \\end{aligned} \\end{equation} $$ 在上面的最后一行，我们用把矩阵当成标量处理直接求导，然后根据前面说的，接下来让维度匹配就可以，先来看上面的每个部分的维度 $$\\mathbf G^{l+1}\\in\\mathcal{R}^{m\\times n_{l+1}}$$ $$\\sigma_{l+1}’(\\mathbf Z^{l}\\mathbf W^{l+1})\\in\\mathcal{R}^{m\\times n_{l+1}}$$ $$ \\mathbf W^{l+1}\\in\\mathcal{R}^{n_l\\times n_{l+1}} $$ 我们想要得到大小为 $m\\times n_1$ 的矩阵，因为 $$\\mathbf G^l\\in\\mathcal{R}^{m\\times n_l}$$ 所以可以这么凑 $$\\mathbf G^{l}=\\Big (\\mathbf G^{l+1}\\odot\\sigma_{l+1}’(\\mathbf Z^{l}\\mathbf W^{l+1})\\Big )(\\mathbf{W}^{l+1})^T=\\Big (\\mathbf G^{l+1}\\odot\\sigma_{l+1}’(\\mathbf Z^{l+1})\\Big )(\\mathbf{W}^{l+1})^T$$ 现在回到我们本来要做的事情——求解关于 $\\mathbf W^l$ 的梯度： $$\\frac{\\partial J}{\\partial \\mathbf W^l}=\\mathbf G^{l}\\cdot\\frac{\\partial \\mathbf Z^l}{\\mathbf W^l}$$ 让我们来展开上面的公式 $$ \\begin{equation} \\begin{aligned} \\frac{\\partial J}{\\partial \\mathbf W^l}\u0026=\\mathbf G^{l}\\cdot\\frac{\\partial \\mathbf Z^l}{\\mathbf W^l} \\\\\\ \u0026= \\mathbf G^{l}\\cdot\\frac{\\partial \\mathbf \\sigma_{l+1}(\\mathbf Z^{l-1}\\mathbf W^l)}{\\partial \\mathbf Z^{l-1}\\mathbf W^l}\\cdot \\frac{\\partial \\mathbf Z^{l-1}\\mathbf W^l}{\\partial\\mathbf W^l} \\\\\\ \u0026= \\mathbf G^{l}\\cdot\\mathbf \\sigma_{l+1}’(\\mathbf Z^{l-1}\\mathbf W^l)\\cdot \\mathbf Z^{l-1}(cheat) \\end{aligned} \\end{equation} $$ 我们想要得到和 $\\mathbf W^l$ 一样大小的矩阵：$(n_l, n_{l+1})$，整理一下上面的不同部分 $$ \\frac{\\partial J}{\\partial \\mathbf W^l}=(\\mathbf Z^{l-1})^T\\Big(\\mathbf G^{l}\\odot\\mathbf \\sigma_{l+1}’(\\mathbf Z^{l-1}\\mathbf W^l) \\Big )\\ =(\\mathbf Z^{l-1})^T\\Big(\\mathbf G^{l}\\odot\\mathbf \\sigma_{l+1}’(\\mathbf Z^l) \\Big )\\ $$ 利用 $\\mathbf G^l$ 和 $\\mathbf G^{l+1}$ 的关系，我们可以从 $\\mathbf G^{l+1}$ 推导出 $\\mathbf G^l$，然后也可以进一步计算 $\\mathbf W^l$ 的梯度，也就是从后往前计算，这也就是反向传播的含义 🤔️ 注意 $\\mathbf G^l$ 的计算和 $\\frac{\\partial J}{\\partial \\mathbf W^l}$ 用到了 $\\mathbf Z^{l-1}, \\mathbf Z^{l}, \\mathbf Z^{l+1}$，也就是不同层的激活函数的输出，这意味着在反向传播的时候我们需要缓存前向传播的值，缓存意味着需要消耗内存，所以这就是为啥模型越大，GPU 就需要更多的显存 ","date":"2023-07-26","objectID":"/zh-cn/a-trick-to-calculating-partial-derivatives-in-ml/:2:1","tags":["Deep-Learning","Machine-Learning"],"title":"机器学习求解梯度的小技巧","uri":"/zh-cn/a-trick-to-calculating-partial-derivatives-in-ml/"},{"categories":["ML-DL"],"content":"线性回归矩阵形式梯度推导 之前在 线性回归 里面我们需要求解下面这个公式 $$ \\begin{aligned} \\frac{\\partial}{\\partial \\theta}\\ J(w,b) \u0026= \\frac{\\partial}{\\partial \\theta}\\ \\frac{1}{2m}(\\mathbf X\\theta - \\vec{y})^T(\\mathbf X\\theta - \\vec{y}) \\\\\\ \\end{aligned} $$ 利用维度分析的技巧，可以这么推导 $$ \\begin{equation} \\begin{aligned} \\frac{\\partial}{\\partial \\theta}\\ J(w,b) \u0026= \\frac{\\partial}{\\partial \\theta}\\ \\frac{1}{2m}(\\mathbf X\\theta - \\vec{y})^T(\\mathbf X\\theta - \\vec{y}) \\\\\\ \u0026= \\frac{1}{2m}\\frac{\\partial(\\ \\mathbf X\\theta - \\vec{y})^T(\\mathbf X\\theta - \\vec{y}) }{\\partial \\mathbf X\\theta-\\vec y}\\cdot \\frac{\\partial \\mathbf X\\theta-\\vec y}{\\partial \\theta}\\\\\\ \u0026= \\frac{1}{2m}\\cdot2(\\mathbf X\\theta-\\vec y)\\cdot\\mathbf X\\ (cheat) \\end{aligned} \\end{equation} $$ 考虑维度信息 $$\\mathbf X\\theta-\\vec y\\in\\mathcal{R}^{m\\times 1}$$ $$\\mathbf X\\in\\mathcal{R}^{m\\times(n+1)}$$ 我们想要得到的是跟 $\\theta$ 一样维度大小的： $$\\theta\\in\\mathcal{R}^{(n+1)\\times 1}$$ 因此直接凑出来就好： $$\\frac{1}{m}\\mathbf X^T(\\mathbf X\\theta-\\vec y)$$ ","date":"2023-07-26","objectID":"/zh-cn/a-trick-to-calculating-partial-derivatives-in-ml/:2:2","tags":["Deep-Learning","Machine-Learning"],"title":"机器学习求解梯度的小技巧","uri":"/zh-cn/a-trick-to-calculating-partial-derivatives-in-ml/"},{"categories":["ML-DL"],"content":"总结 尽管这是一个不严格的技巧，像是作弊一样😨，但我发现还蛮实用的✌️，学会这个技巧之后，机器学习里面的公式推导会轻松很多，当然别忘了利用梯度检查确保式子是正确的 :) ","date":"2023-07-26","objectID":"/zh-cn/a-trick-to-calculating-partial-derivatives-in-ml/:3:0","tags":["Deep-Learning","Machine-Learning"],"title":"机器学习求解梯度的小技巧","uri":"/zh-cn/a-trick-to-calculating-partial-derivatives-in-ml/"},{"categories":["ML-DL","Internal"],"content":"介绍了 Pytorch 的张量的 strides 格式原理","date":"2023-07-14","objectID":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/","tags":["Internal","Pytorch","Deep-Learning"],"title":"Pytorch 张量的 strides 格式是什么","uri":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/"},{"categories":["ML-DL","Internal"],"content":"引言 尽管我已经使用 Numpy 和 Pytorch 好长一段时间了，但我一直不知道他们是如何实现底层的张量（tensor），而且这么高效。最近在看 Deep Learning Systems 这门课，终于有机会尝试自己实现张量，实现一遍之后对张量的理解更深刻了🧐 作为 Pytorch 的使用者有必要理解底层的张量存储原理吗？我觉得是有必要的，大多数情况下理解底层原理都能让你更好理解上层的东西，比如理解张量的存储原理之后有助于你会回答下面这几个问题 广播操作涉及到数组的拷贝吗？ Pytorch 的 contiguous 中是干什么的？为什么需要这个函数？ ","date":"2023-07-14","objectID":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/:1:0","tags":["Internal","Pytorch","Deep-Learning"],"title":"Pytorch 张量的 strides 格式是什么","uri":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/"},{"categories":["ML-DL","Internal"],"content":"按行存储与按列存储 让我们从简单的二维数组出发，二维数组在内存中占据连续的位置，但是要按行存储还是按列存储这点可能不相同 比如现在有下面这个 $2\\times 3$ 的二维数组 A [[0.2949, 0.9608, 0.0965], [0.5463, 0.4176, 0.8146]] 如果是按行存储，那么内存中的排列（这里记为 A_in_row）是： [0.2949, 0.9608, 0.0965, 0.5463, 0.4176, 0.8146] 按行存储的时候，要访问 (i, j) 位置的值的公式是 A[i][j] = A_in_row[i * A.shape[1] + j] 如果是按列存储，那么内存中的排列（这里记为 A_in_col）是： [0.2949, 0.5463, 0.9608, 0.4176, 0.0965, 0.8146] 按列存储的时候，要访问 (i, j) 位置的值的公式是 A[i][j] = A_in_col[j * A.shape[0] + i] ","date":"2023-07-14","objectID":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/:2:0","tags":["Internal","Pytorch","Deep-Learning"],"title":"Pytorch 张量的 strides 格式是什么","uri":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/"},{"categories":["ML-DL","Internal"],"content":"Strides 格式 张量在底层可以是按行存储也可以是按列存储。Numpy 和 Pytorch 都采用了按行存储的方式，任何维度的张量在底层存储都占据着内存中连续的空间，那么问题来了，我们如何访问到我们想要的位置的数据？ 答案就是 strides 格式。strides 格式可以看成是前面两种索引格式的泛化版本，假设现在有一个 $N$ 维的张量 A（假设维度从 0 开始），它的底层存储为 A_internal，我们想要访问 A[i0][i1][i2]...，那么索引的方式如下： A[i0][i1][i2]... = A_internal[ stride_offset + i0 * A.strides[0] + i1 * A.strides[1] + i2 * A.strides[2] + ... + in-1 * A.strides[n-1] ] Strides 格式有两个组成部分 offset - 表示张量相对于底层存储 A_internal 的偏移量 strides 数组，长度和张量的维度一样，strides[i] 表示张量在第 $i$ 个维度上移动“一个单位”需要在内存上跳过多少个元素 举例来说，前面提到的二维数组的例子，如果用 strides 的格式来理解的话，应该是下面这样 A[i][j] = A_in_row[ 0 + i * A.shape[1] + j * 1 ] 即对于一个大小为 (A.shape[0], A.shape[1]) 的二维数组，它的 offset 是 0，strides = [A.shape[1], 1](row-major)。🤔️ 也就是说，每次在第一个维度上要跳跃“一个单位”，需要跳过底层的 A.shape[1] 个元素，A.shape[1] 也就是行的长度 我做了下面这张图片，希望能够帮助你理解 :) 🧐 那么如何得到 $N$ 维张量的 strides 数组？假设要求解的是 strides[k] 即第 $k$ 个维度的 stride，我们知道它的语义是「在第 $k$ 维上移动“一个单位”需要在内存上跳过多少个元素」，如果这个张量的底层存储在内存上是连续存储（紧凑格式），那就是 「$k+1,k+2,…,N-1$ 维度的大小的乘积」，如果 $k=N-1$，那么 strides[N - 1] = 1 数学公式就是下面这样， $$strides[k]=\\prod_{i=k+1}^{N-1}shape[i]$$ 💡 再次强调，上面的公式只有在张量的底层存储在内存上是连续存储（紧凑格式）的时候成立 ","date":"2023-07-14","objectID":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/:3:0","tags":["Internal","Pytorch","Deep-Learning"],"title":"Pytorch 张量的 strides 格式是什么","uri":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/"},{"categories":["ML-DL","Internal"],"content":"Why strides？ 知道了 strides 的存储格式之后，我们还要理解为什么这么设计，strides 究竟给我们带来了什么？最大的好处是：很多关于张量的操作都可以是零拷贝（Zero-copy）的。通过 strides 格式，「底层存储」和「视图」之间是分离开的，下面我来讲解一下几个常见的操作 ","date":"2023-07-14","objectID":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/:4:0","tags":["Internal","Pytorch","Deep-Learning"],"title":"Pytorch 张量的 strides 格式是什么","uri":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/"},{"categories":["ML-DL","Internal"],"content":"print_internal 函数 在开始之前，让我们先写一个函数获取 Pytorch 的张量底层存储 首先是 Pytorch 提供的 data_ptr() 这个方法，他会返回张量底层存储表示的第一个元素的内存地址 然后通过 Pytorch 提供的 storage().nbytes() 就可以知道张量的底层存储在内存上占据了多大的空间1，而张量的 dtype 属性则告诉了我们每个元素占据多大，比如 torch.float32 就是 4 个字节 最后通过 ctypes.string_at(address, size=-1) 函数就可以读取这个张量为 C 的字符串（buffer），而 torch.frombuffer 可以从一个 buffer 创建出 tensor 通过上面几个步骤，我们就可以还原出 Pytorch 底层的数组表示，下面命名为 print_internal 函数 def print_internal(t: torch.Tensor): print( torch.frombuffer( ctypes.string_at(t.data_ptr(), t.storage().nbytes()), dtype=t.dtype ) ) 然后我们创建一个维度为 (1, 2, 3, 4) 的张量 t 并观察它的底层表示，后面的操作讲解会基于这个张量 t torch.arange(0, 24).reshape(1, 2, 3, 4) print(t) # tensor([[[[ 0, 1, 2, 3], # [ 4, 5, 6, 7], # [ 8, 9, 10, 11]], # [[12, 13, 14, 15], # [16, 17, 18, 19], # [20, 21, 22, 23]]]]) print(t.stride()) # (24, 12, 4, 1) print_internal(t) # tensor([0, 1, 2, 3, # 4, 5, 6, 7, # 8, 9, 10, 11, # 12, 13, 14, 15, # 16, 17, 18, 19, # 20, 21, 22, 23]) 按照我们前面说的从张量的维度推导 stride 的方法，我们不难知道这个 tensor 的 stride 应该是 (2 * 3 * 4, 3 * 4, 4, 1) 也就是 (24, 12, 4, 1) 在 Pytorch 里面，我们可以通过调用 tensor 的 stride() 方法获得 stride，可以看到，确实跟我们手动计算出来的一样🤔️ ","date":"2023-07-14","objectID":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/:4:1","tags":["Internal","Pytorch","Deep-Learning"],"title":"Pytorch 张量的 strides 格式是什么","uri":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/"},{"categories":["ML-DL","Internal"],"content":"permute 操作 假设我们用 permute 重新排列了各个维度，那么 strides 如何变化？ print(t.stride()) # (24, 12, 4, 1) print(t.permute((1, 2, 3, 0)).is_contiguous()) # True print(t.permute((1, 2, 3, 0)).stride()) # (12, 4, 1, 24) print_internal(t.permute((1, 2, 3, 0))) # tensor([0, 1, 2, 3, # 4, 5, 6, 7, # 8, 9, 10, 11, # 12, 13, 14, 15, # 16, 17, 18, 19, # 20, 21, 22, 23]) permute 操作显然不会影响 offset，而且底层存储仍然是紧凑的，所以我们可以通过 permute 之后的新的维度 new_shape 然后根据定义计算出 strides，但是更快的办法是，直接在 strides 上也做一样的 permute 操作即可。print_internal 函数的输出证明了底层存储确实没有变化。 ","date":"2023-07-14","objectID":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/:4:2","tags":["Internal","Pytorch","Deep-Learning"],"title":"Pytorch 张量的 strides 格式是什么","uri":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/"},{"categories":["ML-DL","Internal"],"content":"broadcast_to 操作 广播操作是比较有意思的，在不了解张量的存储原理之前，你可能以为广播操作就是在对应的维度上拷贝多份，但其实，根本就没有发生拷贝，只是修改了 strides 数组的值而已。更确切来说，Pytorch 会把被广播的维度（本来的维度大小是 1）的 stride 设置为 02 比如现在我们在第一个维度上做广播，观察广播之后的维度大小，以及 strides 数组的变化情况 print(t.broadcast_to((2, 2, 3, 4)).is_contiguous()) # False print(t.broadcast_to((2, 2, 3, 4)).shape) # torch.Size([2, 2, 3, 4]) print(t.stride()) # (24, 12, 4, 1) print(t.broadcast_to((2, 2, 3, 4)).stride()) # (0, 12, 4, 1) print_internal(t.broadcast_to((2, 2, 3, 4))) # tensor([0, 1, 2, 3, # 4, 5, 6, 7, # 8, 9, 10, 11, # 12, 13, 14, 15, # 16, 17, 18, 19, # 20, 21, 22, 23]) 你（可能）会惊讶地发现，Pytorch 确实没有在广播的时候拷贝对应维度的张量，仅仅只是修改 strides 数组了而已。回忆 strides[i] 的含义，被广播的维度的 stride 设置为 0 意味着这个维度上移动“一个单位“并不需要在内存上跳过元素，也就是在被广播的维度上我们一直在访问的是同一块区域 ","date":"2023-07-14","objectID":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/:4:3","tags":["Internal","Pytorch","Deep-Learning"],"title":"Pytorch 张量的 strides 格式是什么","uri":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/"},{"categories":["ML-DL","Internal"],"content":"reshape 操作和 contiguous 操作 索引操作可能会修改 offset，因为索引之后形成的张量不一定从本来底层存储的第一个元素开始，同时索引操作可能会索引到底层存储中的「非连续」部分。因此我们可以通过索引操作来研究 reshape 操作和 contiguous 操作是如何起作用的 现在假设我们想要从 t 拿到下面这个张量 [[[2, 6, 10], [14, 18, 22]]] 对应的索引操作如下 print(t[:, :, :, 2]) # tensor([[[ 2, 6, 10], # [14, 18, 22]]]) 注意到这个操作同时符合我前面说的： offset 改变了，因为现在是从 2 而不是从 0 开始了 索引到的元素在本来的内存上不是连续的 下面的代码验证了我们的猜想 print(t.storage_offset()) # 0 print(t[:, :, :, 2].storage_offset()) # 2 print(t[:, :, :, 2].is_contiguous()) # False 现在来观察底层存储 print_internal(t[:, :, :, 2]) # tensor([ 2, 3, # 4, 5, 6, 7, # 8, 9, 10, 11, # 12, 13, 14, 15, # 16, 17, 18, 19, # 20, 21, 22, 23 # 1152921504606846976, -8070441752123218147]]) # ignore the last row because t.data_ptr() has changed but t.storage().nbytes() # kept the same. # As a result, we read 2 invalid elements and get 2 meaningless values Pytorch 的张量有个方法叫做 storage_offset 可以拿到张量相对于底层存储的偏移量，可以看到现在从底层存储的第二个位置开始了，第二个位置恰好是 t[:, :, :, 2] 的第一个元素 2。而打印出底层存储你会发现，底层存储还是本来的数组 注意这里有个小问题，因为底层存储没有变化，t.storage().nbytes() 跟原来一样。但是 data_ptr() 会给我们第二个元素的地址，导致最后 print_internal 打印底层存储的时候会多打印 2 个无效的位置（也就是上面的最后一行），所以得到了 2 个没有意义的数字 🤔️ 这个时候我们尝试执行 reshape(3, 2) 并观察底层存储情况 print_internal(t[:, :, :, 2].reshape(3, 2)) # tensor([ 2, 3, # 4, 5, 6, 7, # 8, 9, 10, 11, # 12, 13, 14, 15, # 16, 17, 18, 19, # 20, 21, 22, 23 # 1152921504606846976, -8070441752123218147]]) reshape 操作之后发现底层存储还是没有变化，这恰好对应文档里面所说的：可能的情况下，reshape 之后，返回的张量尽可能是同一份存储3 但如果我们想要 reshape 之后的张量在底层的存储是紧凑的呢？此时就可以紧跟着调用 contiguous 方法 print_internal(t[:, :, :, 2].reshape(3, 2).contiguous()) # tensor([ 2, 6, 10, 14, 18, 22]) 😺 可以发现，contiguous 之后确实底层存储就紧凑了，此时的 strides 数组应该符合我们前面提到的公式： # before contiguous print(t[:, :, :, 2].reshape(3, 2).stride()) # (8, 4) # after contiguous print(t[:, :, :, 2].reshape(3, 2).contiguous().shape) # (3, 2) print(t[:, :, :, 2].reshape(3, 2).contiguous().stride()) # (2, 1) 🧐 一个比较有挑战性的问题，索引操作会如何影响 strides？ 让我们以刚才的索引操作为例子，首先，索引之后得到新的维度应该是 (1, 2, 3)，显然 [:, :, :, 2] 这样的索引导致底层存储在内存上不紧凑，因此规律不适用，那么只能从定义上出发，假设 t[:, :, :, 2] 的 strides 是 [x, y, z] 先观察 t[:, :, :, 2] 包含哪一些元素 print(t[:, :, :, 2]) # tensor([[[ 2, 6, 10], # [14, 18, 22]]]) 因为我定义的张量是从 0 开始的整数，因此我们可以直接观察值的变化来计算 strides 的变化（这是一个小技巧） 对于 z，从 2 -\u003e 6 -\u003e 10，每次跳过了 4 个位置，所以 z = 4 对于 y，2 -\u003e 14，6 -\u003e 18，10 -\u003e 22，每次都跳过了 12 个位置，因此 y = 12 对于 x，因为底层存储并没有改变，原本的张量 t 的 stride[0] = 24，如果张量 t 的第一个维度不是 1 而是一个更大的值，我们还是每次会跳过 stride[0] 个元素，所以 x = 24 所以 t[:, :, :, 2] 的 strides 应该是 (24, 12, 4) 让我们来调用一下 API 看这是否正确 print(t.stride()) # (24, 12, 4, 1) print(t[:, :, :, 2].stride()) # (24, 12, 4) # what if the first dimension is not 1 but 2? another_t = torch.arange(0, 48).reshape(2, 2, 3, 4) print(another_t[:, :, :, 2]) # tensor([[[ 2, 6, 10], # [14, 18, 22]], # [[26, 30, 34], # [38, 42, 46]]]) # you can see that 2 -\u003e 26, 6 -\u003e 30, 10 -\u003e 35 # , so the stride[0] = 24 is true 上面的代码验证了我们的猜想 但是，索引操作可能远远比我们这里讲解的 [:, :, :, 2] 复杂得多，比如 [2, 1:3, 1:6:3] 这种，此时 strides 和 offset 又该如何变化？这里不展开，但是可以放一个提示：把每个格式都变成 Python 的 Slice 对象，然后从 strides[i] 的定义出发进行推导 ","date":"2023-07-14","objectID":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/:4:4","tags":["Internal","Pytorch","Deep-Learning"],"title":"Pytorch 张量的 strides 格式是什么","uri":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/"},{"categories":["ML-DL","Internal"],"content":"总结 可以看到，Pytorch 的张量的不少操作都是通过改变 strides 的 offset 或（和）strides 数组实现的，这让很多操作维持了零拷贝开销，因此效率会很高，而且，这使得我们可以把不少张量操作实现为 Lazy 的。理解 strides 格式有助于构建张量的 mental model，它能够让你更好理解张量的操作的代码。顺便推荐一下这个视频，在这个视频中，可以看到如何操纵 strides 来实现高效的卷积操作 现在我们可以回答前面我抛出的问题了： 广播操作涉及到数组的拷贝吗？ 并没有拷贝，只是修改了 strides 数组 Pytorch 的 contiguous 中是干什么的？为什么需要这个函数？ 因为 contiguous 之后，张量的底层存储是内存紧凑的，虽然有拷贝的开销，但是后续执行一些张量相关的操作的时候内存局部性会更好 ","date":"2023-07-14","objectID":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/:5:0","tags":["Internal","Pytorch","Deep-Learning"],"title":"Pytorch 张量的 strides 格式是什么","uri":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/"},{"categories":["ML-DL","Internal"],"content":"参考 Tensor type memory usage - Memory Format - PyTorch Forums ↩︎ torch.expand - PyTorch 2.0 documentation ↩︎ torch.reshape — PyTorch 2.0 documentation ↩︎ ","date":"2023-07-14","objectID":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/:6:0","tags":["Internal","Pytorch","Deep-Learning"],"title":"Pytorch 张量的 strides 格式是什么","uri":"/zh-cn/how-to-reprensent-a-tensor-or-ndarray/"},{"categories":["Data-Structure"],"content":"介绍了如何在 2-3-4 树上思考红黑树的插入和删除操作，减轻记忆负担","date":"2023-07-01","objectID":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/","tags":["Data-Structure"],"title":"如何记忆红黑树的操作","uri":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/"},{"categories":["Data-Structure"],"content":"引言 如果你点进了这一篇文章，相信你也跟我一样：红黑树学一次忘一次，又要做树的旋转，又要给节点重新上色，导致每次都是学完了就忘记。我也曾经仔细阅读过 CLRS 写的《算法导论》，但是上面的分类讨论只是让我更加头疼 当然，记住一项东西的最佳方式永远都是理解它，而最近看到斯坦福的 CS166 高级数据结构课程的课件的时候，我似乎理解了红黑树————红黑树和 2-3-4 树是等同（isometry）的数据结构，他们只是用了不同的方式表示 2-3-4 树1，这意味着我们可以通过 2-3-4 树上的节点变化，进而推导出红黑树上的形状和颜色的变化，而 2-3-4 树的节点变化，是简单很多的 在开始之前，我假定你对以下的内容很熟悉 你知道 2-3-4 树或者说 B 树是什么，2-3-4 树其实就是 B 树的一种。你需要知道在 2-3-4 树上的删除和插入操作如何进行，什么时候会发生节点的 overflow、underflow，以及这种时候要如何处理 你知道如何在二叉搜索树中插入和删除节点，毕竟红黑树本身就是保证高度是 $O(log\\ n)$ 的二叉搜索树，要知道如何找到插入位置，如何确定要删除的节点等 你需要知道红黑树和 2-3-4 树的定义，需要理解红黑树有什么性质，以及在红黑树上插入节点、删除节点都可能打破哪些性质 最重要的，你不需要记住红黑树的旋转和颜色变化操作，因为只要你掌握了今天要讲的技巧，你就可以在红黑树的操作和 2-3-4 树上的操作之间建立直觉上的联系 ","date":"2023-07-01","objectID":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/:1:0","tags":["Data-Structure"],"title":"如何记忆红黑树的操作","uri":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/"},{"categories":["Data-Structure"],"content":"节点映射定义 2-3-4 树上一共只有可能有下面 3 种节点： 2-node，有 2 个孩子，含 1 个 key 3-node，有 3 个孩子，含 2 个 key 4-node，有 4 个孩子，含 3 个 key 通过节点映射关系，我们可以将 2-3-4 树上的节点转化为对应的红黑树结构，反之依然。注意他们都是黑色节点开始，后面我们会多次用到这个映射表 左边是 2-3-4 树的 2-node, 3-node, 4-node，右边是对应的红黑树结构 ","date":"2023-07-01","objectID":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/:2:0","tags":["Data-Structure"],"title":"如何记忆红黑树的操作","uri":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/"},{"categories":["Data-Structure"],"content":"新增节点操作 先来简单回顾一下，往红黑树节点中新增一个节点的步骤 红黑树是二叉搜索树，所以一开始按照二叉搜索树插入节点的办法找到要插入的位置 如果新插入的点会成为根节点（即本来的红黑树为空），则新插入的节点为黑色；其他情况则为红色，因为红黑树有个性质是从任一节点到其每个叶子节点的路径都包含相同数量的的黑色节点，让新插入的节点的颜色为红色就可以维护这个性质。下面我们只考虑新插入的节点为红色的情况 新插入的节点是红色的话这意味着可能打破红黑树的另外一个性质——不能有 2 个连续的红色节点。红黑树中通过树旋转和节点重新上色🎨解决了这个问题，但是规则比较复杂不好记 在讲解具体例子之前，先概括一下通用的思路： 找到要插入的位置插入新节点，设置新节点的颜色为红色 将红黑树上「违背规则的部分」转化为「2-3-4 树上等同的形式」 思考如果在 2-3-4 树的这个等价形式要如何处理 在 2-3-4 树上处理好之后，再转化为红黑树，此时形状和颜色都决定好了 💡 为了帮助读者理解如何在 2-3-4 树和红黑树之间变换，在变换前后的等同部分，我用了一个带颜色的透明框标记了 💡 我选择了直接用具体的数值而不是抽象的符号，因为这样会更加直观，更方便读者在 2-3-4 树和红黑树之间找到联系 ","date":"2023-07-01","objectID":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/:3:0","tags":["Data-Structure"],"title":"如何记忆红黑树的操作","uri":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/"},{"categories":["Data-Structure"],"content":"新增节点的父节点是黑色节点 一个简单情况是，新插入的红色节点的父节点是黑色，此时满足要求仍然是红黑树，不需要任何改动 ","date":"2023-07-01","objectID":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/:3:1","tags":["Data-Structure"],"title":"如何记忆红黑树的操作","uri":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/"},{"categories":["Data-Structure"],"content":"新增节点的父节点是红色节点而且不存在 uncle 节点 接下来，让我们考虑稍微复杂点的情况，新增节点的父节点是红色节点，红黑树不允许这样的情况出现。此时它可能有也可能没有 unlce 节点，让我们先考虑它没有 uncle 节点的情况，可以很轻松画出下面几种可能的形式 注意这几种都是等价的，下面我只展示上图第一个例子是如何操作的 💡 后面当我们讨论其他情况的时候，他们也可能会存在等价形式，但其实方法都大同小异，我会每次挑其中一个讲 根据之前提到的节点映射关系，插入前的红黑树正好对应 2-3-4 树上的 3-node，然后我们在红黑树中插入节点 1，与此同时，我们在 3-node 上也进行插入操作，得到了一个 4-node，4-node 符合 2-3-4 树要求，所以也不需要分裂节点，此时再根据节点映射关系转化为红黑树 此时你可能觉得似乎 2-3-4 树没有带来多大方便，因为这里一个简单右旋，然后重新染色并不是一件复杂的事情，但是之后随着情况越来越复杂，你会发现 2-3-4 树的理解角度容易理解很多🤔️ ","date":"2023-07-01","objectID":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/:3:2","tags":["Data-Structure"],"title":"如何记忆红黑树的操作","uri":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/"},{"categories":["Data-Structure"],"content":"新增节点的父节点是红色节点而且存在 uncle 节点 现在让我们来考虑它有 uncle 节点的情况，它可能为黑色，也可能为红色 先来看看如果 uncle 节点为黑色的其中一种可能情况 根据节点的映射关系，我们可以把红黑树的 2, 5 映射为 2-3-4 树上的 3-node，而红黑树上的 7 就映射为一个 2-node，在红黑树上插入 1，因此也在 2, 5 这个 3-node 上插入 1，得到的 1, 2, 5 根据节点映射关系，映射为一个黑色节点加两个红色孩子节点，而 7 则映射为一个黑色节点 那如果 uncle 节点是红色呢？比如像下面这样 这个会稍微复杂一些，因为在等价的 2-3-4 树插入 1 之后我们需要对 1, 2, 5, 7 进行分裂操作，也就是将图上的节点 5 插入到父节点中，因为不知道父节点什么情况，因此节点 5 两边用省略号表示，在 2-3-4 树中往父节点插入一个节点意味着可能导致父节点也 overflow，最坏的情况我们是需要这样一路一直修改回去 另外注意一个问题，这里插入的新节点的祖先（grandparent）节点应该是红色节点，例子中的节点 5 就是新增节点 1 的祖先节点。这样才能保证从任一节点到其每个叶子节点的路径都包含相同数量的的黑色节点，但是有个例外，那就是祖先节点是红黑树的根节点的时候，那么它就应该是黑色，下图清晰展示了这 2 种可能 ","date":"2023-07-01","objectID":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/:3:3","tags":["Data-Structure"],"title":"如何记忆红黑树的操作","uri":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/"},{"categories":["Data-Structure"],"content":"删除节点操作 先来简单回顾一下，在红黑树节点中删除一个节点的步骤 按照二叉搜索树删除节点的方式，找到要删除的节点，假设要被删除的节点是 z 那么根据 z 的节点颜色可以分出下面两种情况 z 是红色节点，删除红色节点是比较容易的，因为不会打破红黑树的性质，就是正常的二叉搜索树删除节点的操作，这里不展开 z 是黑色节点，删除黑色节点可能打破红黑树的性质——从任一节点到其每个叶子节点的路径都包含相同数量的的黑色节点，在红黑树中，遇到这种情况仍然是需要用树的旋转和节点重新上色🎨解决问题。下面的讨论主要考虑的是这种情况 ","date":"2023-07-01","objectID":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/:4:0","tags":["Data-Structure"],"title":"如何记忆红黑树的操作","uri":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/"},{"categories":["Data-Structure"],"content":"被删除的节点有红色右孩子 💡 注意，根据二叉搜索树的删除节点操作，我们知道要删除的节点 z 一定没有左孩子，如果它有右孩子的话，我们记为 y 💡 黄色节点表示不知道颜色或者是不关心它什么颜色 删除黑色的 z，然后用它的红色右孩子 y 代替 z ","date":"2023-07-01","objectID":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/:4:1","tags":["Data-Structure"],"title":"如何记忆红黑树的操作","uri":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/"},{"categories":["Data-Structure"],"content":"被删除的节点有黑色右孩子 我们暂时用黑色的 y 代替被删除的黑色的 z，并且记 y 为 “double black” 节点，在图上，黑色节点 + 圆环就表示 “double black”2 💡 “double black” 对于红黑树而言，意味着我们要让这边有 2 个黑色节点；对于 2-3-4 树而言，那就对应 2-3-4 树中删除 2-node 的 key之后引发的 underflow 删除黑色的 z，然后用它的黑色右孩子 y 代替 z，标记 y 为 “double black” 节点 接下来我们要根据「“double black” 的兄弟节点」来分情况推导 如果兄弟节点是黑色而且有「一个红色孩子」 在上面的例子，转化为等价的 2-3-4 树上的删除节点操作，在 2-3-4 树中遇到这种情况需要执行 transfer 操作，因为兄弟节点 6, 7 是一个 3-node，还有得借。transfer 操作也就是父节点的 key 移动到被删除的节点的位置，然后兄弟节点的最小的 key 移动到父节点填补空缺 💡 注意看，现在 4 和 5 是 2 个黑色节点，先前这里是一个特殊的 “double black” 节点，现在有 2 个黑色节点了，“double black” 也就没有必要了。这也是它叫做这个名字的原因，我们需要提醒自己这里需要 2 个黑色节点 💡 注意这里节点 6 的颜色就是本来节点 5 的颜色 如果兄弟节点是黑色而且有「两个黑色孩子」 在上面的例子，转化为等价的 2-3-4 树上的删除节点操作，在 2-3-4 树中遇到这种情况需要执行 fusion 操作，因为兄弟节点 7 是一个 2-node，没得借。fusion 操作就是从父节点那边借一个 key 下来，然后和兄弟节点合并，成为一个 3-node，也就是图上的 5, 7 💡 但是注意这里的 Fusion 操作找父节点借了一个 key，这可能导致父节点 underflow 了，正如前面我们在新增节点的时候可能 overflow 理论上来说，这个例子的节点 5 应该是黑色（根据前面对节点映射的规定），这样才能满足 “double black” 的要求，但是不要忘了 5 自己是有颜色的 如果 5 本来是红色，那么把 5 变成黑色是没有问题的，因为现在的节点 7 就是红色，红黑树还是平衡的 如果 5 本来是黑色，那么把 5 变成黑色是有问题的，因为还是会少了一个黑色节点，那么节点 5 就变成了新的 “double black” 节点，我们还得向上继续调整。这恰恰是对应了 2-3-4 树中发生了 underflow 的情况，那么我们就要 bototm-up 一路调整回去。最后如果发现根节点是一个 “double black” 节点，那么把根节点变成黑色节点即可 最后一种情况，如果兄弟节点为红色，而且有 2 个黑色孩子 💡 注意，如果兄弟节点是红色，他们的共同父节点肯定是黑色，因为红黑树不允许有 2 个连续的红色节点 这个可以通过取巧的办法来转化为前面情况： 现在节点 4 的兄弟节点就是黑色节点了，转化为前面的情况，可以按照前面的办法处理 ","date":"2023-07-01","objectID":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/:4:2","tags":["Data-Structure"],"title":"如何记忆红黑树的操作","uri":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/"},{"categories":["Data-Structure"],"content":"总结 经过前面的例子展示，我们发现可以在 2-3-4 树上思考要如何处理，处理完成之后转变回红黑树，而 2-3-4 树的节点插入和删除操作都是比较简单的，这也是这套方法的价值所在，最重要的是，终于可以不用记住旋转顺序和怎么交换颜色了👏 ","date":"2023-07-01","objectID":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/:5:0","tags":["Data-Structure"],"title":"如何记忆红黑树的操作","uri":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/"},{"categories":["Data-Structure"],"content":"推荐阅读 关于 2-3-4 树和红黑树的对应关系，还有下面的几个参考资源可以阅读 CS166. Balanced Trees, Part I CS166. Balanced Trees, Part II CS280. Mapping 2-3-4 trees into Red-Black trees ","date":"2023-07-01","objectID":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/:6:0","tags":["Data-Structure"],"title":"如何记忆红黑树的操作","uri":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/"},{"categories":["Data-Structure"],"content":"参考 CS166. Balanced Trees, Part II ↩︎ Red Black Trees ↩︎ ","date":"2023-07-01","objectID":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/:7:0","tags":["Data-Structure"],"title":"如何记忆红黑树的操作","uri":"/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/"},{"categories":["Git"],"content":"介绍了少为人知的 git bundle 命令","date":"2023-06-16","objectID":"/zh-cn/git-bundle-tutorial/","tags":["Git"],"title":"Git Bundle 指南","uri":"/zh-cn/git-bundle-tutorial/"},{"categories":["Git"],"content":"git bundle 是什么 git bundle 是一个比较少看到的 git 命令，它的作用是把一个 git 仓库打包📦成一个文件，然后别人可以通过这个文件还原出本来的 git 仓库，而且 git bundle 还支持增量更新功能。在知道 git bundle 命令之前，我有时候打包一个 git 仓库一般就直接 tar czf some_git_repo。前阵子偶然发现了 git bundle 发现还挺实用的🍻 这个命令最好通过例子来说明，因此下面我用 HostA 和 HostB 这两个文件夹模拟两台主机，假设在 HostA 上存在某个 git 仓库 foo，目录结构如下： ├── HostA │ └── foo │ ├── 1.txt │ ├── 2.txt │ └── 3.txt ├── HostB 其中 foo 有 3 个 commits，如下所示： * 21486d5 (HEAD -\u003e main) add 3.txt * a051186 add 2.txt * 2820a6c add 1.txt ","date":"2023-06-16","objectID":"/zh-cn/git-bundle-tutorial/:1:0","tags":["Git"],"title":"Git Bundle 指南","uri":"/zh-cn/git-bundle-tutorial/"},{"categories":["Git"],"content":"使用场景 ","date":"2023-06-16","objectID":"/zh-cn/git-bundle-tutorial/:2:0","tags":["Git"],"title":"Git Bundle 指南","uri":"/zh-cn/git-bundle-tutorial/"},{"categories":["Git"],"content":"HostA 上首次打包 首次打包那么必定是要对整个 git 仓库进行打包，打包 HostA 上的 foo 仓库的命令很简单 # in HostA/foo # syntax: git bundle create \u003cfilename\u003e \u003cgit-rev-list-args\u003e $ git bundle create foo.bundle HEAD main 比较难懂的是 \u003cgit-rev-list-args\u003e，它的含义是我们要把什么东西打包到这个 bundle 文件里面。这里我们是要打包 HostA 的 foo 仓库，它有一个 main 分支，同时我们把 HEAD 当前指向的位置也打包到这个 bundle 文件里面，所以用的是 HEAD main ","date":"2023-06-16","objectID":"/zh-cn/git-bundle-tutorial/:2:1","tags":["Git"],"title":"Git Bundle 指南","uri":"/zh-cn/git-bundle-tutorial/"},{"categories":["Git"],"content":"HostB 上克隆仓库 现在假设 HostB 上拿到了前面打包好的 foo.bundle 文件，那么还原出本来的仓库也很简单，命令如下所示 # in HostB # syntax: git clone \u003cfilename\u003e \u003ctarget_dir\u003e $ git clone foo.bundle foo 可以看到，提取 bundle 文件的信息就像是从一个普通的 URL 克隆仓库一样，只不过把 URL 换成了 bundle 文件的路径 此时看下这个仓库的远程仓库信息，你会发现它的远程仓库被设置成了 foo.bundle 文件 # in HostB/foo $ git remote -v # output: # origin \u003cpath_to_foo.bundle\u003e (fetch) # origin \u003cpath_to_foo.bundle\u003e (push) ","date":"2023-06-16","objectID":"/zh-cn/git-bundle-tutorial/:2:2","tags":["Git"],"title":"Git Bundle 指南","uri":"/zh-cn/git-bundle-tutorial/"},{"categories":["Git"],"content":"HostA 上继续更新 现在假设 HostA 上的 foo 仓库多更新了几个 commit，如下所示： * 9ac69b0 (HEAD -\u003e main) add 5.txt -- new commit * 0350a1e add 4.txt -- new commit * 21486d5 add 3.txt * a051186 add 2.txt * 2820a6c add 1.txt 我们想要把 HostA 上这两个新的 commit 打包📦后发送给 HostB 让 HostB 可以和 HostA 保持同步。所以我们可以利用 git 提供的指定 commit range 的语法，选中这两个 commits1 # in HostA/foo # let's verify what will be bundled first $ git log --oneline 21486d5..main $ git bundle create increment.bundle 21486d5..main ","date":"2023-06-16","objectID":"/zh-cn/git-bundle-tutorial/:2:3","tags":["Git"],"title":"Git Bundle 指南","uri":"/zh-cn/git-bundle-tutorial/"},{"categories":["Git"],"content":"HostB 上增量更新 现在假设 HostB 拿到了 increment.bundle，那么用下面的命令可以提取里面的 commits # in HostB/foo # syntax: git fetch \u003cBUNDLE_FILE\u003e \u003cBRANCH_IN_BUNDLE\u003e:\u003cBRANCH_IN_LOCAL_REPO\u003e $ git fetch increment.bundle main:feature 上面这个命令会将 increment.bundle 文件包含的 commit 放到新的 feature 分支上 # in HostB/foo $ git log --oneline --graph --all # output: # * 9ac69b0 (feature) add 5.txt # * 0350a1e add 4.txt # * 21486d5 (HEAD -\u003e main, origin/main, origin/HEAD) add 3.txt # * a051186 add 2.txt # * 2820a6c add 1.txt 确定没有问题之后我们可以尝试合并 feature 分支，并删除 feature 分支 # in HostB/foo $ git merge feature $ git branch -d feature $ git log --oneline --graph --all # output: # * 9ac69b0 (HEAD -\u003e main) add 5.txt # * 0350a1e add 4.txt # * 21486d5 (origin/main, origin/HEAD) add 3.txt # * a051186 add 2.txt # * 2820a6c add 1.txt 🤔️ 那么能否直接将 increment.bundle 文件里的 commits 合并到 HostB 的 foo 的 main 分支上呢？也是可以的，命令是：git pull increment.bundle main:main，但是并不建议这么做，因为 HostB/foo 也有可能更新了仓库，先 fetch 再 merge 是一个好习惯 你可能还记得，HostB 上的 foo 这个仓库的远程分支被设置为某个文件，那么能否像一般使用 git 那样直接 git pull 呢？答案是肯定的，我们只需要将 increment.bundle 文件重命名为 foo.bundle 文件然后放在 git remote -v 显示的路径就行（当然改 remote 信息也可） ","date":"2023-06-16","objectID":"/zh-cn/git-bundle-tutorial/:2:4","tags":["Git"],"title":"Git Bundle 指南","uri":"/zh-cn/git-bundle-tutorial/"},{"categories":["Git"],"content":"FAQ 怎么知道 bundle 文件里面有什么分支可以用呢？下面的命令可以显示 bundle 文件里面所有的分支 # syntax: git bundle list-heads \u003cBUNDLE_FILE\u003e $ git bundle list-heads increment.bundle # output: 9ac69b08060859bc4b2172a8238cb841846ec5e0 refs/heads/main 怎么确定一个 bundle 文件能否用于当前的某个 git 仓库上呢？只需要将 bundle 文件放在这个 git 仓库里然后运行 git bundle verify # in HostB/foo # syntax: git bundle verify \u003cBUNDLE_FILE\u003e $ git bundle verify increment.bundle # output: # The bundle contains this ref: # 9ac69b08060859bc4b2172a8238cb841846ec5e0 refs/heads/main # The bundle requires this ref: # 21486d53326de40678a54159de656714a59b8d09 # The bundle uses this hash algorithm: sha1 # increment.bundle is okay 从上面的输出可以看到，increment.bundle 要求仓库有 21486d5 这个 commit 才能够被用来更新。前面的 HostB/foo 在同步之前的最后一个 commit 就是这个 ","date":"2023-06-16","objectID":"/zh-cn/git-bundle-tutorial/:3:0","tags":["Git"],"title":"Git Bundle 指南","uri":"/zh-cn/git-bundle-tutorial/"},{"categories":["Git"],"content":"总结 git bundle 打包 git 仓库还是很方便的，结合选取 commit range 的语法还可以只选中部分 commits 增量更新，这样这个 bundle 文件就不会太大，方便我们进行传输 ","date":"2023-06-16","objectID":"/zh-cn/git-bundle-tutorial/:4:0","tags":["Git"],"title":"Git Bundle 指南","uri":"/zh-cn/git-bundle-tutorial/"},{"categories":["Git"],"content":"参考 Git Revision Selection ↩︎ ","date":"2023-06-16","objectID":"/zh-cn/git-bundle-tutorial/:5:0","tags":["Git"],"title":"Git Bundle 指南","uri":"/zh-cn/git-bundle-tutorial/"},{"categories":["GNN"],"content":"用 MPNN 框架解读图神经网络中的 GAT","date":"2023-05-21","objectID":"/zh-cn/understanding-graph-attention-network-through-mpnn/","tags":["GNN","Deep-Learning","Paper"],"title":"用 MPNN 框架解读 GAT","uri":"/zh-cn/understanding-graph-attention-network-through-mpnn/"},{"categories":["GNN"],"content":"什么是 MPNN 框架 Justin Gilmer 提出了 MPNN（Message Passing Neural Network）框架1 ，用于描述被用来做图上的监督学习的图神经网络模型。我发现这是一个很好用的框架，可以很好理解不同的 GNN 模型是如何工作的，方便快速弄清楚不同的 GNN 模型之间的差别。我们考虑图 $G$ 上的一个节点 $v$，它的向量表示 $h_v$ 的更新方式如下： $$m_v^{t+1}=\\sum_{u\\in \\mathcal{N}(v)}M_t(h_v^t,h_u^t,e_{vu})$$ $$h_v^{t+1}=U_t(h_v^t,m_v^{t+1})$$ 其中 $u$ 为 $v$ 的邻居节点，$\\mathcal{N}(v)$ 则表示节点 $v$ 的所有邻居 $e_{vu}$ 是可选项，表示边上的特征（若有） $M_t$ 是消息函数，$m_v^{t+1}$ 就是所有邻居节点的消息聚合之后的结果 $U_t$ 是节点更新函数 在更新完图上所有节点的向量表示之后，我们可能需要要做图级别的分类任务，在 MPNN 框架中对应为： $$\\hat y=R({h_v^T|v\\in G})$$ 其中： $R$ 为图读出函数，输入是图上所有节点的向量表示，输出为一个特征向量用于图级别的分类任务 ","date":"2023-05-21","objectID":"/zh-cn/understanding-graph-attention-network-through-mpnn/:1:0","tags":["GNN","Deep-Learning","Paper"],"title":"用 MPNN 框架解读 GAT","uri":"/zh-cn/understanding-graph-attention-network-through-mpnn/"},{"categories":["GNN"],"content":"什么是 GAT 🧐 我发现将论文的公式和具体的代码联系起来总是能够帮助理解，因此下面关于 GAT 公式的讲解我会在用 MPNN 框架的基础上，同时附上相关的代码（用 ... 表示其他省略的部分）。代码来自于 DGL 官方提供的 GAT 模块的源码 🧐 GAT 可以方便堆叠多层，下面的讨论都是从某一层 $l$的某个节点 $v$ 的角度来谈的 Step 1. 对节点做线性变换 $$h_v^{l}=W^lh_v^{l}$$ 设每个节点的向量表示的长度为 $F$，在第一步中，对图上每个结点的向量先做一个线性变换，其中 $W\\in\\mathcal{R}^{F’\\times F}$, 因此每个节点的向量都更新长度为 $F’$。为了区分不同层的向量，用上角标 $l$ 表示这是第 $l$ 层的。注意在第 $l$ 层中，所有节点共用同一个权重矩阵 $W$ 📒 注意后面的 $h_v^l$ 或者 $h_u^l$ 都是经过线性变换之后的 class GATConv(nn.Module): def __init__(self, ...): ... self.fc = nn.Linear( self._in_src_feats, out_feats * num_heads, bias=False ) ... def forward(self, graph, feat, ...): \"\"\" Args ---- feat: (N, *, D_in) where D_in is the size of input feature Returns ------- torch.Tensor (N, *, num_heads, D_out) \"\"\" ... src_prefix_shape = dst_prefix_shape = feat.shape[:-1] h_src = h_dst = self.feat_drop(feat) # h_src: (N, *, D_in) feat_src = feat_dst = self.fc(h_src).view( *src_prefix_shape, self._num_heads, self._out_feats ) # feat_src/feat_dst: (N, *, num_heads, out_feat) ... 注意，上面代码中的 h_src 会出来两个一样的 feat_src 和 feat_dst 是因为 DGL 采用了数学上等价但是计算效率会更高的实现。后面会解释 Step 2. 计算注意力 $$e_{vu}^l=LeakyReLU\\Big((a^l)^T[h_v^{l}||h_u^{l}]\\Big)$$ $$\\alpha_{vu}^l=Softmax_u(e_{vu}^l)$$ 第二步就是要计算中心节点 $v$ 和它的所有邻居节点之间的注意力了。在上面的公式中： $e_{vu}^l$ 表示注意力系数（attention coefficient）。论文中提到完全可以采用不同的注意力计算方式，在 GAT 的论文中，作者选择用一层前馈神经网络计算注意力2。注意这里的 $e_{vu}^l$ 跟 MPNN 的 $e_{vu}$ 是没有关系的，只是恰好记号一样了而已 $||$ 表示拼接操作，即我们会将中心节点和它对应的邻居结点的向量表示拼接起来，得到一个长度为 $2F’$ 的向量，对应公式中的 $[h_v^{l}||h_u^{l}]$，然后把它送入到前面提到的一层前馈神经网络中，对应公式中的 $(a^l)^T[h_v^{l}||h_u^{l}]$，其中 $(a^l)^T$ 指的是第 $l$ 层的单层前馈神经网络的参数 激活函数选用的是 $LeakyReLU$ 最后在节点 $v$ 的所有邻居节点之间用 Softmax 做归一化 🤔️ 步骤一和步骤二对应 MPNN 框架的 $m_v^{t+1}$ 的计算 多头注意力 正如 Transformer 中有多头注意力一样，GAT 的作者同样在节点更新的时候采用了多头注意力的机制： $$h_v^{l+1}= ||^{K^l} \\sigma(\\sum_{u\\in\\mathcal{N}(i)}\\alpha_{vu}^{(k,l)}W^{(k,l)}h_u^{l})$$ 记号越来越复杂了，但是仔细思索一番还是可以理清楚的，上角标 $(k,l)$ 的意思是第 $l$ 层的第 $k$ 个头。其中 $K^l$ 为第 $l$ 层“头”的数量。上面的公式的意思就是每个“头”会计算出一个向量表示，然后不同“头”之间的会拼接起来 class GATConv(nn.Module): def __init__(self, ...): ... self.attn_l = nn.Parameter( th.FloatTensor(size=(1, num_heads, out_feats)) ) self.attn_r = nn.Parameter( th.FloatTensor(size=(1, num_heads, out_feats)) ) self.leaky_relu = nn.LeakyReLU(negative_slope) ... def forward(self, graph, feat, ...): \"\"\" Args ---- feat: (N, *, D_in) where D_in is the size of input feature Returns ------- torch.Tensor (N, *, num_heads, D_out) \"\"\" # feat_src/feat_dst: (N, *, num_heads, out_feat) el = (feat_src * self.attn_l).sum(dim=-1).unsqueeze(-1) er = (feat_dst * self.attn_r).sum(dim=-1).unsqueeze(-1) # el/er: (N, *, num_heads, 1) graph.srcdata.update({\"ft\": feat_src, \"el\": el}) graph.dstdata.update({\"er\": er}) graph.apply_edges(fn.u_add_v(\"el\", \"er\", \"e\")) e = self.leaky_relu(graph.edata.pop(\"e\")) # e: (N, *, num_heads, 1) # normalization graph.edata[\"a\"] = self.attn_drop(edge_softmax(graph, e)) # a: (N, *, num_heads, 1) # weighted sum graph.update_all( # ft: (N, *, num_heads, out_feat) # a: (N, *, num_heads, 1) # m: (N, *, num_heads, out_feat) fn.u_mul_e(\"ft\", \"a\", \"m\"), fn.sum(\"m\", \"ft\") ) rst = graph.dstdata[\"ft\"] # rst: (N, *, num_heads, out_feat) ... DGL 的实现基于下面这个事实： $$a^T[h_v||h_u]=a_l^Th_v+a_r^Th_u$$ 为什么会更为高效呢？ 不需要存储 $[h_v||h_u]$ 这个中间变量了（DGL 会将消息存储为边的属性） 加法可以用 DGL 优化过的 fn.u_add_v 函数 Step 3. 聚合邻居消息 最后节点更新的方式就是计算邻居的向量表示的加权和（基于前面算好的注意力）： $$h_v^{l+1}=\\sigma(\\sum_{u\\in \\mathcal{N}(i)}\\alpha_{vu}W^{l}h_u^{l})$$ 🤔️ 上面就对应 MPNN 框架中的 $h_v^{t+1}$ 的计算，注意 GAT 算 $h_t^{l+1}$ 的时候并不会用到自己上一层表示 $h_t^l$。同时 GAT 的提出是用于解决图上的节点分类问题，因此也没有图读出的操作。 在 GAT 的论文中，作者是要将 GAT 用于节点级别的分类任务2。假设我们堆叠了 $L$ 层的 GAT 之后，在最后一层如果还采用拼接的方式显然是不合理的。因此作者在最后一层 GAT 中，是取多个头的平均值之后才应用了激活函数，这里的激活函数如果采用 Softmax，就可以直接做节点分类了2。公式如下所示: $$final\\ embedding\\ of\\ h_v= \\sigma\\Big(\\frac{1}{K^L}\\sum_{k=1}^{K^L}\\sum_{u\\in\\mathcal{N}(i)}\\alpha_{vu}^{(k,L)}W^{(k,L)}h_u^{L}\\Big)$$ ","date":"2023-05-21","objectID":"/zh-cn/understanding-graph-attention-network-through-mpnn/:2:0","tags":["GNN","Deep-Learning","Paper"],"title":"用 MPNN 框架解读 GAT","uri":"/zh-cn/understanding-graph-attention-network-through-mpnn/"},{"categories":["GNN"],"content":"实现 🤔️ 图神经网络的流行框架之一 DGL 的设计就是基于 MPNN 框架，不过他们的公式会稍有不同，他们还有一个聚合函数 $\\rho$，用于决定一个节点如何聚合从邻居那边收到的所有信息。我认为他们的公式更具有泛化性，能够适用于更多种情况。他们还贴心地写了关于如何使用 DGL 的 MPNN 相关函数的教程，推荐一看👍👍👍 至于 GAT 的实现，DGL 不仅提供了 GAT 模块，而且还写了一篇不错的用自带的 message_func 和 reduce_func 手动实现 GAT 的教程。一个完整的 GAT 任务训练脚本可以看这里 ","date":"2023-05-21","objectID":"/zh-cn/understanding-graph-attention-network-through-mpnn/:3:0","tags":["GNN","Deep-Learning","Paper"],"title":"用 MPNN 框架解读 GAT","uri":"/zh-cn/understanding-graph-attention-network-through-mpnn/"},{"categories":["GNN"],"content":"总结 以上就是如何用 MPNN 框架解释 GAT 的方法，其中加上了 DGL 的源码分析进行解释，用注意力计算节点之间的关系看起来是一个很自然的思路，可以看成是对 GCN 的一种泛化。GAT 能够很好学习到图的局部结构表示，而且计算注意力的方式可以并行，是十分高效的🍻🍻🍻 ","date":"2023-05-21","objectID":"/zh-cn/understanding-graph-attention-network-through-mpnn/:4:0","tags":["GNN","Deep-Learning","Paper"],"title":"用 MPNN 框架解读 GAT","uri":"/zh-cn/understanding-graph-attention-network-through-mpnn/"},{"categories":["GNN"],"content":"参考 Gilmer J, Schoenholz S S, Riley P F, et al. Neural message passing for quantum chemistry[C]//International conference on machine learning. PMLR, 2017: 1263-1272. arXiv ↩︎ Veličković P, Cucurull G, Casanova A, et al. Graph attention networks[J]. arXiv preprint arXiv:1710.10903, 2017. arXiv ↩︎ ↩︎ ↩︎ ","date":"2023-05-21","objectID":"/zh-cn/understanding-graph-attention-network-through-mpnn/:5:0","tags":["GNN","Deep-Learning","Paper"],"title":"用 MPNN 框架解读 GAT","uri":"/zh-cn/understanding-graph-attention-network-through-mpnn/"},{"categories":["Exercise"],"content":"SICP 练习 2.27 答案","date":"2023-05-16","objectID":"/zh-cn/sicp-exercise-2-27/","tags":["SICP","Racket"],"title":"SICP 练习 2.27","uri":"/zh-cn/sicp-exercise-2-27/"},{"categories":["Exercise"],"content":"题目 Modify your reverse procedure of exercise 2.18 to produce a deep-reverse procedure that taks a list as argument and returns as its value the list with its elements reversed and with all sublists deep-reversed as well. (define x (list (list 1 2) (list 3 4))) ;; x - ((1 2) (3 4)) (deep-reverse x) ;; the output should be ((4 3) (2 1)) ","date":"2023-05-16","objectID":"/zh-cn/sicp-exercise-2-27/:1:0","tags":["SICP","Racket"],"title":"SICP 练习 2.27","uri":"/zh-cn/sicp-exercise-2-27/"},{"categories":["Exercise"],"content":"答案 在前面的练习 2.18 中实现的 reverse 忽略了列表中的元素可能仍然是列表的情况。这里要求的实现的 deep-reverse 则要求我们递归式翻转整个列表。 我认为这题很好体现了如何设计一个递归程序的思想，基本上弄明白下面几点函数就不会出错 递归的 base case 是什么？对于列表来说，空列表很自然就是 base case，此时返回 '() 即可 接下来如何细分情况来递归调用？ 在细分情况之前，应该记住 car 和 cdr 的特点，(cdr l) 总是返回列表，(car l) 总是返回第一个元素（但不保证是否为原子项，即第一个元素也可能为列表） deep-reverse 有什么不变量（invariants）？根据题目所说，它的参数总是为列表 根据前面两点，我们已经不难得出细分情况的标准——即检查列表的第一个元素是否为原子项 代码如下 ;; invariants: the argument of deep-reverse are always a list (define (deep-reverse l) (cond ((null? l) '()) ;; base case (else (let ([remains (deep-reverse (cdr l))]) (if (pair? (car l)) ;; the arguments of append procedure should be lists too (append remains (list (deep-reverse (car l)))) (append remains (list (car l)))))))) 顺便附上一些测试用例 (deep-reverse '(2 3)) (deep-reverse '((2 3))) (deep-reverse '((2 3) 1)) (deep-reverse '(5 (2 3) 1)) (deep-reverse '((4 2) (2 3) 1)) (deep-reverse '(5 (2 3) (5 2))) 🚧 完整 SICP 练习题解仍在施工中 ","date":"2023-05-16","objectID":"/zh-cn/sicp-exercise-2-27/:2:0","tags":["SICP","Racket"],"title":"SICP 练习 2.27","uri":"/zh-cn/sicp-exercise-2-27/"},{"categories":["Exercise"],"content":"SICP 练习 1.46 答案","date":"2023-05-10","objectID":"/zh-cn/sicp-exercise-1-46/","tags":["SICP","Racket"],"title":"SICP 练习 1.46","uri":"/zh-cn/sicp-exercise-1-46/"},{"categories":["Exercise"],"content":"Question Several of the numerical methods described in this chapter are instances of an extremely general computational strategy known as iterative improvement. Iterative improvement says that, to compute something, we start with an initial guess for the answer, test if the guess is good enough, and otherwise improve the guess and continue the process using the improved guess as the new guess. Write a procedure iterative-improve that takes two procedures as arguments: a method for telling whether a guess is good enough and a method for improving a guess. Iterative-improve should return as its value a procedure that takes a guess as argument and keeps improving the guess until it is good enough. Rewrite the sqrt procedure of section 1.1.7 and the fixed-point procedure of section 1.3.3 in terms of iterative-improve. ","date":"2023-05-10","objectID":"/zh-cn/sicp-exercise-1-46/:1:0","tags":["SICP","Racket"],"title":"SICP 练习 1.46","uri":"/zh-cn/sicp-exercise-1-46/"},{"categories":["Exercise"],"content":"Answer 让我们总结一下题目要让我们做什么： 写一个函数，函数名为 iterative-improve，它包含了 2 个参数 第一个参数是函数，用于判断猜测是否足够好 第二个参数仍然是一个函数，用于改进猜测 用 iterative-improve 重写 fixed-point 和 sqrt 如果你一路做完了 SICP 第一章节的练习，那么你可以很轻松写出如下的代码: ;; test: test if a guess is good enough ;; improve: how to improve a guess (define (iterative-improve test improve) (lambda (guess) (if (test guess) guess ...))) 在函数里面用 lambda 返回另外一个函数很方便，但是这一道题要这么用有点“绕”，主要的困难来自于：我们要在 ... 的部分放什么？放 ((iterative-improve good-enough? improve) (improve guess)) 是可以的，但是我感觉这样写并不是很直观 这样的场景在写递归函数的时候其实经常出现，这种时候我们可以在主函数里面定义一个辅助函数，最后在主函数里面返回这个辅助函数即可。代码如下： (define (iterative-improve test improve) (define (helper guess) (if (test guess) guess (helper (improve guess)))) helper) 写完了 iterative-improve 之后，要重写 fixed-point 和 sqrt 函数是件很容易的事情。我们只需要定义好对应的 test 和 improve 是什么然后调用 iterative-improve (define (average x y) (/ (+ x y) 2)) (define (square x) (* x x)) (define (fixed-point f first-guess) ;; it's fine to refer a variable in the enclosing scope (define (close-enough? v) (let ([next (f v)]) (\u003c (abs (- v next)) 0.00001))) ((iterative-improve close-enough? f) first-guess)) (define (sqrt x) ;; it's fine to refer a variable in the enclosing scope (define (good-enough? v) (\u003c (abs (- (square v) x)) 0.001)) (define (improve guess) (average guess (/ x guess))) ((iterative-improve good-enough? improve) 1.0)) 🚧 完整 SICP 练习题解仍在施工中 ","date":"2023-05-10","objectID":"/zh-cn/sicp-exercise-1-46/:2:0","tags":["SICP","Racket"],"title":"SICP 练习 1.46","uri":"/zh-cn/sicp-exercise-1-46/"},{"categories":["Exercise"],"content":"SICP 练习 1.34 答案","date":"2023-05-09","objectID":"/zh-cn/sicp-exercise-1-34/","tags":["SICP","Racket"],"title":"SICP 练习 1.34","uri":"/zh-cn/sicp-exercise-1-34/"},{"categories":["Exercise"],"content":"题目 Suppose we define the procedure f. What happens if we (perversely) ask the interpreter to evaluate the combination (f f)? (define (square x) (* x x)) (define (f g) (g 2)) Then we have (f square) ;; 4 (f (lambda (z) (* z (+ z 1)))) ;; 6 = 2 * 3 ","date":"2023-05-09","objectID":"/zh-cn/sicp-exercise-1-34/:1:0","tags":["SICP","Racket"],"title":"SICP 练习 1.34","uri":"/zh-cn/sicp-exercise-1-34/"},{"categories":["Exercise"],"content":"答案 回忆之前书上讲的 applicative-order evaluation：我们需要先计算所有参数的值，然后将这些参数代入计算 第一步，先计算参数 f，过程如下 ;; replace g with f ;; (define (f g) ;; (g 2)) (f 2) 第二步：计算参数 2。注意这里的 2 被看成是参数而不是一个数字 ;; replace g with 2 ;; (define (f g) ;; (g 2)) (2 2) 最后就得到了 (2 2) 这个 S 表达式，它被看成是 function/procedure application。这也是求 S 表达式的值的方式 :) 但是，这里的 2 不是一个函数/过程，这也解释了为什么 Racket 输入了如下信息： application: not a procedure; expected a procedure that can be applied to arguments given: 2 🚧 完整 SICP 练习题解仍在施工中 ","date":"2023-05-09","objectID":"/zh-cn/sicp-exercise-1-34/:2:0","tags":["SICP","Racket"],"title":"SICP 练习 1.34","uri":"/zh-cn/sicp-exercise-1-34/"},{"categories":["Course"],"content":"CS61A 的项目四 - 实现一个 Scheme 解释器的题解","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/","tags":["Course","Python","Scheme"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/"},{"categories":["Course"],"content":"引言 最近正在跟着《Crafting interpreter》这本书写解释器，原本书里面用 Java 实现了一个 Tree-walker 解释器 jlox，我正在用 Python 重写一遍，称为 pylox。看了这本书感觉对解释器的理解越来越深刻了，很推荐👍。此时的我突然想起来之前看完的 CS61A 的 Scheme 解释器还有几个小问题没有解决，导致它一直是未完成的状态，于是今天我打开了这个项目，打算从头到尾捋一遍，讲讲思路。 注：Scheme 解释器这个项目比较大，所以我只复制了题目描述中的重要部分，完整的描述还是要回去看项目主页。同时代码只显示核心的部分。 ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:1:0","tags":["Course","Python","Scheme"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/"},{"categories":["Course"],"content":"Part 1. The Evaluator ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:2:0","tags":["Course","Python","Scheme"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/"},{"categories":["Course"],"content":"Problem 1 Implement the define and lookup methods of the Frame class…bindings is a dictionary representing the bindings in the frame…parent is the parent Frame instance…The environment for a Frame instance consists of that frame, its parent frame, and all its ancestor frames, including the Global Frame. define 函数很简单，就是一个字符串（symbol）到 Scheme 值（value）的映射，参数都给你写好了 lookup 函数的具体执行过程在本来的题目描述中已经列出来了，照着做就行，迭代和递归的解法都可以，我感觉迭代的解法会比较简单 ... def define(self, symbol, value): \"\"\"Define Scheme SYMBOL to have VALUE.\"\"\" self.bindings[symbol] = value def lookup(self, symbol): \"\"\"Return the value bound to SYMBOL. Errors if SYMBOL is not found.\"\"\" # Case 1. we check if the symbol is in the current frame if symbol in self.bindings.keys(): return self.bindings[symbol] else: # Case 2. we check the parent of the current frame repreatly pos = self.parent while pos is not None: if symbol in pos.bindings.keys(): return pos.bindings[symbol] pos = pos.parent # Case 3. we can't find the symbol raise SchemeError(\"unknown identifier: {0}\".format(symbol)) ... ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:2:1","tags":["Course","Python","Scheme"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/"},{"categories":["Course"],"content":"Problem 2 To be able to call built-in procedures, such as +, you need to complete the BuiltinProcedure case within the scheme_apply function in scheme_eval_apply.py. Built-in procedures are applied by calling a corresponding Python function that implements the procedure. 跟着题目的要求做即可，没有什么难度。值得一提的是要和 nil 判断而不是和 None 判断，不然你可能在第三题一直得到 “incorrect number of arguments…\"，我发现我之前没有做出来就是这里没写好 def scheme_apply(procedure, args, env): ... if isinstance(procedure, BuiltinProcedure): # Convert the Scheme list to a Python list of arguments args_list = [] pos = args while pos is not nil: if pos.first is not nil: args_list.append(pos.first) else: args_list.append(nil) pos = pos.rest # Add the current environment if procedure.expect_env == True if procedure.expect_env: args_list.append(env) # Call procedure.py_func on all arguments try: return procedure.py_func(*args_list) except TypeError as e: raise SchemeError(f\"incorrect number of arguments, {e}\") ... ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:2:2","tags":["Course","Python","Scheme"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/"},{"categories":["Course"],"content":"Problem 3 Implement the missing part of scheme_eval, which evaluates a call expression…You’ll have to recursively call scheme_eval in the first two steps…The map method of Pair returns a new Scheme list constructed by applying a one-argument function to every item in a Scheme list…Important: do not mutate the passed-in expr. That would change a program as it’s being evaluated, creating strange and incorrect effects. 这一道题也很直白，可能的一个难点是，rest.map 的参数是一个 “one-argument function”，也就是只接受一个参数，但是题目提供的 scheme_eval 有 2 个参数。所以需要对函数进行转化，当然这里可以写一个 lambda 表达式包装一下 scheme_eval。我选择用 functools 包提供的 partial 函数，它的用途就是绑定函数的部分参数并返回一个新的函数。第一次见到 partial 这种用法还是在函数式编程语言里面，不少函数式编程语言都是原生就支持这个功能。 def scheme_eval(expr, env, _=None): # Optional third argument is ignored ... else: # Evaluate the operator(first argument) operator = scheme_eval(first, env) validate_procedure(operator) # Evaluate all of the operands(other arguments) from functools import partial operands = rest.map(partial(scheme_eval, env=env)) return scheme_apply(operator, operands, env) ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:2:3","tags":["Course","Python","Scheme"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/"},{"categories":["Course"],"content":"Problem 4 The type of the first operand tells us what is being defined…implement just the first part, which evaluates the second operand to obtain a value and binds the first operand, a symbol, to that value. Then, do_define_form returns the symbol that was bound. 这里只要求实现 define 的第一个功能——绑定变量，具体绑定的方式其实我们已经在 Problem 1 里面实现好了，就是 Frame 类的 define 方法，因此绑定变量只要调用 env.define 即可。 根据 define 绑定变量的写法: (define a some_val)，可以通过 .rest.first 拿到对应的 some_val 用 scheme_eval 进行估值 def do_define_form(expressions, env): ... if scheme_symbolp(signature): # assigning a name to a value e.g. (define x (+ 1 2)) validate_form( expressions, 2, 2 ) # Checks that expressions is a list of length exactly 2 env.define(signature, scheme_eval(expressions.rest.first, env)) return signature ... ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:2:4","tags":["Course","Python","Scheme"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/"},{"categories":["Course"],"content":"Problem 5 Implement the do_quote_form function in scheme_forms.py so that it simply returns the unevaluated operand of the (quote ...) expression. validate_form(expressions, 1, 1) 确保输入长度为 1，即检查是否为 '... 形式，我们只需要直接返回即可 def do_quote_form(expressions, env): validate_form(expressions, 1, 1) return expressions.first ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:2:5","tags":["Course","Python","Scheme"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/"},{"categories":["Course"],"content":"Part 2. Procedures ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:3:0","tags":["Course","Python","Scheme"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/"},{"categories":["Course"],"content":"Problem 6 Change the eval_all function in scheme_eval_apply.py (which is called from do_begin_form in scheme_forms.py) to complete the implementation of the begin special form (spec). A begin expression is evaluated by evaluating all sub-expressions in order. The value of the begin expression is the value of the final sub-expression. 其实这是一个递归的过程： 先检查 expressions 是否为 nil，是的话返回 None 表示没有定义 继续检查 expressions.rest 是否为 nil，是的话返回 expressions.first 的评估结果，否则继续递归调用 def eval_all(expressions, env): if expressions is nil: return None res = scheme_eval(expressions.first, env) if expressions.rest is nil: return res else: return eval_all(expressions.rest, env) ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:3:1","tags":["Course","Python","Scheme"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/"},{"categories":["Course"],"content":"Problem 7 Implement the do_lambda_form function (spec), which creates and returns a LambdaProcedure instance 在 Problem 6 里面已经说了 LambdaProcedure 的结构，调用一下它的构造函数就行 def do_lambda_form(expressions, env): validate_form(expressions, 2) formals = expressions.first validate_formals(formals) return LambdaProcedure(formals, expressions.rest, env) ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:3:2","tags":["Course","Python","Scheme"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/"},{"categories":["Course"],"content":"Problem 8 This method takes in two arguments: formals, which is a Scheme list of symbols, and vals, which is a Scheme list of values. It should return a new child frame, binding the formal parameters to the values. 题目的步骤已经够详细了，这里就不展开了 def make_child_frame(self, formals, vals): if len(formals) != len(vals): raise SchemeError(\"Incorrect number of arguments to function call\") sub_frame = Frame(self) # iterate pos1, pos2 = formals, vals while pos1 is not nil: key, value = pos1.first, pos2.first sub_frame.define(key, value) pos1, pos2 = pos1.rest, pos2.rest return sub_frame ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:3:3","tags":["Course","Python","Scheme"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/"},{"categories":["Course"],"content":"Problem 9 You should first create a new Frame instance using the make_child_frame method of the appropriate parent frame, binding formal parameters to argument values. Then, evaluate each of the expressions of the body of the procedure using eval_all within this new frame. 这里刚好用了 Problem 8 写的 make_child_frame 函数 def scheme_apply(procedure, args, env): ... elif isinstance(procedure, LambdaProcedure): child_frame = procedure.env.make_child_frame(procedure.formals, args) return eval_all(procedure.body, child_frame) ... ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:3:4","tags":["Course","Python","Scheme"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/"},{"categories":["Course"],"content":"Problem 10 Modify the do_define_form function in scheme_forms.py so that it correctly handles define (...) ...) expressions 和之前的相比，差别主要在 env.define 的第 2 个参数，用前面写好的 do_lambda_form 或者直接调用 LambdaProcedure 也可以 def do_define_form(expressions, env): ... elif isinstance(signature, Pair) and scheme_symbolp(signature.first): # defining a named procedure e.g. (define (f x y) (+ x y)) # the signature is (f x y) formals = signature.rest # (x y) validate_formals(formals) # now we need to parse (+ x y) env.define(signature.first, LambdaProcedure(formals, expressions.rest, env)) return signature.first # f ... ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:3:5","tags":["Course","Python","Scheme"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/"},{"categories":["Course"],"content":"Problem 11 Implement do_mu_form in scheme_forms.py to evaluate the mu special form. A mu expression evaluates to a MuProcedure. Most of the MuProcedure class (defined in scheme_classes.py) has been provided for you. MuProcedure 的特别之处在于 dynamic scoping，参数的值取决于调用的时候环境里面有什么。scheme_apply 函数的参数 env 就表示了当前环境，我们只需要构造一个 child frame 并在里面评估 MuProcedure 即可 def scheme_apply(procedure, args, env): ... elif isinstance(procedure, MuProcedure): child_frame = env.make_child_frame(procedure.formals, args) return eval_all(procedure.body, child_frame) ... def do_mu_form(expressions, env): validate_form(expressions, 2) formals = expressions.first validate_formals(formals) return MuProcedure(formals, expressions.rest) ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:3:6","tags":["Course","Python","Scheme"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/"},{"categories":["Course"],"content":"Part 3. Special Forms ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:4:0","tags":["Course","Python","Scheme"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/"},{"categories":["Course"],"content":"Problem 12 Implement do_and_form and do_or_form so that and and or expressions are evaluated correctly. The logical forms and and or are short-circuiting do_and_form 和 do_or_form 都可以用递归写： do_and_form：base case 为 nil 此时返回为 True，从头到尾检查，一旦发现不为 True 的就立刻返回 do_or_form：base case 为 nil 此时返回 False，从头到尾检查，一旦发现为 True 的就立刻返回 def do_and_form(expressions, env): # base case: (and) if expressions is nil: return True front = scheme_eval(expressions.first, env) if is_scheme_true(front): if expressions.rest is nil: return front else: return do_and_form(expressions.rest, env) else: return front def do_or_form(expressions, env): # base case: (or) if expressions is nil: return False front = scheme_eval(expressions.first, env) if is_scheme_false(front): if expressions.rest is nil: return front else: return do_or_form(expressions.rest, env) else: return front ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:4:1","tags":["Course","Python","Scheme"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/"},{"categories":["Course"],"content":"Problem 13 Fill in the missing parts of do_cond_form so that it correctly implements cond, returning the value of the first result sub-expression corresponding to a true predicate, or the result sub-expression corresponding to else. 按照题目的意思来就行 def do_cond_form(expressions, env): ... if is_scheme_true(test): # no sub-expression if clause.rest is nil: return test return eval_all(clause.rest, env) ... ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:4:2","tags":["Course","Python","Scheme"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/"},{"categories":["Course"],"content":"Problem 14 Implement make_let_frame in scheme_forms.py, which returns a child frame of env that binds the symbol in each element of bindings to the value of its corresponding expression. The bindings Scheme list contains pairs that each contain a symbol and a corresponding expression. 遍历每一个 binding，收集参数名和值到 names 和 values 就行 def make_let_frame(bindings, env): if not scheme_listp(bindings): raise SchemeError(\"bad bindings list in let form\") names = values = nil # bingding: (\u003cname\u003e \u003cexpression\u003e) # bingdings: ( (\u003cname1\u003e \u003cexpression1\u003e) (\u003cname2\u003e \u003cexpression2\u003e) ...) pos = bindings while pos is not nil: front = pos.first # i.e. the first binding validate_form(front, 2, 2) # verify the structure is (\u003cname\u003e \u003cexpression\u003e) names = Pair(front.first, names) values = Pair(eval_all(front.rest, env), values) pos = pos.rest validate_formals(names) return = env.make_child_frame(names, values) ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:4:3","tags":["Course","Python","Scheme"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/"},{"categories":["Course"],"content":"Problem 15 Implement the enumerate procedure, which takes in a list of values and returns a list of two-element lists, where the first element is the index of the value, and the second element is the value itself. 通过递归就可以实现，在下面我实现了一个 helper 递归函数，参数是输入 input 和索引 index： base case：输入 input 为空，则返回 '() 其他情况：递归调用，注意参数变化：input -\u003e (cdr input) 和 index -\u003e (+ index 1) (define (enumerate s) (begin ;; a helper funtion (define (helper input index) (cond ((null? input) '()) ;; base case: return () if it is nil (else (cons (cons index (cons (car input) nil)) (helper (cdr input) (+ index 1)))))) ;; recursive call (helper s 0)) ) ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:4:4","tags":["Course","Python","Scheme"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/"},{"categories":["Course"],"content":"Problem 16 Implement the merge procedure, which takes in a comparator function inorder? and two lists that are sorted, and combines the two lists into a single sorted list. A comparator defines an ordering by comparing two values and returning a true value if and only if the two values are ordered. Here, sorted means sorted according to the comparator 经典算法：合并 2 个有序列表，每次取出 2 个列表的头个元素，对应下面的 (car list1) (car list2)，然后进行比较，根据不同情况进行递归调用 (define (merge inorder? list1 list2) (cond ((null? list1) list2) ;; base case: list1 is empty ((null? list2) list1) ;; base case: list2 is empty ((inorder? (car list1) (car list2)) (cons (car list1) (merge inorder? (cdr list1) list2))) ;; consume list1 (else (cons (car list2) (merge inorder? list1 (cdr list2))))) ;; consume list2 ) ","date":"2023-04-21","objectID":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/:4:5","tags":["Course","Python","Scheme"],"title":"CS61A 的项目四之 Scheme 解释器实现 (2021-Fall)","uri":"/zh-cn/proj4-scheme-interpreter-of-cs61a-of-ucb-fa21/"},{"categories":["Algorithm"],"content":"介绍了 MIT6.006 里面提到的 SRTBOT 框架，用于解决动态规划问题","date":"2023-04-09","objectID":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/","tags":["Algorithm"],"title":"用 SRTBOT 框架分析动态规划问题","uri":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/"},{"categories":["Algorithm"],"content":"Changelog: 更新依赖图 @2023.04.13 ","date":"2023-04-09","objectID":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/:0:0","tags":["Algorithm"],"title":"用 SRTBOT 框架分析动态规划问题","uri":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/"},{"categories":["Algorithm"],"content":"引言 在做算法题的时候，让我头疼的经常是动态规划问题，它属于那种自己琢磨半天想不出来，但是看了答案之后会恍然大悟，下次再做的话很有可能又忘记了的一类问题。我也曾经看了很多人的题解，试图消化、吸收、应用他们的思路，但我一直找不到一个归纳得特别好的框架，似乎每个人都有自己解决动态规划的思路，将他们的思路应用在没有见过的动态规划问题的时候我总是遇到困难，而他们的方法轮似乎也无法让我处理所有的动态规划问题。这种寻寻觅觅对动态规划似懂非懂的状态，终于在我看完 MIT6.006 的课程之后发生了改变，课上老师提出了解决动态规划问题的 6 个步骤——被称为 SRTBOT 框架，我发现它是如此地好用，因此我决定写下这篇博客来与大家分享🙌 👉 总的来说，这篇博客更适合已经对动态规划有了初步了解但是还没有找到系统方法论人的阅读 ","date":"2023-04-09","objectID":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/:1:0","tags":["Algorithm"],"title":"用 SRTBOT 框架分析动态规划问题","uri":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/"},{"categories":["Algorithm"],"content":"什么是动态规划问题 动态规划问题的两大特征：重叠子问题和最优子结构1 重叠子问题：解决一个动态规划问题往往是将它分解为若干个重叠的子问题 最优子结构：即大问题的解可以通过组合小问题的最优解计算出来 前面的定义要特别注意的是「重叠」以及「子问题」，强调重叠是因为动态规划的厉害之处就在于它会记住解决过的子问题的答案，那么重叠的子问题越多，动态规划的优势更加明显 🤔️ 如果子问题并不重叠，那么就应该用分治法解决 上面是从定义的角度来谈动态规划问题的，从编程题目的角度来看，下面两大类问题一般都是要用动态规划算法： 最优化问题：求最值 + 重叠子问题 组合问题：求解所有可能的解法的数量 📒 或者，根据我的个人刷题经验来说：动态规划问题一般是可以暴力解决的递归问题，但是存在大量重叠子问题因此可以对其进行优化 ","date":"2023-04-09","objectID":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/:2:0","tags":["Algorithm"],"title":"用 SRTBOT 框架分析动态规划问题","uri":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/"},{"categories":["Algorithm"],"content":"SRTBOT 框架 SRTBOT 是 6 个步骤的首字母缩写，分别是2： Subproblems definition Relate subproblem solutions recursively Topological order to argue relation is acyclic and subproblems form a DAG Base cases Original problem Time analysis 下面我来分别讲讲上面每一个步骤需要做些什么✈️ ","date":"2023-04-09","objectID":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/:3:0","tags":["Algorithm"],"title":"用 SRTBOT 框架分析动态规划问题","uri":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/"},{"categories":["Algorithm"],"content":"定义子问题（Subproblems definition） 包含下面几个步骤 定义子问题并用文字描述其含义，这里定义的子问题会包含参数。具体定义子问题的技巧会在后面提到 子问题的参数一般包含输入的子集，不同的动态规划问题可能有不同的输入格式：二叉树、单序列、数字等 在设计子问题的时候可以参考下面几种： 如果输入是单个序列 A 前缀形式（Prefix form）：定义 dp[i] 表示输入为 A[:i+1] 的子问题的解，注意这里的区间表示是基于 Python 的，左闭右开 后缀形式（Suffix form）：定义 dp[i] 表示输入为 A[i:] 的子问题的解 子串形式（Contiguous substrings of a sequence）：定义 dp[i][j] 表示输入为 A[i:j+1] 的子问题的解 如果输入是两个序列 A 和 B 为之前 3 种可能的笛卡尔乘积，一共有 $3\\times 3=9$ 种，视具体情况而定 比如最长公共子序列的问题，可以用 dp[i][j] 表示输入为 A[:i+1] 和 B[:i+1] 的最长公共子序列 如果输入是一个数字 k 定义 dp[k] 为输入为 k 的子问题的解 如果输入是一棵二叉树 定义 dp[r] 为输入为以 r 为根节点的子树的这个子问题的解。在树形 DP 中要注意「子问题」和「子树」这个对应的关系 📒 进阶：掌握了上面的一般思路之后，其实已经能够解决很多动态规划问题，但你有时候会发现你定义的子问题不够精确，导致难以无法关联子问题，当你在关联子问题有困难的时候总是可以尝试给你定义的子问题加上约束，或者是对子问题进行扩展。在 MIT 6.006 中称为 Subproblem Constraints and Expansion 对子问题进行扩展会更为常见一些，一般此时就是将定义的 dp[i] 变成 dp[i][j] 这样的形式，同时修改你的子问题定义。举例来说，在 198. 打家劫舍 中可以考虑额外引入一个状态记住是否偷了房屋 i 也稍微提一下对子问题的定义加上限制是什么意思，比如我们定义 dp[i] 是输入为 A[:i+1] 的解，假设每个 A[i] 存在选中与不选中两个状态，那么可以考虑将 dp[i] 定义为 输入为 A[:i+1] 而且 A[i] 一定是选中状态的时候的解（这么说可能有点抽象，待我之后找到可以这样处理的问题后贴个链接在这） 📒 你会发现，定义子问题的时候我们根本不会去思考要如何计算出来，千万不要在定义子问题的时候就开始想要怎么计算出这个值，当你使用 SRTBOT 框架分析到最后，你就自然而然知道怎么计算了~ ","date":"2023-04-09","objectID":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/:3:1","tags":["Algorithm"],"title":"用 SRTBOT 框架分析动态规划问题","uri":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/"},{"categories":["Algorithm"],"content":"递归式关联子问题（Relate subproblem solutions recursively） 试着提出一个问题——如果你知道这个问题的答案，你就能够将这个大问题分解为更小的子问题。可能用数学公式表述会更明显一点： $$ dp[i] = f(dp[j_1],dp[j_2], …, dp[j_k])\\ where\\ j_k \u003ci $$ 其中 $f$ 是一个抽象的操作，即「大问题」和「小问题」的关联方式 上面提出的问题的答案一般就是“局部暴力枚举”，这也是我们关联不同子问题的主要手段。方法是：看问题描述，从中归纳出允许的“决策”，“决策”会导致我们从一个子问题转移到另外一个子问题。思考的时候注意力放在 nums[i]、更小的子问题 dp[j_k] 和可行的决策这三者上 👻 如果一开始做动态规划想不出来也没关系，这东西熟练了之后就比较容易想到不同子问题如何通过不同的决策关联起来 🤔️ 我发现，在想办法递归关联子问题的时候，画出依赖图总是能给我很大帮助（结点为子问题，边为“决策”），依赖图不仅清晰展示了子问题之间的关联方式，还可以验证有重叠子问题出现 dp[i] (apply f to aggregate results) / | \\ (?)/ |(?) \\(?) / | \\ dp[j_1] dp[j_2] ... / \\ / \\ / \\ ... ... ... ... ... 举例来说，在 70. 爬楼梯 问题中，每次只能爬一个台阶或者两个台阶（$K=2$），那么爬到第 i 个台阶一定是从第 i - 1 个台阶和第 i - 2 个台阶过来的，又因为求解的是所有可能的走法，因此 dp[i] = dp[i - 1] + dp[i - 2]，画出依赖图如下 dp[i] (sum) / \\ (climb one step)/ \\(climb two steps) / \\ dp[i - 1] dp[i - 2] / \\ / \\ ... ...... ... 🤔️ 可以通过这个例子理解“局部暴力枚举”中的“局部”的含义：我们只考虑做一次决策，比如上面爬楼梯，每次爬一个台阶最后连续爬 n 个台阶 关联 dp[i] 和 dp[i - n] 这种方式就不是局部 ","date":"2023-04-09","objectID":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/:3:2","tags":["Algorithm"],"title":"用 SRTBOT 框架分析动态规划问题","uri":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/"},{"categories":["Algorithm"],"content":"根据拓扑排序确定解决子问题的顺序（Topological order to argue relation is acyclic and subproblems form a DAG） 你可能在别的地方看到过动态规划问题的另外一个名字——“表格法”。因为当我们采用“自底向上”的解法解决动态规划问题的时候可以看成是在填表格。但在我看来，将动态规划看成一张有向无环图会更有助于对动态规划的理解——将子问题看成是图上的顶点，用有向边连接「小的子问题」-\u003e 「大的子问题」，这个图会构成一个有向无环图（DAG），动态规划算法其实就是 DAG 的拓扑排序过程。即「DAG 拓扑排序」=「自底向上方法」=「表格法」。上面的依赖图“自底向上”就是在做拓扑排序 🤔️ 为什么是有向无环图？首先，有向边表示了子问题之间的依赖关系也表示了我们求解子问题的顺序：要解决一个子问题，需要先求解出更小的子问题；其次，它必须是无环的，因为动态规划会记住求解过的子问题，我们不可能多次求解同一个子问题，因此它必须是无环的。 意识到动态规划的子问题求解顺序是 DAG 的拓扑排序有什么用呢？这在很大程度上帮我理解了树形 DP 问题：动态规划要先求解子问题 – 在树形 DP 中，显然“子树”和“子问题”的概念是对应的，因此要先解决子问题其实意味着计算 dp[r] 的时候应该先计算 dp[r.left] 和 dp[r.right]，而这恰恰遵循了二叉树的后序遍历顺序，因此树形 DP 问题往往是通过后序遍历实现的。如果把树看成图的话（注意边由孩子结点指向父节点），那么拓扑排序也是和后序遍历的顺序对应的 🤔️ 实际写代码的时候，你可能对如何用正确的顺序更新子问题有疑问，只要记住永远都是先解决小问题，然后才到大问题，再看一眼前面定义的关系式，你就知道更新顺序是什么了 ","date":"2023-04-09","objectID":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/:3:3","tags":["Algorithm"],"title":"用 SRTBOT 框架分析动态规划问题","uri":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/"},{"categories":["Algorithm"],"content":"边界情况（Base cases） 类似递归算法中的 base case，表示独立的最小子问题的解，是关系式推导的起点，这种信息一般可以通过看题目看出来 ","date":"2023-04-09","objectID":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/:3:4","tags":["Algorithm"],"title":"用 SRTBOT 框架分析动态规划问题","uri":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/"},{"categories":["Algorithm"],"content":"原始问题（Original problem） 通常来说，原问题一般都对应 dp[n] 或者 dp[0]，但是不要死记硬背，还是要结合题意、你定义的子问题形式。但不必担心，因为这一步通常不是求解动态规划问题的难点 ","date":"2023-04-09","objectID":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/:3:5","tags":["Algorithm"],"title":"用 SRTBOT 框架分析动态规划问题","uri":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/"},{"categories":["Algorithm"],"content":"时间复杂度分析（Time analysis） 动态规划算法就是求解所有需要求解的子问题，然后计算原始问题，假设一共有 $n$ 个子问题要求解，那么动态规划的时间复杂度可以用下面这个公式解决： $$ n * O(each\\ subproblem) + O(original\\ problem) $$ ","date":"2023-04-09","objectID":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/:3:6","tags":["Algorithm"],"title":"用 SRTBOT 框架分析动态规划问题","uri":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/"},{"categories":["Algorithm"],"content":"应用 光是谈理论总是一知半解，只有真正开始把 SRTBOT 框架应用于动态规划问题才能够体会它的强大之处，下面是我整理的部分动态规划问题的题解，在题解里面我会谈到如何用 SRTBOT 分析动态规划问题。后序会不断把做的动态规划的题目搬运到这里来，或者也可以直接看 Leetcode 账号查看题解👻 📒 注：我的解法并不一定是最优的解法，比如有时候可以用「状态压缩」的技巧减少空间复杂度等，我可能并不会这么做，我只是将 SRTBOT 框架应用于这些动态规划问题 Problem Solution Note 70. 爬楼梯 题解 数 746. 使用最小花费爬楼梯 题解 单序列 198. 打家劫舍 题解 单序列 + 扩展子问题 322. 零钱兑换 题解 数 + 非$O(1)$ 子问题 300. 最长递增子序列 题解 单序列 + 限制子问题 5. 最长回文子串 题解 子串 91. 解码方法 题解 单序列 139. 单词拆分 题解 单序列 279. 完全平方数 题解 单数字 673. 最长递增子序列的个数 题解 单序列 62. 不同路径 题解 网格 1143. 最长公共子序列 题解 双序列 + 扩展子问题 309. 最佳买卖股票时机含冷冻期 题解 单序列 + 扩展子问题 1911. 最大子序列交替和 题解 单序列 + 扩展子问题 1220. 统计元音字母序列的数目 题解 数 + 扩展子问题 ","date":"2023-04-09","objectID":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/:4:0","tags":["Algorithm"],"title":"用 SRTBOT 框架分析动态规划问题","uri":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/"},{"categories":["Algorithm"],"content":"参考 Dynamic programming - Wiki ↩︎ Lecture 15 ~ 18 of MIT 6.006 ↩︎ ","date":"2023-04-09","objectID":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/:5:0","tags":["Algorithm"],"title":"用 SRTBOT 框架分析动态规划问题","uri":"/zh-cn/solving-dynamic-programming-problems-using-srtbot/"},{"categories":["ML-DL"],"content":"推导了深度学习中的反向传播算法的公式，并讨论了如何理解","date":"2023-04-04","objectID":"/zh-cn/backpropagation-tutorial/","tags":["Deep-Learning"],"title":"反向传播公式推导和理解","uri":"/zh-cn/backpropagation-tutorial/"},{"categories":["ML-DL"],"content":" 更新：矩阵形式的反向传播可以看 这里 ","date":"2023-04-04","objectID":"/zh-cn/backpropagation-tutorial/:0:0","tags":["Deep-Learning"],"title":"反向传播公式推导和理解","uri":"/zh-cn/backpropagation-tutorial/"},{"categories":["ML-DL"],"content":"引言 在深度学习中，模型的优化是通过采用梯度下降法不断更新权重和偏置项，让损失越来越小。其中的核心就是反向传播算法。回忆梯度下降的公式，用 $\\theta$ 表示模型所有可学习的参数，$J$ 表示损失函数，$\\alpha$ 表示学习率，那么有 $$ \\theta \\leftarrow \\theta - \\alpha * \\frac{\\partial J}{\\partial \\theta} $$ 反向传播要求解的就是上面式子中 $\\frac{\\partial J}{\\partial \\theta}$ 这一项。只有正确高效计算出梯度，模型才可以沿着梯度的负方向更新不断优化。 📒 本文会交叉使用「参数」和「权重和偏置项」这两个术语，他们是同一个意思，都表示了模型可以学习的参数 📒 本文假定你对数学上的求导链式法则等有所了解🫡 ","date":"2023-04-04","objectID":"/zh-cn/backpropagation-tutorial/:1:0","tags":["Deep-Learning"],"title":"反向传播公式推导和理解","uri":"/zh-cn/backpropagation-tutorial/"},{"categories":["ML-DL"],"content":"模型假设 本文要讲解反向传播，那么当然要定义一个模型用于之后的推导，考虑一个简单然而很经典的三层全连接层，如下所示: 📒 为了记号方便，大写字母表示矩阵，小写字母表示向量（无下标）或者标量（有下标） 并规定如下记号： 不同层的神经元个数：输入层有 $n$ 个神经元，隐藏层有 $h$ 个神经元，输出层有 $k$ 个神经元 $x^1_j$ 表示输入的第 $j$ 个特征。记输入层第 $1$ 层 $y_j$ 表示对应输出层的第 $j$ 个输出的真实值 $w^l_{jk}$ 表示第 $l-1$ 层的第 $k$ 个神经元和第 $l$ 层的第 $j$ 个神经元这个链接对应的权重，注意这里的下角标是从后面指向前面。根据前面的隐藏层大小，可以算出权重矩阵的大小为： $W^2\\in \\mathcal{R}^{h\\times n}$ $W^3\\in \\mathcal{R}^{k\\times h}$ $b_j^l$ 表示第 $l$ 层的第 $j$ 个神经元的偏置项 $z_j^l$ 表示第 $l$ 层的第 $j$ 个神经元计算的加权和 $a_j^l$ 表示第 $l$ 层的第 $j$ 个神经元的激活函数输出值 根据上面的记号，模型的前向传播的公式如下： $$ z_j^2 = \\sum_kw_{jk}^2x^1_k+b_j^2 $$ $$ a_j^2=\\sigma(z_j^2) $$ $$ z_j^3 = \\sum_kw_{jk}^3a_k^2+b_j^3 $$ $$ a_j^3=\\sigma(z_j^3) $$ 更一般的，可以对上面的公式进行概括。$z_j^l$ 和 $a_j^l$ 的计算方式如下： $$ z_j^l=\\sum_kw_{jk}^la^{l-1}_k+b_j^l $$ $$ a_j^l=\\sigma(z_j^l) $$ 上面这两个公式很重要，特别要弄清楚式子的下标和上标的关系，他们在之后的反向传播的公式推导中会很有用 这里考虑用均值平方误差即 MSE 作为损失函数 $J$，$sigmoid$ 函数作为激活函数，当然这两个换成别的函数的话推导过程也是类似的 $$ J = \\frac{1}{2k}\\sum_{j=1}^k(a_j^L-y_j)^2 $$ ","date":"2023-04-04","objectID":"/zh-cn/backpropagation-tutorial/:2:0","tags":["Deep-Learning"],"title":"反向传播公式推导和理解","uri":"/zh-cn/backpropagation-tutorial/"},{"categories":["ML-DL"],"content":"反向传播的直觉理解 我发现，在深入了解细节之前，从高层次的角度理解一个概念总是能带来帮助。我们知道，深度学习模型的训练过程就是要让模型的预测 $a^L_j$ 越接近真实值 $y_j$ 越好。那么 $a^L_j$ 跟什么有关呢？根据样本的真实值 $y_j$，可以计算 $a^L_j$ 和 $y_j$ 的误差，计算出误差之后，我们肯定知道要增大还是减小 $a^L_j$ 才能让模型的预测更好。而我们能够改变的量只有：第 $L - 1$ 层和第 $L$ 层之间的每个权重 $w^L_{jk}$，偏置项 $b_j^L$，或者是第 $L-1$ 层的激活函数的输出值 $a^{L-1}_k$，但是 $a_k^{L-1}$ 并无法直接改变，它是由更前面的权重和偏置项的值决定的。当我们从后往前根据预测的误差，考虑要如何修改每一层的权重和偏置项的时候，就是在做反向传播1。 上述过程解释了 $a_j^L$ 想要如何调整模型的权重和偏置项。当然，我们还需要考虑输出层中除了$a_j^L$ 以外的神经元的“意见”。他们各自对如何改变模型的权重和偏置项的“意见”并不一定相同。最后，我们需要考虑输出层中所有神经元的意见来更新模型的权重和偏差 ","date":"2023-04-04","objectID":"/zh-cn/backpropagation-tutorial/:3:0","tags":["Deep-Learning"],"title":"反向传播公式推导和理解","uri":"/zh-cn/backpropagation-tutorial/"},{"categories":["ML-DL"],"content":"反向传播的四个公式 反向传播的核心就是下面四个公式 ","date":"2023-04-04","objectID":"/zh-cn/backpropagation-tutorial/:4:0","tags":["Deep-Learning"],"title":"反向传播公式推导和理解","uri":"/zh-cn/backpropagation-tutorial/"},{"categories":["ML-DL"],"content":"公式一 $$ \\delta_j^L=\\frac{\\partial J}{\\partial a_j^L}\\sigma’(z_j^L) $$ 其中 $L$ 为模型的层数，在我们前面定义的模型中 $L=3$，$\\delta_j^L$ 表示第 $L$ 层即输出层的第 $j$ 个神经元的梯度信息 顺带一提，用矩阵和向量的角度可以把上面的公式改写为$\\delta^L=\\nabla J\\odot \\sigma’(z^L)$。其中 $\\odot$ 表示按元素（element-wise）乘 📒 公式一计算的是输出层的每个神经元的梯度 推导过程⬇️ $$ \\begin{aligned} \\delta_j^L\u0026=\\frac{\\partial J}{\\partial z_j^L} \\\\\\ \u0026=\\sum_k\\frac{\\partial J}{\\partial a_k^L}\\frac{\\partial a_k^L}{\\partial z_j^L} \\\\\\ \u0026=\\frac{\\partial J}{\\partial a_j^L}\\frac{\\partial a_j^L}{\\partial z_j^L}\\ (only\\ \\frac{\\partial a_j^L}{\\partial z_j^L}\\ne 0) \\\\\\ \u0026=\\frac{\\partial J}{\\partial a_j^L}\\frac{\\partial \\sigma(z_j^L)}{\\partial z_j^L}\\ \\\\\\ \u0026=\\frac{\\partial J}{\\partial a_j^L}\\sigma’(z_j^L) \\end{aligned} $$ ","date":"2023-04-04","objectID":"/zh-cn/backpropagation-tutorial/:4:1","tags":["Deep-Learning"],"title":"反向传播公式推导和理解","uri":"/zh-cn/backpropagation-tutorial/"},{"categories":["ML-DL"],"content":"公式二 $$ \\delta^l=((w^{l+1})^T\\delta^{l+1})\\odot \\sigma’(z^l) $$ 📒 公式二计算的是任意层 $l$ 的梯度向量，注意这个公式如何将第 $l$ 层的梯度向量和第 $l+1$ 的梯度向量联系起来。它让我们可以用后面的层的梯度向量计算前面的层的梯度向量 推导过程⬇️ $$ \\begin{aligned} \\delta_j^l\u0026=\\frac{\\partial J}{\\partial z_j^l} \\\\\\ \u0026=\\sum_k\\frac{\\partial J}{\\partial z_k^{l+1}}\\frac{\\partial z_k^{l+1}}{\\partial z_j^l} \\\\\\ \u0026=\\sum_k\\delta_k^{l+1}\\frac{\\partial }{\\partial z_j^l}z_k^{l+1} \\end{aligned} $$ 注意其中 $\\frac{\\partial }{\\partial z_j^l}z_k^{l+1} = \\frac{\\partial }{\\partial z_j^l}\\ \\sum_pw^{l+1}_{kp}\\sigma(z_p^l)+b^{l+1}_k$ 只有当 $p=j$ 的时候才可导，因此上面公式的解是 $w^{l+1}_{kj}\\sigma’(z_j^l)$ 即，我们证明了$\\delta_j^l=\\sum_k\\delta_k^{l+1}\\ w^{l+1}_{kj}\\sigma’(z_j^l)$ $\\sum_k\\delta_k^{l+1}w^{l+1}_{kj}$ 其实就是计算 2 个向量的内积，因此可以将其改写为向量形式 - $\\delta^l=((w^{l+1})^T\\delta^{l+1})\\odot \\sigma’(z^l)$ ","date":"2023-04-04","objectID":"/zh-cn/backpropagation-tutorial/:4:2","tags":["Deep-Learning"],"title":"反向传播公式推导和理解","uri":"/zh-cn/backpropagation-tutorial/"},{"categories":["ML-DL"],"content":"公式三 $$ \\frac{\\partial J}{\\partial b^l_j}=\\delta_j^l $$ 📒 公式三可以用来计算模型中任意一个权重的梯度 推导过程⬇️ $$ \\begin{aligned} \\frac{\\partial J}{\\partial b^l_j}\u0026= \\frac{\\partial J}{\\partial z^l_j}\\frac{\\partial z^l_j}{\\partial b^l_j} \\\\\\ \u0026= \\delta_j^l \\frac{\\partial}{\\partial b^l_j}\\sum_kw^l_{jk}a^{l-1}_j+b^l_j\\\\\\ \u0026= \\delta_j^l \\end{aligned} $$ 注意上面的第一个等号和公式一的推导类似，我直接跳过了去掉 $\\sum_k$ 的过程 ","date":"2023-04-04","objectID":"/zh-cn/backpropagation-tutorial/:4:3","tags":["Deep-Learning"],"title":"反向传播公式推导和理解","uri":"/zh-cn/backpropagation-tutorial/"},{"categories":["ML-DL"],"content":"公式四 $$ \\frac{\\partial J}{\\partial w_{jk}^l}=a_k^{l-1}\\delta_j^l $$ 📒 公式四可以用来计算模型中任意一个偏置项的梯度 推导过程⬇️ $$ \\begin{aligned} \\frac{\\partial J}{\\partial w_{jk}^l}\u0026=\\frac{\\partial J}{\\partial z^l_j}\\frac{\\partial z^l_j}{\\partial w_{jk}^l} \\\\\\ \u0026=\\frac{\\partial J}{\\partial z^l_j}\\frac{\\partial }{\\partial w_{jk}^l}\\sum_pw_{jp}^la_p^{l-1}+b_j^l \\\\\\ \u0026=\\delta_j^l\\frac{\\partial }{\\partial w_{jk}^l}\\sum_kw_{jk}^la_k^{l-1}+b_j^l \\\\\\ \u0026=\\delta_j^la_k^{l-1} \\end{aligned} $$ ","date":"2023-04-04","objectID":"/zh-cn/backpropagation-tutorial/:4:4","tags":["Deep-Learning"],"title":"反向传播公式推导和理解","uri":"/zh-cn/backpropagation-tutorial/"},{"categories":["ML-DL"],"content":"反向传播算法 基于前面讨论的公式，可以知道反向传播算法的工作流程 前向传播，计算每个 $z_j^l$，$a_j^l$ 根据公式一计算输出层的梯度向量 $\\delta^L$ 从后往前 根据公式二计算每一层的梯度向量 $\\delta^l$，注意我们总是可以根据 $\\delta^{l+1}$ 计算出 $\\delta^l$ 根据公式三可以计算出每个偏置项 $b^l_j$ 的梯度，它等于 $\\delta^l_j$ 根据公式四可以计算出每个权重 $w^l_{jk}$ 的梯度，它等于 $a_k^{l-1}\\delta_j^l$ 上面这个过程也回答了——为什么反向传播是一个高效的算法这个问题 👍 根据公式二，计算第 $l$ 层的梯度向量 $\\delta^l$ 的时候 $\\delta^{l+1}$ 已经算好了，不用从头从输出层开始推导 👍 根据公式三和公式四，直接算出了损失函数对当前层权重和偏置项的梯度，而不是其他什么中间的梯度结果 ","date":"2023-04-04","objectID":"/zh-cn/backpropagation-tutorial/:4:5","tags":["Deep-Learning"],"title":"反向传播公式推导和理解","uri":"/zh-cn/backpropagation-tutorial/"},{"categories":["ML-DL"],"content":"总结 上面就是反向传播算法的整个流程，公式和记号还是颇多的～但还是比较好理解的，在复习反向传播算法的时候发现了一些可能帮助读者理解反向传播的点： 反向传播是针对单个样本的算法，所以推导的时候考虑一个样本作为模型的输入就行了 推导公式的时候从某个神经元的角度思考，然后归纳为向量形式。而不是一上来就从向量形式入手，当然实力好的当我没说 收工，感谢阅读👋 ","date":"2023-04-04","objectID":"/zh-cn/backpropagation-tutorial/:5:0","tags":["Deep-Learning"],"title":"反向传播公式推导和理解","uri":"/zh-cn/backpropagation-tutorial/"},{"categories":["ML-DL"],"content":"参考 What is backpropagation really doing? - 3Blue1Brown ↩︎ ","date":"2023-04-04","objectID":"/zh-cn/backpropagation-tutorial/:6:0","tags":["Deep-Learning"],"title":"反向传播公式推导和理解","uri":"/zh-cn/backpropagation-tutorial/"},{"categories":["ML-DL"],"content":"机器学习中的线性回归模型指南，包括梯度下降算法推导等","date":"2023-03-15","objectID":"/zh-cn/linear-regression-model-guide-theory/","tags":["Machine-Learning"],"title":"线性回归模型指南 - 理论部分","uri":"/zh-cn/linear-regression-model-guide-theory/"},{"categories":["ML-DL"],"content":"引言 最近，重新刷起了吴恩达的机器学习课程，系统性复习了之前学过的知识，发现又有不少收获，打算仔细整理一番👍 要谈论什么是线性回归首先要对什么是机器学习有一个基本的认识，什么是机器学习？抽象来说机器学习就是学习一个函数 $$ f(input) = output $$ 其中 $f$ 指的就是具体的机器学习模型。机器学习就是自动拟合输入 - 输出之间的关系的一套方法论。有时候我们会发现一些问题很难定义出一个具体的算法来解决，这时就是机器学习发光发热的地方了，我们可以让它从数据中自己学习、总结一些模式，做出相关的预测。这也是它和传统的算法（二分、递归等）区别的地方。不得不承认，机器学习从定义上来说就很迷人，它似乎为所有难以解决的问题提供了一套可行的解决框架。恰恰现实生活中的一些问题就是很难用传统算法解决的 📒 为此，我总觉得每个程序员都应该懂点机器学习/深度学习，它也是我们解决问题的一大工具💪 线性回归就是经典的机器学习入门模型之一，可以说是机器学习界的 “Hello world”，经典的比如波士顿房价预测项目（虽然说现在已经是烂大街的项目了） 前面的公式中，$input$ 为机器学习中所谓的特征（Feature），常用记号 $x$ 表示。而 $output$ 可以根据是预测值还是预测类别可以大致划分为回归问题（Regression problem）和分类问题（Classification problem）两大类 📒 如何理解特征？所谓特征就是，跟要预测的东西高度相关的东西。还是用预测房价作为例子，房价显然跟占地面积、绿化条件等相关，这里的占地面积等就是特征。机器学习中可以对特征分析，看哪些跟输出的关联程度高，或者运用我们的领域知识（Domain knowledge），自己选择好的特征。但总的来说，机器学习还是要求我们花费大量精力在提取好的特征上，这也是机器学习被人诟病的地方，而这个缺点在深度学习中被大大缓解，当然那是后话了 📒 机器学习无法魔法般地理解你提供的各种格式的 $input$，比如图片、文本、视频等。在机器学习中，$input$ 常常被处理为数字，才能用各种机器学习方法学习。有些特征本身就是数字，比如预测房价，房子的占地面积这个特征本身就是一个数字。当输入不是数字的时候，就需要别的手段将输入转化为数字，比如用词嵌入向量模型表示文本等，这里不展开细讲。我们暂时假设已经将输入处理为了数字的形式 今天要提到的线性回归模型就属于监督学习分类下的回归模型，它足够简单，但是又可以阐述很多机器学习的思想，用来入门是再适合不过了。话不多说，让我们开始吧 :) 📒 本文假定你对基本的微积分和线性代数有所了解，比如你需要知道行向量乘列向量如何进行以及对应的记号表示，矩阵乘法的定义，函数如何求导等 ","date":"2023-03-15","objectID":"/zh-cn/linear-regression-model-guide-theory/:1:0","tags":["Machine-Learning"],"title":"线性回归模型指南 - 理论部分","uri":"/zh-cn/linear-regression-model-guide-theory/"},{"categories":["ML-DL"],"content":"线性回归模型 线性回归的英文是 Linear regression。顾名思义，由两部分组成： Linear 的含义就是它是线性的。以二维平面为例，$y=kx+b$ 这种就是线性，画出来是一条直线，而 $y=x^2$ 这种就不是，因为它画出来为曲线 Regression 是因为它符合机器学习中对回归问题的定义——预测一个不限制范围的值 ","date":"2023-03-15","objectID":"/zh-cn/linear-regression-model-guide-theory/:2:0","tags":["Machine-Learning"],"title":"线性回归模型指南 - 理论部分","uri":"/zh-cn/linear-regression-model-guide-theory/"},{"categories":["ML-DL"],"content":"分类 📒 为了形式的简洁下面的记号 $f(x)$ 其实省略了下标 $w,b$。$f(x)=f_{w,b}(x)$ 📒 有时候会看到有的书或者博客用 $h_\\theta$ 表示模型，我认为 $f(x)$ 比较简洁就用了这个记法 如果要进一步对线性回归模型进行细分，又可以分成如下几类 ","date":"2023-03-15","objectID":"/zh-cn/linear-regression-model-guide-theory/:3:0","tags":["Machine-Learning"],"title":"线性回归模型指南 - 理论部分","uri":"/zh-cn/linear-regression-model-guide-theory/"},{"categories":["ML-DL"],"content":"单变量线性回归 如果模型的输入特征只有一个，就叫做单变量线性回归（Univariate linear regression），此时达到了最简单的形式 $$ f(x)=wx+b $$ 在机器学习中，分别称 $w$ 和 $b$ 为权重（Weight）和偏置项（Bias） 📒 注意：$\\theta$ 为一个向量，按道理应该用 $\\vec \\theta$ 表示，但是下面为了简洁，我都省略了箭头 📒 也可以用向量的形式写，用 $\\theta=[b, w]$ 表示模型的参数，令 $\\vec x=[1, x]^T$。那么根据向量乘法的知识我们可以知道 $\\theta^T\\vec x=wx+b$ ","date":"2023-03-15","objectID":"/zh-cn/linear-regression-model-guide-theory/:3:1","tags":["Machine-Learning"],"title":"线性回归模型指南 - 理论部分","uri":"/zh-cn/linear-regression-model-guide-theory/"},{"categories":["ML-DL"],"content":"多变量线性回归 如果模型有多个输入的特征，就叫做多变量线性回归（Multiple linear regresseion） $$ f(x)=w_1x_1+w_1x_2+…w_nx_n+b $$ 其中 $x_i$ 是不同的特征，一共有 $n$ 个特征，为此我们需要每个特征学习一个权重 $w_i$ 📒 同理，可以选择用向量的形式来写，令 $\\theta=[b, w_1, w_2, …, w_n]$，$\\vec x=[1, x_1, x_2, …, x_n]^T$，向量乘法之后也可以得到上面的形式。你会惊讶地发现，单变量线性回归和多变量线性回归有了统一的形式——$f(\\vec x)=\\theta^T\\vec x$。这在后面求解梯度的时候会带来很大的方便 ","date":"2023-03-15","objectID":"/zh-cn/linear-regression-model-guide-theory/:3:2","tags":["Machine-Learning"],"title":"线性回归模型指南 - 理论部分","uri":"/zh-cn/linear-regression-model-guide-theory/"},{"categories":["ML-DL"],"content":"模型如何训练 ","date":"2023-03-15","objectID":"/zh-cn/linear-regression-model-guide-theory/:4:0","tags":["Machine-Learning"],"title":"线性回归模型指南 - 理论部分","uri":"/zh-cn/linear-regression-model-guide-theory/"},{"categories":["ML-DL"],"content":"损失函数 定义了线性回归模型之后，我们需要衡量它的预测好坏，显然，我们希望预测的值跟实际上的值的“距离”越接近越好。在机器学习中，我们会规定一个损失函数（Cost function）衡量“距离”，损失自然是越低越好。当模型在验证集上的损失降到最低不再明显变化的时候，我们认为模型收敛了，此时得到了最好的模型 📒 在机器学习中，通常将数据划分为训练集/验证集/测试集，模型用训练集上的数据学习，在验证集上验证、调参，最后在测试集上进行泛化性验证（测试集包含没有见过的数据）。只用训练集/测试集这种划分方法，直接在测试集上调参是不正确的做法。测试集当且仅当最后你训练和调参结束，选出你认为的最好模型的的时候，在论文里面是报告结果的时候采用的 线性回归模型的损失函数最常用的是均平方误差，我更经常直接用英文的缩写 MSE（Mean square error）代指。其公式如下： $$ MSE=\\frac{1}{2m}\\sum^m_{i=1}(\\hat y^{(i)} - y^{(i)})^2 $$ 其中 $m$ 表示样本个数 上角标 ${(i)}$ 加了括号，和指数的记号进行区分，表示第 $i$ 个样本的预测/真实值 $\\hat y$ 这个记号表示线性回归模型的预测，$y$ 表示本来的真实值 📒 我采用了符合机器学习惯例的记号，推荐记住～ 📒 线性回归模型不是非要用 MSE，也可以用绝对值误差 MAE，MAE 适用于：当数据集中的异常值（Outlier）比较多的时候，降低对这种样本的敏感度 ","date":"2023-03-15","objectID":"/zh-cn/linear-regression-model-guide-theory/:4:1","tags":["Machine-Learning"],"title":"线性回归模型指南 - 理论部分","uri":"/zh-cn/linear-regression-model-guide-theory/"},{"categories":["ML-DL"],"content":"梯度下降训练法 前面提到当模型在验证集上的损失降到最低而且不再变化的时候，我们得到最好的模型。但是要如何让模型不断改进预测，降低损失呢？🤔 梯度下降（Gradient descent）算法是一种通用的做法 不要被这个名字所迷惑，梯度下降算法其实没有那么神秘。先整理我们目前学到了什么： 模型的预测 $\\hat y$ 跟它参数，如果是单变量线性回归模型，就是和 $w$ 和 $b$ 有关 损失函数跟模型的预测有关系，因为数据本身真实的值这个我们是无法改变的 所以损失函数实际上是一个关于模型参数的函数，在机器学习中，常用记号 $J$ 表示 先考虑简单的单变量线性回归，当它采用 MSE 作为损失函数的时候： $$ J(w, b) = \\frac{1}{2m}\\sum^m_{i=1}(f(x^{(i)})-y^{(i)})^2 = \\frac{1}{2m}\\sum^m_{i=1}(wx^{(i)} + b - y^{(i)})^2 $$ 根据 $w$ 和 $b$ 的取值不同，$J(w,b)$ 也不同，因此改进线性回归模型其实就是一直在调整这两个参数让 $J(w,b)$ 的值更小。用数学的语言来说，求解最优模型其实就是求解函数 $J(w,b)$ 的最小点 📒 回忆 $m$ 为训练集的样本个数。更为严格来说，上面的梯度下降式子是批梯度下降（Batch gradient descent），即每个计算梯度的时候用的是整个训练集上的样本。当数据集很大的时候这个方法就无法很好 Scale，此时我们就需要使用随机梯度下降（Stochastic gradient descent） 📒 只要学过导数、最小值，我们不难求解出上面公式的最小值，但这是因为线性回归模型比较简单，当模型更加复杂的时候，用数学方法求解也会更加困难，因此在实践中采用的都是梯度下降算法（不考虑强化学习，因为强化学习优化的目标一般不是一个可微的函数） 让我们暂时不考虑 $b$ 只考虑 $w$，那么此时 $J$ 是一个关于 $w$ 的函数，我们可以以 $w$ 为横轴，$J(w)$ 为纵轴画出如下的图： 📒 注意，上面的图并不严格遵循 $J(w)$ 的定义，为了方便我这里直接画了 $y=\\frac{1}{2}x^2$。但是形状应该差不多，可以用来理解梯度下降算法 从图中不难看出，当 $w=0$ 的时候 $J(w)$ 取到了最小值。假设模型当前的参数 $w=5$，计算得到损失 $J(5)=12.5$，我们要如何更新 $w$ 让模型更好呢？答案是让 $w$ 沿着梯度的反方向更新（图中红色的线为在 $w=5$ 这个点的切线），不难求出这一点的梯度（导数）是 $5$，$w$ 应该减小，因此应该是减去这个梯度（所以说是反方向），同时引入学习率 $\\alpha$ 控制更新的幅度，得到更新式子 $w \\leftarrow w - \\alpha \\cdot 5$ 📒 想象你自己站在 $w=5$ 这个点要前进到 $w=0$ 这个最小值在的点，如果学习率 $\\alpha$ 太大，你新得到的 $w$ 可能会小于 $0$，一下子越过了 $w=0$ 这个点。虽然你可以通过梯度下降再次尝试更新，但此时往往你会发现你的模型的损失一直在变化无法收敛。学习率和梯度共同控制了每次参数更新的幅度 📒 我们在只考虑 $w$ 的时候得出了该如何更新的结论——沿着梯度的反方向，考虑更多的参数的时候这个结论仍然适用，不过那就要涉及到求解偏导数乃至向量求导的知识，而且此时的 $J$ 的可视化也更为困难，所以这里不细讲。只需要记住模型的更新总是沿着梯度的反方向前进，从直觉上进行把握👻 在单变量线性回归中，梯度更新的式子如下： $$ w \\leftarrow w - \\alpha \\cdot \\frac{\\partial}{\\partial w}J(w,b) $$ 别忘了还有 $b$，它也要更新 $$ b \\leftarrow b - \\alpha \\cdot \\frac{\\partial}{\\partial b}J(w,b) $$ 我们来对其中的梯度计算进行推导 $$ \\begin{aligned} \\frac{\\partial}{\\partial w}J(w,b)\u0026=\\frac{\\partial}{\\partial w}\\frac{1}{2m}\\sum_{i=1}^m(f(x^{(i)})-y^{(i)})^2 \\\\\\ \u0026= \\frac{\\partial}{\\partial w}\\frac{1}{2m}(wx^{(i)}+b-y^{(i)})^2 \\\\\\ \u0026= \\frac{\\partial}{\\partial w}\\frac{1}{m}\\sum_{i=1}^m(f(x^{(i)})-y^{(i)})x^{(i)} \\end{aligned} $$ $$ \\begin{aligned} \\frac{\\partial}{\\partial b}J(w,b)\u0026=\\frac{\\partial}{\\partial w}\\frac{1}{2m}\\sum_{i=1}^m(f(x^{(i)})-y^{(i)})^2 \\\\\\ \u0026= \\frac{\\partial}{\\partial b}\\frac{1}{2m}(wx^{(i)}+b-y^{(i)})^2 \\\\\\ \u0026= \\frac{\\partial}{\\partial b}\\frac{1}{m}\\sum_{i=1}^m(f(x^{(i)})-y^{(i)}) \\end{aligned} $$ 如果是多变量线性回归，我们要求解每个 $\\frac{\\partial }{w_i}J(w_1,w_2, …,b)$ 显然很不方便，此时用向量形式推导梯度是最好的 在向量的形式下，损失函数 MSE 写作： $$ J(\\theta) = \\frac{1}{2m}(X\\theta - \\vec{y})^T(X\\theta - \\vec{y}) $$ 其中 $X$ 为输入的矩阵，常用大写字母表示矩阵，它的每一行为一个样本的特征值 $(x^{(i)})^T$，大小为 $(m, n+1)$ 前面提到我们有 $n$ 个特征，这里为 $n+1$ 维是因为在第一个位置插入了一个 $1$，这样相乘的时候 $1$ 会和 $b$ 做计算 $x^{(i)}$ 需要转置因为本来它本是列向量 对于单个样本是 $\\theta^T\\vec x$，对于 $m$ 个样本的计算就要用矩阵乘法 $X\\theta$ $\\theta$ 正如我们前面说的是 $[b, w_1, w_2, …, w_n]$，长为 $n + 1$ 因此 $X\\theta$ 就是模型的预测值，根据矩阵乘法的知识，我们会得到长为 $m$ 的向量，表示对每个样本的预测 $X\\theta - \\vec y$ 就是每个预测的误差 顺带一提，假设 $\\vec a$ 为列向量，$\\vec a^T\\vec a$ 得到的总是一个标量，为每个元素的平方和。如果让 $\\vec a=X\\theta -\\vec y$ 就得到了上面右边的部分，这也解释了为什么会是这个形式 🤔️ 更新：在 维度分析 这篇博客中，我展示了如何用维度分析技巧快速推导出这个公式的解，感兴趣的话可以看下 下面我们开始尝试推导这个公式的梯度，这需要你有一定的向量/矩阵求导知识，可以选择跳过🔮。不过我建议还是看看，因为机器学习里面还挺多公式推导的 $$ \\begin{aligned} \\frac{\\partial}{\\partial \\theta}\\ J(w,b) \u0026= \\frac{\\partial}{\\partial \\theta}\\ \\frac{1}{2m}(X\\theta - \\vec{y})^T(X\\theta - \\vec{y}) \\\\\\ \u0026= \\frac{1}{2m}\\frac{\\partial}{\\partial \\theta}\\ (\\theta^TX^T - \\vec{y}^T)(X\\theta - \\vec{y}) \\\\\\ \u0026= \\frac{1}{2m}\\frac{\\partial}{\\partial \\theta}\\ (\\theta^TX^TX\\theta - \\theta^TX^T\\vec y - \\vec y^TX\\theta + \\vec y^T\\vec y) \\\\\\ \u0026= \\frac{1}{2m}\\frac{\\partial}{\\partial \\theta}\\ (\\theta^TX^TX\\theta - \\theta^T(X^T\\vec y) - (X^T\\vec y)^T\\theta + \\vec y^T\\vec y) \\\\\\ \u0026= \\frac{1}{2m}\\frac{\\partial}{\\partial \\theta}\\ (\\theta^TX^TX\\theta - 2\\theta^T(X^T\\vec y) + \\vec y^T\\vec y) \\\\\\ \u0026= \\frac{1}{2m}(\\frac{\\partial}{\\partial \\theta}\\ (\\theta^TX^TX\\theta) - 2\\frac{\\partial}{\\partial \\theta}(\\theta^TX^T\\vec y))) \\\\\\ \u0026= \\frac{1}{2m}(2X^TX\\theta - 2X^T\\vec y)) \\\\\\ \u0026= \\frac{1}{m}(X^TX\\theta - X^T\\vec y)) \\\\\\ \u0026= \\frac{1}{m}X^T(X\\theta-\\vec y) \\end{aligned} $$ 几个解释： $X^T$ 的大小是 $(n+1, m)","date":"2023-03-15","objectID":"/zh-cn/linear-regression-model-guide-theory/:4:2","tags":["Machine-Learning"],"title":"线性回归模型指南 - 理论部分","uri":"/zh-cn/linear-regression-model-guide-theory/"},{"categories":["ML-DL"],"content":"总结 线性回归模型的理论部分就是以上的内容，本文介绍了单变量线性回归，多变量线性回归，前者可以看成是后者的一个特例。最后我们将其都用向量的形式统一了写法，并给出了向量形式下采用 MSE 作为损失函数的时候的梯度计算公式 本来还想放一下代码在这里，结果写着写着发现这一篇博客已经很长了，看来只好将线性回归模型的算法放在另一篇了🙌 ","date":"2023-03-15","objectID":"/zh-cn/linear-regression-model-guide-theory/:5:0","tags":["Machine-Learning"],"title":"线性回归模型指南 - 理论部分","uri":"/zh-cn/linear-regression-model-guide-theory/"},{"categories":["Vim"],"content":"从零开始配置 Neovim 为一个轻量级的 IDE","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/","tags":["Nvim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/"},{"categories":["Vim"],"content":"版本信息 我使用的是 Macbook pro 2020 Intel 版本，系统版本为 macOS 13.2。我的 Nvim 版本信息如下 NVIM v0.8.3 Build type: Release LuaJIT 2.1.0-beta3 Compiled by brew@Ventura Features: +acl +iconv +tui See \":help feature-compile\" system vimrc file: \"$VIM/sysinit.vim\" fall-back for $VIM: \"/usr/local/Cellar/neovim/0.8.3/share/nvim\" Run :checkhealth for more info ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:1:0","tags":["Nvim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/"},{"categories":["Vim"],"content":"为什么选择 Neovim 在使用 Vim 一年多之后，我越发觉得 Vim 的配置麻烦，启动加载速度也不尽人意。我也很不喜欢 Vimscript 的写法，这导致我决定使用 Neovim(Nvim)。我决定重新配置 Nvim。为什么会想要重新配置而不是迁移配置呢？因为我想顺便趁着这个机会，重新审视我本来 Vim 的配置，以及将本来用到的的插件替换为现在的 SOTA(State-of-the-art)。我自从看完 MIT 的 Missing semester 的课配置了 ~/.vimrc 之后就很长时间都没有再编辑 ~/.vimrc 文件了 我认为在配置 Nvim 的时候弄清楚每一个选项的意思是很有必要的，因此我在这篇博客中会尽量解释清楚每个选项的含义，同时将解释放在注释里面，即我尽量让我自己的配置文件是 self-contained 而且可读性强的 💡 当然，这难免有疏漏。别忘了我们永远可以在 Nvim 里面输入 :h \u003cname\u003e 来看到更为详细的解释 💡 该篇博客假定你对 Vim 有基本了解 ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:2:0","tags":["Nvim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/"},{"categories":["Vim"],"content":"Nvim 配置基础知识 ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:3:0","tags":["Nvim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/"},{"categories":["Vim"],"content":"Lua 语言 在配置 Nvim 的时候，我会尽可能用 Lua 语言写配置，因此你有必要了解一下 Lua 的基本语法和语义。可以快速浏览一下 Learn Lua in Y minutes 了解大概 ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:3:1","tags":["Nvim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/"},{"categories":["Vim"],"content":"配置文件路径 Nvim 的配置目录在 ~/.config/nvim 下。在 Linux/Mac 系统上，Nvim 会默认读取 ~/.config/nvim/init.lua 文件，理论上来说可以将所有配置的东西都放在这个文件里面，但这样不是一个好的做法，因此我划分不同的文件和目录来分管不同的配置 首先看下按照本篇教程配置 Nvim 之后，目录结构看起来会是怎么样⬇️ nvim ├── init.lua └── lua ├── colorscheme.lua ├── config │ └── nvim-cmp.lua ├── keymaps.lua ├── lsp.lua ├── options.lua └── plugins.lua 解释如下 init.lua 为 Nvim 配置的 Entry point，我们主要用来导入其他 *.lua 文件 colorscheme.lua 配置主题 keymaps.lua 配置按键映射 lsp.lua 配置 LSP options.lua 配置选项 plugins.lua 配置插件 config 用于存放各种插件自身的配置，文件名为插件的名字，这样比较好找。这里的 nvim-cmp.lua 就是 nvim-cmp 插件的配置文件 lua 目录。当我们在 Lua 里面调用 require 加载模块（文件）的时候，它会自动在 lua 文件夹里面进行搜索 将路径分隔符从 / 替换为 .，然后去掉 .lua 后缀就得到了 require 的参数格式 比如要导入上面的 nvim-cmp.lua 文件，可以用 require('config.nvim-cmp') ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:3:2","tags":["Nvim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/"},{"categories":["Vim"],"content":"选项配置 主要用到的就是 vim.g、vim.opt、vim.cmd 等，我制造了一个快速参照对比的表格 In Vim In Nvim Note let g:foo = bar vim.g.foo = bar set foo = bar vim.opt.foo = bar set foo = vim.opt.foo = true some_vimscript vim.cmd(some_vimscript) ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:3:3","tags":["Nvim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/"},{"categories":["Vim"],"content":"按键配置 在 Nvim 里面进行按键绑定的语法如下，具体的解释可以看 :h vim.keymap.set vim.keymap.set(\u003cmode\u003e, \u003ckey\u003e, \u003caction\u003e, \u003copts\u003e) ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:3:4","tags":["Nvim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/"},{"categories":["Vim"],"content":"从零开始配置 Nvim 在阅读了前面一些配置基础之后，现在我们可以从头开始，由简到易一步步配置 Nvim 了 ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:4:0","tags":["Nvim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/"},{"categories":["Vim"],"content":"安装 Nvim 我用的是 Mac，用 Homebrew 安装 Nvim 非常容易，只要运行如下命令即可1 $ brew install neovim 在安装完成之后，如果 ~/.config/nvim 目录不存在，创建目录并新建 init.lua 文件 $ mkdir ~/.config/nvim $ mkdir ~/.config/nvim/lua $ touch ~/.config/nvim/init.lua 💡 配置文件编辑保存之后，重启 Nvim 就能看到效果，后面默认每次小章节配置完成后就重启 ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:4:1","tags":["Nvim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/"},{"categories":["Vim"],"content":"选项配置 选项配置功能一览： 默认采用系统剪贴板，同时支持鼠标操控 Nvim Tab 和空格的换算 UI 界面 “智能”搜索 新建 ~/.config/nvim/lua/options.lua 文件并加入如下内容⬇️ -- Hint: use `:h \u003coption\u003e` to figure out the meaning if needed vim.opt.clipboard = 'unnamedplus' -- use system clipboard vim.opt.completeopt = { 'menu', 'menuone', 'noselect' } vim.opt.mouse = 'a' -- allow the mouse to be used in Nvim -- Tab vim.opt.tabstop = 4 -- number of visual spaces per TAB vim.opt.softtabstop = 4 -- number of spacesin tab when editing vim.opt.shiftwidth = 4 -- insert 4 spaces on a tab vim.opt.expandtab = true -- tabs are spaces, mainly because of python -- UI config vim.opt.number = true -- show absolute number vim.opt.relativenumber = true -- add numbers to each line on the left side vim.opt.cursorline = true -- highlight cursor line underneath the cursor horizontally vim.opt.splitbelow = true -- open new vertical split bottom vim.opt.splitright = true -- open new horizontal splits right -- vim.opt.termguicolors = true -- enabl 24-bit RGB color in the TUI vim.opt.showmode = false -- we are experienced, wo don't need the \"-- INSERT --\" mode hint -- Searching vim.opt.incsearch = true -- search as characters are entered vim.opt.hlsearch = false -- do not highlight matches vim.opt.ignorecase = true -- ignore case in searches by default vim.opt.smartcase = true -- but make it case sensitive if an uppercase is entered 然后打开 init.lua，用 require 导入刚才写的 options.lua 文件 require('options') ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:4:2","tags":["Nvim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/"},{"categories":["Vim"],"content":"按键配置 按键功能一览： 用 \u003cC-h/j/k/l\u003e 快速在多窗口之间移动光标 用 Ctrl + 方向键进行窗口大小的调整 选择模式下可以一直用 Tab 或者 Shift-Tab 改变缩进 新建 ~/.config/nvim/lua/keymaps.lua 文件并放入如下内容⬇️ -- define common options local opts = { noremap = true, -- non-recursive silent = true, -- do not show message } ----------------- -- Normal mode -- ----------------- -- Hint: see `:h vim.map.set()` -- Better window navigation vim.keymap.set('n', '\u003cC-h\u003e', '\u003cC-w\u003eh', opts) vim.keymap.set('n', '\u003cC-j\u003e', '\u003cC-w\u003ej', opts) vim.keymap.set('n', '\u003cC-k\u003e', '\u003cC-w\u003ek', opts) vim.keymap.set('n', '\u003cC-l\u003e', '\u003cC-w\u003el', opts) -- Resize with arrows -- delta: 2 lines vim.keymap.set('n', '\u003cC-Up\u003e', ':resize -2\u003cCR\u003e', opts) vim.keymap.set('n', '\u003cC-Down\u003e', ':resize +2\u003cCR\u003e', opts) vim.keymap.set('n', '\u003cC-Left\u003e', ':vertical resize -2\u003cCR\u003e', opts) vim.keymap.set('n', '\u003cC-Right\u003e', ':vertical resize +2\u003cCR\u003e', opts) ----------------- -- Visual mode -- ----------------- -- Hint: start visual mode with the same area as the previous area and the same mode vim.keymap.set('v', '\u003c', '\u003cgv', opts) vim.keymap.set('v', '\u003e', '\u003egv', opts) 然后在 init.lua 文件里面再次加上一行导入这个文件 ... require('keymaps') 💡 ... 表示我们省略了其他部分的代码（为了节省博客的篇幅） ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:4:3","tags":["Nvim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/"},{"categories":["Vim"],"content":"安装插件管理器 一个强大的 Nvim 离不开插件的支持。我选用的是当下最为流行，而且完全用 Lua 语言编写的 Packer.nvim。它支持如下许多特性： 支持配置第三方插件的依赖 支持 Lazy loading 支持设置插件安装之后的钩子函数 … 💡 在 Packer.nvim 配置里面指定第三方插件很简单，用 use ... 即可 新建 ~/.config/nvim/lua/plugins.lua 文件并放入如下内容。下面的模板只完成了 Packer.vim 自身的安装，还没有指定其他第三方插件。这个模板的功能主要是 初次启动的时候自动安装 Packer.nvim 当我们保存对这个文件（plugins.lua）文件的修改的时候，Packer.nvim 会自动帮我们自动更新插件和帮我们做好配置。你可以看到Nvim 右边看到多了一个窗口显示进度 💡 Packer.nvim 还支持了不少命令，不过你不需要把他们都记住。因为这个模板会自动帮我们处理好。值得一提的是如果因为网络问题安装失败的话，在它弹出的窗口里面按照提示按下大写的 R 就会自动重新下载。在 Packer.nvim 提示全都安装成功后，重启 Nvim 就生效了 -- Install Packer automatically if it's not installed(Bootstraping) -- Hint: string concatenation is done by `..` local ensure_packer = function() local fn = vim.fn local install_path = fn.stdpath('data') .. '/site/pack/packer/start/packer.nvim' if fn.empty(fn.glob(install_path)) \u003e 0 then fn.system({ 'git', 'clone', '--depth', '1', 'https://github.com/wbthomason/packer.nvim', install_path }) vim.cmd [[packadd packer.nvim]] return true end return false end local packer_bootstrap = ensure_packer() -- Reload configurations if we modify plugins.lua -- Hint -- \u003cafile\u003e - replaced with the filename of the buffer being manipulated vim.cmd([[ augroup packer_user_config autocmd! autocmd BufWritePost plugins.lua source \u003cafile\u003e | PackerSync augroup end ]]) -- Install plugins here - `use ...` -- Packer.nvim hints -- after = string or list, -- Specifies plugins to load before this plugin. See \"sequencing\" below -- config = string or function, -- Specifies code to run after this plugin is loaded -- requires = string or list, -- Specifies plugin dependencies. See \"dependencies\". -- ft = string or list, -- Specifies filetypes which load this plugin. -- run = string, function, or table, -- Specify operations to be run after successful installs/updates of a plugin return require('packer').startup(function(use) -- Packer can manage itself use 'wbthomason/packer.nvim' --------------------------------------- -- NOTE: PUT YOUR THIRD PLUGIN HERE -- --------------------------------------- -- Automatically set up your configuration after cloning packer.nvim -- Put this at the end after all plugins if packer_bootstrap then require('packer').sync() end end) 然后在 init.lua 文件里面再次加上一行导入这个文件 ... require('plugins') 此时你重启 Nvim 会发现黑屏没显示，这是因为 Packer.nvim 在安装自己，静待片刻即可☕️ ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:4:4","tags":["Nvim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/"},{"categories":["Vim"],"content":"主题配置 我喜欢的主题是 monokai，在 plugins.lua 里面加上 ... use 'tanvirtin/monokai.nvim' ... 保存更改待 Packer.nvim 下载插件完成之后，新建并编辑 ~/.config/nvim/colorscheme.lua 文件 -- define your colorscheme here local colorscheme = 'monokai_pro' local is_ok, _ = pcall(vim.cmd, \"colorscheme \" .. colorscheme) if not is_ok then vim.notify('colorscheme ' .. colorscheme .. ' not found!') return end 这里用到的 pcall 是 Lua 里面的 protected call，会返回一个 bool 变量表示是否执行成功（跟 Golang 的 err 功能类似）。这里采用 pcall 而不是直接在 init.lua 文件里面加上 vim.cmd('colorscheme monokai_pro') 是为了避免主题没有安装的话打开 Nvim 看到一大堆报错信息2 最后在 init.lua 文件里面导入就行 ... require('colorscheme') ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:4:5","tags":["Nvim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/"},{"categories":["Vim"],"content":"自动补全指南 自己手动配置自动补全功能的话会比较繁琐，所以我们最好是借助于一些插件来帮忙，下面我讲讲我摸索出来的最简单配置方法 首先，第一个要用到的插件是 nvim-cmp，它可以管理各种补全候选项来源，然后展示在补全菜单里面，还支持我们对外观等进行定制化。 我们先新建 ~/.config/nvim/lua/config/nvim-cmp.lua 文件配置 nvim-cmp 💡 这里首先选择写 nvim-cmp 的配置文件然后再在 plugins.lua 文件里面用 use 添加插件。这样可以保证 Packer.nvim 安装 nvim-cmp 的相关插件读取 nvim-cmp.lua 配置文件的时候不会报错。下面的配置文件暂时看不懂也没有关系，我会对其进行解释 local has_words_before = function() unpack = unpack or table.unpack local line, col = unpack(vim.api.nvim_win_get_cursor(0)) return col ~= 0 and vim.api.nvim_buf_get_lines(0, line - 1, line, true)[1]:sub(col, col):match(\"%s\") == nil end local luasnip = require(\"luasnip\") local cmp = require(\"cmp\") cmp.setup({ snippet = { -- REQUIRED - you must specify a snippet engine expand = function(args) require('luasnip').lsp_expand(args.body) -- For `luasnip` users. end, }, mapping = cmp.mapping.preset.insert({ -- Use \u003cC-b/f\u003e to scroll the docs ['\u003cC-b\u003e'] = cmp.mapping.scroll_docs( -4), ['\u003cC-f\u003e'] = cmp.mapping.scroll_docs(4), -- Use \u003cC-k/j\u003e to switch in items ['\u003cC-k\u003e'] = cmp.mapping.select_prev_item(), ['\u003cC-j\u003e'] = cmp.mapping.select_next_item(), -- Use \u003cCR\u003e(Enter) to confirm selection -- Accept currently selected item. Set `select` to `false` to only confirm explicitly selected items. ['\u003cCR\u003e'] = cmp.mapping.confirm({ select = true }), -- A super tab -- sourc: https://github.com/hrsh7th/nvim-cmp/wiki/Example-mappings#luasnip [\"\u003cTab\u003e\"] = cmp.mapping(function(fallback) -- Hint: if the completion menu is visible select next one if cmp.visible() then cmp.select_next_item() elseif has_words_before() then cmp.complete() else fallback() end end, { \"i\", \"s\" }), -- i - insert mode; s - select mode [\"\u003cS-Tab\u003e\"] = cmp.mapping(function(fallback) if cmp.visible() then cmp.select_prev_item() elseif luasnip.jumpable( -1) then luasnip.jump( -1) else fallback() end end, { \"i\", \"s\" }), }), -- Let's configure the item's appearance -- source: https://github.com/hrsh7th/nvim-cmp/wiki/Menu-Appearance formatting = { -- Set order from left to right -- kind: single letter indicating the type of completion -- abbr: abbreviation of \"word\"; when not empty it is used in the menu instead of \"word\" -- menu: extra text for the popup menu, displayed after \"word\" or \"abbr\" fields = { 'abbr', 'menu' }, -- customize the appearance of the completion menu format = function(entry, vim_item) vim_item.menu = ({ nvim_lsp = '[Lsp]', luasnip = '[Luasnip]', buffer = '[File]', path = '[Path]', })[entry.source.name] return vim_item end, }, -- Set source precedence sources = cmp.config.sources({ { name = 'nvim_lsp' }, -- For nvim-lsp { name = 'luasnip' }, -- For luasnip user { name = 'buffer' }, -- For buffer word completion { name = 'path' }, -- For path completion }) }) 然后我们修改 plugins.lua 文件添加插件 ... use { 'neovim/nvim-lspconfig' } use { 'hrsh7th/nvim-cmp', config = [[require('config.nvim-cmp')]] } use { 'hrsh7th/cmp-nvim-lsp', after = 'nvim-cmp' } use { 'hrsh7th/cmp-buffer', after = 'nvim-cmp' } -- buffer auto-completion use { 'hrsh7th/cmp-path', after = 'nvim-cmp' } -- path auto-completion use { 'hrsh7th/cmp-cmdline', after = 'nvim-cmp' } -- cmdline auto-completion use 'L3MON4D3/LuaSnip' use 'saadparwaiz1/cmp_luasnip' ... 解释如下 cmp.setup 函数的参数是一个 Lua 的 Table，用于设置各个选项（下面会解释）。后面你会发现很多第三方插件都用 setup 传入一个 Lua table 的方式进行配置，这个是 Nvim 的 Lua 插件的惯例 不要被上面的这么多插件吓到，nvim-cmp 为主，其他 cmp-... 的插件是用于在候选项来源和 nvim-cmp 之间交互 LuaSnip 是 code snippet 引擎，因为nvim-cmp 要求我们必须指定至少一个 code snippet 引擎来源所以才加上，你暂时用不到当它不存在也没有关系 Packer.nvim 支持用 config = ... 指定对应插件被加载之后要运行的代码，所以 config = [[require('config.nvim-cmp')]] 的意思是导入了 config 文件夹里面的 nvim-cmp.lua 文件，这个设计参考了3 nvim-cmp 里面的按键映射 按键映射用的是 mapping = ... ，每个按键绑定的格式是 ['\u003ckey-binding\u003e'] = cmp.mapping.xxx,，不同的 cmp.mapping.xxx 的含义可以用 :h 查看。如果你想要用其他的按键，只要修改 [...] 里面的按键即可 按照我的个人习惯，设置了 \u003cC-k/j\u003e 或者 \u003cTab\u003e/\u003cShift-Tab\u003e 在各种候选项里面移动 \u003cC-b/f\u003e 在候选项的文档里面移动 \u003cCR\u003e 也就是回车键确定补全 nvim-cmp 里面的补全菜单 补全菜单的定制化用的是 formatting = ... fields 字段规定了每个候选项要显示什么东西 format = function(...) 设置了不同的候选项的来源显示，在 sources = ... 里面声明来源 🎙️ 到这为止，重新启动 Nvim 后应该能够用初步的自动补全功能了～ LSP 要把 Nvim 变成 IDE 就势必要借助于 LSP","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:4:6","tags":["Nvim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/"},{"categories":["Vim"],"content":"总结 这样配置下来，我们成功把 Nvim 变成了一个轻量级的 IDE，它支持代码高亮、代码补全、语法检查等功能，而且是完全开源免费的，虽然还有些简陋，但已经是可以用的了🥰 我发现自从学了 Vim 之后，我总在其他各种代码编辑器、IDE 看是不是支持 Vim。大多数情况下，他们对 Vim 的支持都不是很让人满意，还容易有快捷键冲突等问题。因此我选择将 Nvim 变成 IDE，并将配置文件托管在我的 martinlwx/dotfiles 上。这样在新的机器上只要安装好 Nvim 并克隆配置静待片刻之后，就可以在不同的机器上获得一样的编程体验 打磨定制化工具是需要付出一定精力的。为了理解每个选项都在干啥，我不得不查找各种资料。但我仍相信这是值得的，理解你的工具利于你做扩展和定制化。本文已经尽可能采用了比较简单的配置，还有很多美化、私人定制化的内容可以配置，更别提其他很多优秀的第三方插件都还没有提及，这些就留给读者自己去探索发现了 ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:5:0","tags":["Nvim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/"},{"categories":["Vim"],"content":"参考 Installing-Neovim ↩︎ Adding a colorscheme/theme ↩︎ jdhao/nvim-config ↩︎ Language Server Protocol - Wiki ↩︎ ","date":"2023-02-08","objectID":"/zh-cn/config-neovim-from-scratch/:6:0","tags":["Nvim"],"title":"从零开始配置 Neovim(Nvim)","uri":"/zh-cn/config-neovim-from-scratch/"},{"categories":["Python"],"content":"Python 的类型提示的简单介绍","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/","tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/"},{"categories":["Python"],"content":"引言 一开始吸引我学习 Python 的是它的动态语言特性，以及它的鸭子类型（Duck typing）系统——我们不关心具体的类型是什么，我们只关心它的行为。得益于 Python 的动态语言特性，我们不需要声明具体类型，这很大程度上加快了开发速度，而且去掉了不少心智负担，再加上强大的第三方库支持，Python 成为了我最爱用的编程语言😺 而随着 PEP 4841 的提出，Python 决定引入类型提示（Type hint），这似乎又向静态类型语言看齐了？但其实非也，Python 仍然是一门动态编程语言，它的类型提示是可选项，加不加都可以，不会对程序运行产生影响。 这样听起来似乎没有必要专门写这篇博客来介绍 Python 的类型提示特性，但我发现写类型提示还是有不少好处的： 可以使用类型检查工具对代码进行检查，比如 Mypy IDE 的代码补全会更加智能，推荐的 API 更准确，我们用错了 API 也能及时发现。这可能是我选择写类型提示的最大动力 对抗代码复杂性。类型提示暴露了 API 的不少信息。作为开发者，我们只要看一下这样的函数签名就能知道个大概，而不用经常去看文档 ! python --version Python 3.11.0\r","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:1:0","tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/"},{"categories":["Python"],"content":"函数的类型提示语法 早在 Python 3.0，类型提示的语法就已经确定了下来2： 函数参数：name[: type] [ = default_val ]，其中 [] 表示这是可选项 函数返回类型：用 -\u003e return_type 表示 我们可以通过函数的 __annotations__ 属性访问到参数的类型信息，该属性返回一个字典，key 为参数名，value 为类型。==不推荐直接访问该属性，而应该通过 inspect 模块（\u003e Python 3.10）或者 typing 模块（Python 3.5 ~ 3.9）里面的对应方法来获取这个信息==。如下所示： def maximum(a: float, b: float) -\u003e float: \"\"\" A simple function to return the maximum elements of two floats\"\"\" return max(a, b) # \u003e= Python 3.10, do this import inspect assert inspect.get_annotations(maximum) == maximum.__annotations__ # Python 3.5 ~ 3.9 import typing assert typing.get_type_hints(maximum) == maximum.__annotations__ inspect.get_annotations(maximum) {'a': float, 'b': float, 'return': float} 📒 再次强调，类型提示信息不会对程序的运行产生任何影响，这意味着即使我们违背了类型提示信息，程序也可以正常运行。只是静态代码检查工具会对此抛出警告 # returns the maximum of two strings # , but we declared the arguments should be float! maximum('hello', 'world') 'world' ","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:2:0","tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/"},{"categories":["Python"],"content":"变量的类型提示语法 在 Python 3.6 之前，如果要给一个变量加上类型提示只能使用 Type comments，也就是在注释里面用 # type ... 声明1，但在 PEP 526 中提出了变量的类型提示语法，和函数参数的语法是类似的3 a: int # undefined typed value a: int = 0 # typed value with default value a 0 类似的，我们可以通过 module 的 __annotations__ 属性访问类型提示信息 __annotations__ {'a': int} ","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:3:0","tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/"},{"categories":["Python"],"content":"常见使用场景 ","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:4:0","tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/"},{"categories":["Python"],"content":"简单的内建类型 这里说的简单内建类型就是：int、str 等，也可以是第三方库里面定义的类型。前面提到的 maximum 函数的 2 个参数就是用 float ","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:4:1","tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/"},{"categories":["Python"],"content":"Any 类型 Any 表示什么类型都有可能。但它跟 object 并不相同1 基本上我们可以认为一个不包含类型提示的函数的参数类型和返回类型都是 Any def foo(x): ... # it assumes: def foo(x: Any) -\u003e Any: ... ","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:4:2","tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/"},{"categories":["Python"],"content":"集合类型和映射类型 我们称集合里面的每个东西为 item，那么我们如何给集合和 item 都加上类型提示信息？==Python 采用 [] 记号支持这个特性，[] 里面指定 item 的类型==。比如，一个包含字符串的列表这个类型可以写作 list[str]，非常清楚。 注意：Python 3.9 发布了 PEP 585 4，允许我们直接使用自带的 list、dict 等而无需使用 typing 模块对应的类型。下面我列出了不同，更为详细的请查阅原文 4： \u003c Python 3.9 \u003e= Python 3.9 typing.Tuple tuple typing.Dict dict typing.List list typing.Set set typing.Frozenset frozenset typing.Type type typing.AbstractSet collections.abc.Set typing.ContextManager contextlib.AbstractContextManager typing.AsyncContextManager contextlib.AbstractAsyncContextManager typing.Pattern, typing.re.Pattern re.Pattern typing.Match, typing.re.Match re.Match 📒 typing 模块的部分特性将来会被移除。所以我后面会使用最新的语法✏️ string_list: list[str] = ['hello', 'world'] # tuple[type1, type2, ..., typen] with fixed size date: tuple[int, int, int] = (2023, 1, 11) string_count: dict[str, int] = { 'hello': 1, 'world': 2, } __annotations__ {'a': int, 'string_list': list[str], 'date': tuple[int, int, int], 'string_count': dict[str, int]} 下面的 join_str_list 函数接受一个包含字符串的列表，用空格将他们连接起来，然后返回这个字符串 def join_str_list(string_list: list[str]) -\u003e str: \"\"\" join all string in a list\"\"\" return ' '.join(string_list) print(join_str_list(string_list)) print(inspect.get_annotations(join_str_list)) hello world {'string_list': list[str], 'return': \u003cclass 'str'\u003e} 📒 在 Python 3.9+，我们可以使用 tuple[type1, ...] 表示类型全都是 type1 的任意长度的 tuple def sum_variable_integers(data: tuple[int, ...]): \"\"\" Sum all integers of a tuple\"\"\" sum_val = 0 for integer in data: sum_val += integer return sum_val print(sum_variable_integers((1, 2, 3))) print(sum_variable_integers((3,))) 6 3 众所周知，Python 的 list 可以放置任何类型，那么如何用类型提示说明这一点呢？可以用前面的 Any 类型： list[Any] 其实直接用 list 就可以，而且更为简洁 📒 如果这 3 个基本的集合类型不能满足你的要求，可以查阅 collections.abc 的文档了解更多 ","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:4:3","tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/"},{"categories":["Python"],"content":"类型别名（Type alias） 有时候，类型会变得很复杂而且很长，我们并不想要在每一个地方都写上一长串的类型提示。那么我们应该怎么做呢？一个通常的做法是为其取一个有意义的别名。定义别名的方法也很简单： AliasName = Type 拿前面的 date 日期类型作为例子。date 类型被我定义为一个 tuple，每个位置上的类型都是 int。那么，list[tuple[int, int, int] 表示一个日期的列表这个类型。为了让代码更有可读性，我们可以给他起个别名叫做 Date，看下面的例子： Date = tuple[int, int, int] DateList = list[Date] def print_date_list(l: DateList): \"\"\" Print all dates in the format `year-month-day` in the date list\"\"\" for year, month, day in l: print(f'{year}-{month}-{day}') print_date_list([(2022, 1, 1), (2023, 1, 3)]) print(inspect.get_annotations(print_date_list)) 2022-1-1 2023-1-3 {'l': list[tuple[int, int, int]]} 类型别名的语法很容易和定义全局变量混淆，所以 PEP 163（\u003e= Python 3.10）提出了更加 explicit 的方式5： AliasName: TypeAlias = Type from typing import TypeAlias Date: TypeAlias = tuple[int, int, int] ","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:4:4","tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/"},{"categories":["Python"],"content":"参数化的泛型 其他编程语言中经常使用大写字母比如 T 等表示参数化的泛型，在 Python 里面，我们使用 TypeVar 关键字，如同文档所说，一共有 3 种用法： T = TypeVar('T') # Can be anything S = TypeVar('S', bound=str) # Can be any subtype of str A = TypeVar('A', str, bytes)# Must be exactly str or bytes 总的来说，TypeVar 提供了 2 种方式让我们对泛型作出限制： 用 bound=some_type，那么我们就只能传入 some_type 的 subtype 直接指定允许的类型 📒 关于 subtype 的定义可以参考 PEP 4836，概括来说为 2 点：a）每个类型都是自己的 subtype。b）OOP 中，子类是父类的 subtype from typing import TypeVar GenericString = TypeVar('GenericString', str, bytes) def process(s: GenericString): \"\"\" The GenericString can be either str or bytes\"\"\" ... 📒 实际上 Python 已经帮你定义好了可能是 str 也可能是 bytes 的类型——typing.AnyStr ","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:4:5","tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/"},{"categories":["Python"],"content":"Optional 和 Union 类型 Optional[type1] 用于表示类型可能是 type1 也可能是 None。 Union[type1, type2, ...] 表示允许的类型可能是我们指定的多个可能类型的的任意一种，也就是逻辑上的「或」关系**。因此，Optional[type1] 其实和 Union[type1, None] 是一个意思 from typing import Optional, Union def parse(s: Union[str, int]) -\u003e Optional[int]: \"\"\" Parse `s` and get an integer value. The `s` may be a string. Return None if fail \"\"\" if isinstance(s, str): if not s.isdigit(): return None else: return int(s) elif isinstance(s, int): return s assert parse('foo') is None assert parse('123') == 123 assert parse(123) == 123 inspect.get_annotations(parse) {'s': typing.Union[str, int], 'return': typing.Optional[int]} 在 Python 3.10 里面，新引入了 |，可以用来代替 Union 的写法7。其他语言中也可以见到这种用法：比如 Rust 的 pattern matching 也采用了 | 分隔多个可能的 pattern。那么我们前面写的 parse 函数就可以写成下面这种形式： def parse(s: str | int) -\u003e int | None: \"\"\" Parse `s` and get an integer value. The `s` may be a string. Return None if fail \"\"\" if isinstance(s, str): if not s.isdigit(): return None else: return int(s) elif isinstance(s, int): return s inspect.get_annotations(parse) {'s': str | int, 'return': int | None} ","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:4:6","tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/"},{"categories":["Python"],"content":"可调用对象（Callable） 下面用函数作为例子，Python 的函数是 first-class object，所以函数可以是另一个函数的参数或者返回值。类型提示对此的支持是： Callable[[ParamType1, ParamType2], ReturnType] 让我们定义一个 apply 函数，入参为可调用对象和要处理的数据，将这个可调用对象应用在数据上 # from typing import Callable # Python \u003c 3.9 from collections.abc import Callable def apply(f: Callable[[str | int], int | None], data: list): \"\"\" Apply callable object on data. The `Callable[[str | int], int | None]` is the type hints of `parse` we aforementioned \"\"\" for d in data: print(f(d)) apply(parse, ['hello', 123]) None 123 ","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:4:7","tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/"},{"categories":["Python"],"content":"类 在 Python 3.11 里面8提出了 Self 类型，表示当前类的实例。有了 Self 之后在写 Python 的类的时候就很方便，我们可以在一个类的定义里面使用 Self 代指当前的类的实例。再也不需要用 TypeVar 先引入了 from typing import Self class Shape: def set_scale(self, scale: float) -\u003e Self: self.scale = scale return self 💡 Rust 也采用了 Self 来表示当前正在操纵的对象的类型，这经常可以在 impl block 里面看到 ","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:4:8","tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/"},{"categories":["Python"],"content":"总结 以上就是本篇博客的全部内容，我其实只谈到了我认为比较有用的一些类型提示使用场景，不少的高级特性比如 Static protocol9 等没有提到，这些内容留给读者自己探索。 我对类型提示的态度仍然是：当它变得复杂的时候就不用，除非这个代价是值得的。 根据我的开发经验，下面附上关于类型提示的几点建议🎯： 决定要加上什么类型提示的时候，考虑这个类型能够做什么。Python 3.8 提出的 static protocols 就很好解决了这点9。感觉有点像 Rust 中的 traits 对于函数返回类型，力求返回的类型越精确越好。设想一个返回类型为 Union[str, int]，我们还需要自己手动再进行一次类型检查，就显得这个类型提示不是很有必要 通过了代码静态类型检查也不意味着程序就没有 bug 了，软件测试才是软件工程领域保证软件质量的标准做法～ 将这份 cheatsheet 加入你的书签👍 ","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:5:0","tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/"},{"categories":["Python"],"content":"参考 PEP 484. Type Hints ↩︎ ↩︎ ↩︎ PEP 3107. Function Annotations ↩︎ PEP 526. Syntax for Variable Annotations ↩︎ PEP 585. Type Hinting Generics In Standard Collections ↩︎ ↩︎ PEP 613. Explicit Type Aliases ↩︎ PEP 483. The Theory of Type Hints ↩︎ PEP 604. Allow writing union types as X | Y ↩︎ PEP 673. Self Type ↩︎ PEP 544. Protocols: Structural subtyping (static duck typing) ↩︎ ↩︎ ","date":"2023-01-13","objectID":"/zh-cn/type-hints-in-python/:6:0","tags":["Python"],"title":"Python 的类型提示：是什么以及为什么","uri":"/zh-cn/type-hints-in-python/"},{"categories":["Python"],"content":"Python 中的解包操作符的简单介绍","date":"2022-12-05","objectID":"/zh-cn/unpacking-in-python/","tags":["Python"],"title":"Python 3.5 的解包操作符","uri":"/zh-cn/unpacking-in-python/"},{"categories":["Python"],"content":" 这一篇博客一开始是写在 jupyter notebook 里面而后转成 markdown 的。如果想要访问和运行本来的 notebook，请查阅这个仓库 ","date":"2022-12-05","objectID":"/zh-cn/unpacking-in-python/:0:0","tags":["Python"],"title":"Python 3.5 的解包操作符","uri":"/zh-cn/unpacking-in-python/"},{"categories":["Python"],"content":"引言 今天我想要聊聊 Python 中用于解包（Unpacking）的两个操作符号——* 和 ** ","date":"2022-12-05","objectID":"/zh-cn/unpacking-in-python/:1:0","tags":["Python"],"title":"Python 3.5 的解包操作符","uri":"/zh-cn/unpacking-in-python/"},{"categories":["Python"],"content":"基本用法 * 最为常见的用法是用来表示乘法。但我们也可以将 * 用于任意一个可迭代对象（iterable object）1上，表示我们想要提取里面所有的值 📒 Python 自带的可迭代对象包括：list, tuple, set, 和 dict ","date":"2022-12-05","objectID":"/zh-cn/unpacking-in-python/:2:0","tags":["Python"],"title":"Python 3.5 的解包操作符","uri":"/zh-cn/unpacking-in-python/"},{"categories":["Python"],"content":"Starred assignment/expression 随着 Python 3.0 的发布，Python 支持使用 * 来解包任意可迭代对象2。这个被称之为 Starred assignment，也叫做 Starred expressions。我也有看到称之为 parallel assignment 的。 我们可以在 = 左边声明一个特殊的变量表示捕获*所有变量**。看下面这个直观的例子： \u003e\u003e\u003e first, *rest, last = [1, 2, 3, 4, 5] \u003e\u003e\u003e first 1 \u003e\u003e\u003e rest [2, 3, 4] \u003e\u003e\u003e last 5 📒 语法很简单：一个星号后面紧跟着变量名 - *foo。我们可以在 = 左边任意位置放置它，但是只能最多使用一次这样的变量。以及，foo 的类型为 list 在我看来，Python 的这个特性很大程度上提高了代码的可读性 不过它也有一些局限： 我们不能仅仅在 = 左边使用一个 *foo 当成唯一的被赋值目标。= 左侧必须是一个 list 或者是 tuple 如果 = 右边的值不够用于解包的话，程序就会报错 下面的例子证明了这两点： *first = [1, 2, 3] Cell In [1], line 1 *first = [1, 2, 3] ^ SyntaxError: starred assignment target must be in a list or tuple # just add `,` would be fine # now the LHS is a tuple *first, = [1, 2, 3] first [1, 2, 3] first, second, *rest = [1] --------------------------------------------------------------------------- ValueError Traceback (most recent call last) Cell In [3], line 1 ----\u003e 1 first, second, *rest = [1] ValueError: not enough values to unpack (expected at least 2, got 1) 📒 常见的一个做法是将 * 和 _ 结合在一起使用（也就是 *_），表示我们不关心它捕获的变量 first, *_ = [1, 2, 3] first ","date":"2022-12-05","objectID":"/zh-cn/unpacking-in-python/:2:1","tags":["Python"],"title":"Python 3.5 的解包操作符","uri":"/zh-cn/unpacking-in-python/"},{"categories":["Python"],"content":"更进一步 从 Python 3.5 开始，我们可以在更多的情况下使用 * 和 **3 情况1⃣️：在函数调用里面，我们想要使用几次就可以使用几次 foo, bar = {'a': 1, 'b': 2}, {'c': 3, 'd': 4} dict(**foo, **bar) # dict is a function 📒dict 中的 keys 的优先级是右边大于左边。换句话说，后面出现的 key 的值总是会覆盖前面出现的。看下面这个例子 {**{'a': 1, 'b': 2}, **{'a': 3}} {'a': 3, 'b': 2} 📒当我们在函数调用里面使用 ** 的时候，需要注意个问题：我们需要确保没有重复的 key dict(**{'a': 1, 'b': 2}, **{'a': 3}) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) Cell In [5], line 1 ----\u003e 1 dict(**{'a': 1, 'b': 2}, **{'a': 3}) TypeError: dict() got multiple values for keyword argument 'a' 情况2⃣️：我们可以在 tuple/list/set/dict 字面值中使用。但是不能在 list/set/dict comprehensions 里面使用😺 # an example drawn from PEP 448 \u003e\u003e\u003e *range(4), 4 (0, 1, 2, 3, 4) \u003e\u003e\u003e [*range(4), 4] [0, 1, 2, 3, 4] \u003e\u003e\u003e {*range(4), 4} {0, 1, 2, 3, 4} \u003e\u003e\u003e {'x': 1, **{'y': 2}} {'x': 1, 'y': 2} {'x': 1, 'y': 2} matrix = [ [1, 2, 3] [4, 5, 6] ] [*sublist for sublist in matrix] Cell In [7], line 5 [*sublist for sublist in matrix] ^ SyntaxError: iterable unpacking cannot be used in comprehension ","date":"2022-12-05","objectID":"/zh-cn/unpacking-in-python/:2:2","tags":["Python"],"title":"Python 3.5 的解包操作符","uri":"/zh-cn/unpacking-in-python/"},{"categories":["Python"],"content":"总结 Python 的解包操作符让编程轻松很多。它提供了一种直观的解构可迭代对象的手段。在这个操作符的帮助下，我们可以避免一些愚蠢的索引错误🙅 ","date":"2022-12-05","objectID":"/zh-cn/unpacking-in-python/:3:0","tags":["Python"],"title":"Python 3.5 的解包操作符","uri":"/zh-cn/unpacking-in-python/"},{"categories":["Python"],"content":"参考 Python iterators ↩︎ PEP 3132. Extended Iterable Unpacking ↩︎ PEP 448. Additional Unpacking Generalizations ↩︎ ","date":"2022-12-05","objectID":"/zh-cn/unpacking-in-python/:4:0","tags":["Python"],"title":"Python 3.5 的解包操作符","uri":"/zh-cn/unpacking-in-python/"},{"categories":["Python"],"content":"Python 3.6 引入的 f-strings 的简单介绍","date":"2022-11-16","objectID":"/zh-cn/f-strings-in-python/","tags":["Python"],"title":"f-strings in Python 3.6","uri":"/zh-cn/f-strings-in-python/"},{"categories":["Python"],"content":" 这一篇博客一开始是写在 jupyter notebook 里面而后转成 markdown 的。如果想要访问和运行本来的 notebook，请查阅这个仓库 ","date":"2022-11-16","objectID":"/zh-cn/f-strings-in-python/:0:0","tags":["Python"],"title":"f-strings in Python 3.6","uri":"/zh-cn/f-strings-in-python/"},{"categories":["Python"],"content":"引言 字符串格式化绝对可以算得上日常生活中最为常用的功能之一，我们经常需要输出各种字符串还需要精确控制其格式 在一些过时的 Python 教程上，还可以看到使用 % 来格式化字符串。但其实在 Python 3.6 之后，f-strings 已经成了格式化字符串的最优解，优点包括： 可以在字符串字面值（String literal）里面内嵌表达式 可读性非常强 下面的简单对比就可以看出 f-strings 在可读性上的优势： name = \"Martin\" f\"My name is {name}\" 'My name is Martin' name = \"Martin\" \"My name is %s\" % name 'My name is Martin' 在上面的例子中我们分别用两种方式实现了同样功能的字符串输出。 看一眼 f-strings 就知道这个字符串是要输出名字（当然这要求你用的是有意义的变量，比如这里用的是 name）。而如果用旧的 % 字符串格式化字符串，则稍微显得不那么自然，我们首先会看到 %s 占位符，此时我们需要向右看才知道这里会放置什么变量。 这里的例子不长所以没啥差别，但是如果用 % 格式化的字符串很长的话，看代码就会有割裂感，你的眼睛需要来回左右移动。而且这不仅仅是阅读代码上不大自然，如果是自己写很长的字符串，还得核对一遍占位符和变量的顺序是否一致，这无疑是一个负担。😫 ","date":"2022-11-16","objectID":"/zh-cn/f-strings-in-python/:1:0","tags":["Python"],"title":"f-strings in Python 3.6","uri":"/zh-cn/f-strings-in-python/"},{"categories":["Python"],"content":"语法规则 f-strings 的语法规则很简单，下面我借用1里面的定义： f'\u003ctext\u003e{\u003cexpression\u003e\u003coptional !s, !r, or !a\u003e \u003coptional:format_specifier\u003e }\u003ctext\u003e...' 整体上来看可以将其归纳为 f\"...\" 或者 f'...' 这种形式。 像普通的字符串那样，我们可以选择用单引号 '' 或者双引号 \"\" 将字符串的内容括起来，当然 \"\"\"...\"\"\" 这种三个引号的也是 OK 的 至于其他部分，我们分成几个小节进行讲解： ","date":"2022-11-16","objectID":"/zh-cn/f-strings-in-python/:2:0","tags":["Python"],"title":"f-strings in Python 3.6","uri":"/zh-cn/f-strings-in-python/"},{"categories":["Python"],"content":"\u003ctext\u003e 放置字符串字面值，最简单的使用场景是不带任何表达式的字符串，此时 f-strings 就退化成了普通字符串。比如 f\"Hello world\"。当然这完全没有必要用 f-strings ","date":"2022-11-16","objectID":"/zh-cn/f-strings-in-python/:2:1","tags":["Python"],"title":"f-strings in Python 3.6","uri":"/zh-cn/f-strings-in-python/"},{"categories":["Python"],"content":"{\u003cexpression\u003e} 我们先考虑最简单的情况： 不包含任何可选部分（即上面语法中的 \u003coption...\u003e ）的 {expression} 上面其实已经指明了如何在 f-strings 里面嵌入表达式：只要将其放在 {} 里面即可。下面是一个简单的例子 left, right = 3, 5 f\"{left} + {right} = {left + right}\" '3 + 5 = 8' 用 {} 来充当占位符就很自然引申出一个问题——如果要在字符串里面输出 {} 这两个字符怎么办？ 答案也很简单，我们只要用 {{expression}} 这种格式即可 # 'hello' is an expression too. # Note that we need to use different quote syntax inside {} f\"{{'hello'}}\" \"{'hello'}\" 值得一提的还有，expression 里面不允许出现 : 和 ! 和 \\ 实际上 expression 里面也很少会包含这几个字符。\\ 的一个使用场景是用来转义 ' 或者 \"，但其实只要我们内外用的是不同的引号格式即可。至于 :，在 PEP1 里面举例可能应用场景是 lambda 表达式，此时我们只需用一对括号将 lambda 表达式括起来即可： # note that we need to add () around the lambda expression f\"{(lambda x: x + 1)(3)}\" '4' ","date":"2022-11-16","objectID":"/zh-cn/f-strings-in-python/:2:2","tags":["Python"],"title":"f-strings in Python 3.6","uri":"/zh-cn/f-strings-in-python/"},{"categories":["Python"],"content":"\u003coption...\u003e \u003coptional !s, !r, or !a\u003e 这几个是用来对 \u003cexpression\u003e 做类型转换的 {foo:!s} # it's equal to call str(foo) first {foo:!r} # similarily, call repr(foo) first {foo:!a} # similarily，call ascii(foo) first 这三个了解即可，一般也不会怎么用到，真要用的话还是自己直接调用对应的函数会比较直观，PEP 4981 里面自己也说了这三个只是为了最小化和之前的 str.format 的差别 \u003coptional:format_specifier\u003e 这一部分就是对前面 expression 的值进行“修饰”，比如我们想要控制小数的精度，或者做字符串对齐等等。下面我会简单讲讲其中几个部分。更为详细的完整支持选项可以参考2 注意这个部分的开头用的是 :（这也一定程度上解释了为什么 Python 不允许 expression 里面出现 :） 可以先看看 format_specifier 的语法描述： [[fill]align][sign][z][#][0][width][,][grouping_option][.precision][type] 在语法里面，[] 表示是可选项 [[fill]align] 主要用来对字符串进行输出对齐，这里的 fill 可以是任意的字符（默认情况下是空格）用于填充剩下的部分 注意：[[fill]align] 需要和 width 一起搭配使用，没有指定输出宽度的情况下是没有用的 align 支持下面这几种对齐方式： \u003c # left-aligned \u003e # right-aligned ^ # centered = # only valid for numeric types, pad between sign and digits f\"{-1:*^9}\" # set `fill` to *, and set width to 9 '***-1****' f\"{-1:*\u003e9}\" # set `fill` to *, and set width to 9 '*******-1' f\"{-1:*\u003c9}\" # set `fill` to *, and set width to 9 '-1*******' f\"{-1:*=9}\" # set `fill` to *, and set width to 9 '-*******1' [sign] 用于控制数值类型的符号位显示，支持下面这几种 + # both positive and negative - # only negative (default) space # a leading spaces for positive and minus sign for negative f\"{1:+}\" '+1' f\"{-1:+}\" '-1' assert f\"{1}\" == f\"{1:-}\" # because it's the default behavior [z] 在 Python 3.11 里面，增加了可选的 z 用来处理 -0.。因为调查显示3，大多数情况下我们都不想得到 -0.0 这样的输出 x = -0.0001 f\"{x:.1f}\" # set the precision to 1, so it will round to -0.0 '-0.0' x = -0.0001 f\"{x:z.1f}\" # with z, we will get 0.0 rather than -0.0 '0.0' [#] 和 [type] [#] 只对 integer、float 和 complex 类型有效 integer：会根据你选择输出的进制增加相应的前缀，比如二进制就增加 0b float 和 complex：总是输出小数点，就算小数点之后没有数字 如何用不同的进制显示？这就是 [type] 的工作： b # base 2 o # base 8 d # base 10 x # base 16, low-case letters X # base 16, upper-case letters f\"{15:#b}\" # represent 15 in base 2, use # to add prefix 0b '0b1111' f\"{15:#X}\" # represent 15 in base 16, use # to add prefix 0X '0XF' f\"{3:.0f}\" '3' f\"{3:#.0f}\" '3.' [0][width] width 是用来控制显示的最小长度，如果加上 0，那么就会在数值前面补 0 f\"{123:5}\" # width 5 ' 123' f\"{123:05}\" # width 5 with leading 0 '00123' f\"{123.1:5}\" # Note: the width includes the decimal point char '123.1' [grouping_option] 指定千分位分隔符，有两种选项45： _ , 在数字很大的时候，这两个千分位分隔符都会让可读性大大增强！ f\"{123456789:,}\" '123,456,789' f\"{1234.56789:,}\" '1,234.56789' f\"{123456789:_}\" '123_456_789' f\"{1234.56789:_}\" '1_234.56789' [.precision] 指定小数点之后要保留几位，会自动舍入 f\"{123.456:.2f}\" '123.46' ","date":"2022-11-16","objectID":"/zh-cn/f-strings-in-python/:2:3","tags":["Python"],"title":"f-strings in Python 3.6","uri":"/zh-cn/f-strings-in-python/"},{"categories":["Python"],"content":"总结 在我刚开始学习 Python 的时候，当时的教程都是在用 % 来格式化输出，后来的推荐是 str.format 方法。而到了 f-string 随着 Python 3.6 发布之后，似乎统一了字符串输出的 Best practice，大家都在用这个。这也是符合 Python 设计哲学的——应该只有一种显而易见的方式做到一件事🚀 ","date":"2022-11-16","objectID":"/zh-cn/f-strings-in-python/:3:0","tags":["Python"],"title":"f-strings in Python 3.6","uri":"/zh-cn/f-strings-in-python/"},{"categories":["Python"],"content":"参考 PEP 498. Literal String Interpolation ↩︎ ↩︎ ↩︎ Format Specifications ↩︎ PEP 682. Format Specifier for Signed Zero ↩︎ PEP 378. Format Specifier for Thousands Separator ↩︎ PEP 515. Underscores in Numeric Literals ↩︎ ","date":"2022-11-16","objectID":"/zh-cn/f-strings-in-python/:4:0","tags":["Python"],"title":"f-strings in Python 3.6","uri":"/zh-cn/f-strings-in-python/"},{"categories":["Python"],"content":"海象表达式的简单介绍","date":"2022-10-29","objectID":"/zh-cn/walrus-operator-in-python/","tags":["Python"],"title":"海象表达式简明教程（Python 3.8）","uri":"/zh-cn/walrus-operator-in-python/"},{"categories":["Python"],"content":" 这一篇博客一开始是写在 jupyter notebook 里面而后转成 markdown 的。如果想要访问和运行本来的 notebook，请查阅这个仓库 ","date":"2022-10-29","objectID":"/zh-cn/walrus-operator-in-python/:0:0","tags":["Python"],"title":"海象表达式简明教程（Python 3.8）","uri":"/zh-cn/walrus-operator-in-python/"},{"categories":["Python"],"content":"引言 今天要说的是在 Python3.8 中引入的新特性：海象运算符（Walrus operator），这是一个备受争议的特性，但它最后还是通过并发布了🤔 在 Python 中，赋值语句（=）并不是 expression 而是 statement。海象表达式则是 expression。关于 statement 和 expression 的区别可以简单理解为：expression 总是会返回值，而 statement 不返回值。 两者的区别可以看下面的代码： # `=` is a statement, so it will print no value x = 5 # `:=` is an expression, so it will evaluate to a value # not recommended :) (x := 5) 5 📒 这里海象表达式需要加上 () 是为了避免造成混淆。毕竟在 Python设计哲学-Zen 里面提到了一条：“There should be one– and preferably only one –obvious way to do it.\"。如果不加 () 就能使用的话，开发者就会陷入到该用哪一个的困惑之中🤕️ 在 C/C++ 中，= 是 expression。如果你有相关的编程背景的话，你可能对下面的代码不陌生 // = will store the value in the LHS(left-hand-side) variable. // , and it has the value of the LHS // so we store the result of `foo` function call to `a` // , then we check if `a` \u003e 0 while ( (a = foo(...)) \u003e 0 ) { ... } 但是在 Python 3.8 之前是无法做到类似的事情的，因为 = 在 Python 里面是一个 statement，并不会返回值。这就是海象表达式发挥作用的地方 🤩 ","date":"2022-10-29","objectID":"/zh-cn/walrus-operator-in-python/:1:0","tags":["Python"],"title":"海象表达式简明教程（Python 3.8）","uri":"/zh-cn/walrus-operator-in-python/"},{"categories":["Python"],"content":"语法规则 海象表达式的语法很简单：NAME := EXPRESSION。:= 左边放变量名，右边则是表达式。表达式的值会被绑定到 NAME 上。 这里的 NAME 不能是属性或者索引 # a dummy example. we bind `1 + 2 + 3` to `res` for future usage if (res := 1 + 2 + 3) \u003e 5: print(f\"res is {res}\") res is 6 class foo: val: int = 0 some_foo = foo() (some_foo.val := 1) Input In [4] (some_foo.val := 1) ^ SyntaxError: cannot use assignment expressions with attribute x = [1, 2, 3] (x[1] := 3) Input In [5] (x[1] := 3) ^ SyntaxError: cannot use assignment expressions with subscript 关于 NAME 的作用域 海象表达式不会引入新的作用域 🤩 NAME 可以在当前的作用域使用，同时有个例外：如果是在 list/dict/set comprehension 里面使用。则是是在 enclosing scope 里面. 可以看下面的例子： s = [1, 2, 3] # the list comprehension forms a new scope. # its enclosing scope is the global scope double_s = [item * 2 for item in s] # `item` is not in the global scope :) print(item) --------------------------------------------------------------------------- NameError Traceback (most recent call last) Input In [6], in \u003ccell line: 7\u003e() 4 double_s = [item * 2 for item in s] 6 # `item` is not in the global scope :) ----\u003e 7 print(item) NameError: name 'item' is not defined s = [1, 2, 3] # the list comprehension forms a new scope. # its enclosing scope is the global scope double_s = [last := item * 2 for item in s] # so we can use `last` variable here print(last) 优先级规则：除了比 , 高，比其他的都低 x = 1, 2 x (1, 2) (x := 1, 2) x 1 ","date":"2022-10-29","objectID":"/zh-cn/walrus-operator-in-python/:2:0","tags":["Python"],"title":"海象表达式简明教程（Python 3.8）","uri":"/zh-cn/walrus-operator-in-python/"},{"categories":["Python"],"content":"适用场景 📒 结合参考了1的内容和平常的编程经验。感觉海象表达式最方便的还是：处理返回值可能为 None 的函数 对于返回值可能为 None 的函数，以前经常是先用 = 赋值语句保存函数的返回结果。不为 None 的时候要使用返回值来进行下一步处理。此时代码看起来大概是这样： some_thing = foo(....) if some_thing: ... else: ... 下面用 re 库举例子 import re # define a regex pattern to extract digits in a string DIGIT_PATTERN = r'\\d+' text = 'There are 10 dogs' # re.search will return None if no match was found. match = re.search(DIGIT_PATTERN, text) if match: # group(0) will return the entire match print(f\"Find match: {match.group(0)}\") else: print(\"Not match was found\") Find match: 10 为了能在后面使用 match.group() 的时候 Python 解释器不会返回 AttributeError: 'NoneType' object has no attribute 'group' 错误，我们不得不用一个中间变量 match 暂时保存 re.search 的返回值对其进行检查，显得似乎有点冗余。我们无法直接将他们连起来：re.search(DIGIT_PATTERN, text).group(0) 📒 插点题外话：在 Rust 里面，可能返回 None 的返回类型是 Option\u003cT\u003e。我们可以使用 ? 来处理这种情况，它会尝试提取里面的值，如果失败了就会尽早终止报错。所以在 Rust 里面，我们可以这样（假设 Rust 也有类似的 API）：re.search(DIGIT_PATTERN, text)?.group(0) 🍺 另外一点是：可读性稍弱，当然这是个人的主观感受。有一点不舒服是：只有可能在 match is not None 的时候我们才会使用 match 变量，我们不会在 else 分支里面使用。但是如果很快地从上往下看代码的话，单独另起一行的 match = ... 就像是后面都可以使用一样🤣 此时我们可以选择用 := 来绑定其返回值 if match := re.search(DIGIT_PATTERN, text): # group(0) will return the entire match print(f\"Find match: {match.group(0)}\") else: print(\"Not match was found\") Find match: 10 1 里面提到支持 := 的一个理由是：调查显示，开发者往往喜欢写比较少行的代码而不是让代码更短。这里我们就少写了一行代码。同时看一眼就知道 match 的作用域👏 类似的，在 while 循环中我们也可以借用这个特性 val = foo(...) while val: # do something while val is not None val = foo(...) ","date":"2022-10-29","objectID":"/zh-cn/walrus-operator-in-python/:3:0","tags":["Python"],"title":"海象表达式简明教程（Python 3.8）","uri":"/zh-cn/walrus-operator-in-python/"},{"categories":["Python"],"content":"🆚 = 几个值得一提的不同： = 是 statement，:= 是 expression。这也决定了他们的适用场景是不同的 只有 = 支持foo = bar = 1 这种连续使用的情况；而且 = 左边可以是 foo.bar 这种属性，或者是 foo[1] 这种索引的形式，但是 := 左边只能是一个简单的变量名 = 支持 += 这种 augmented 的形式，但是 := 不行 ","date":"2022-10-29","objectID":"/zh-cn/walrus-operator-in-python/:4:0","tags":["Python"],"title":"海象表达式简明教程（Python 3.8）","uri":"/zh-cn/walrus-operator-in-python/"},{"categories":["Python"],"content":"总结 在我看来，海象表达式在我前面提到的引用场景中是挺有用的（推荐使用👍），可读性提高不少🚀。但是1中的某些例子我觉得可能是负优化了👀 ","date":"2022-10-29","objectID":"/zh-cn/walrus-operator-in-python/:5:0","tags":["Python"],"title":"海象表达式简明教程（Python 3.8）","uri":"/zh-cn/walrus-operator-in-python/"},{"categories":["Python"],"content":"参考 PEP 572. Assignment Expressions ↩︎ ↩︎ ↩︎ ","date":"2022-10-29","objectID":"/zh-cn/walrus-operator-in-python/:6:0","tags":["Python"],"title":"海象表达式简明教程（Python 3.8）","uri":"/zh-cn/walrus-operator-in-python/"},{"categories":["Python"],"content":"Python 3.10 的 pattern matching 的简单介绍","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/","tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/"},{"categories":["Python"],"content":" 这一篇博客一开始是写在 jupyter notebook 里面而后转成 markdown 的。如果想要访问和运行本来的 notebook，请查阅这个仓库 ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:0:0","tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/"},{"categories":["Python"],"content":"引言 今天我想要谈一下 Python 3.10 提出的新特性1——模式匹配🎉 学习过 C 语言的人想必对下面的 switch 语句不陌生， switch (expression) { case constant_1: // statements break; case constant_2: // statements break; // Fall through // the value of the expression can be either constant_3 or constant_4 :) case constant_3: case constant_4: // statements default: // default statements } 概括一下，C 语言的 switch 语句的几点规则： expression 必须是 int 或者 char 类型；constant 必须是 int 或 char 常量 switch 语句的执行过程： 计算出 expression 的值，拿着这个值从上到下检查是否和某一条 case 语句的 constant 相等，如果一样就会执行里面的 statements 和后面的 case 语句的 statements，除非遇到了 break。这个特性叫做 Fall through，我们可以利用这个特性，将多个 case 语句堆叠在一起，表示逻辑上的「或」的关系 存在 default 表示默认情况，用于兜底，当前面的 case 语句都匹配失败的时候执行 Python 则并没有提供 switch 语句，我们可以用 if...elif..elif..else 达到同样的效果，举例来说，假设我们要根据 list 的长度执行不同的操作，我们可以这么写： some_list = [1, 2, 3, 4, 5] if len(some_list) == 1: # do something when the length is 1 ... # or more pythonic way: elif len(some_list) in [3, 5]: elif len(some_list) == 3 or len(some_list) == 5: # do something when the length is 3 or 5 ... else: ... 上面这一连串的 if...elif..elif..else 其实可读性稍微差些，另外它还违反了 DRY(Don’t repeat yourself) 原则，我们多次写下 len(some_list) 当然我们可以选择先用一个变量 length 记住 some_list 的长度，这样就可以让我们少打一些代码，但若情况更复杂写，这个技巧也不适用了 解决上面的一个更优雅的方式就是本文要讲到的：Pattern matching ⬇️ match len(some_list): case 1: # do something when the length is 1 ... case 3 | 5: # do something when the length is 3 or 5 ... case _: # equal to the `default:` ... ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:1:0","tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/"},{"categories":["Python"],"content":"基本的语法 下面我给出 Pattern matching 的基本语法 match subject: case \u003cpattern_1\u003e: \u003caction_1\u003e case \u003cpattern_2\u003e: \u003caction_2\u003e case \u003cpattern_3\u003e: \u003caction_3\u003e # [Optional] wildcard to cover all situations case _: \u003caction_wildcard\u003e 从语法上看，和前面 C 语言的 switch 语句差不多。区别在于： 虽然都是从上到下进行检查，但是 Python 的 pattern matching 不存在 Fall through 情况，只会执行匹配的 case 语句里面的代码。执行完就退出。所以也不用在每个 case 的代码块里最后加一个 break 没有 default 关键字，但是我们可以用 case _ 来捕获所有的情况，这其实用到了后面会讲到的 Wildcard pattern 这里的 subject 和 pattern 比 C 语言的强大多了，不仅仅是整型和字符类型，pattern 彼此之间还可以组合嵌套。后面会对其进行详细说明 ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:2:0","tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/"},{"categories":["Python"],"content":"Patterns 在 pattern matching 里面，Pattern 主要有下面两个作用： 对 subject 的结构进行约束（structure constrait） 可以使用变量绑定 subject 的某些部分（bind variables），用于后续的处理，见 Capture pattern 下面我们对不同的 patterns 进行探讨 :) 为了避免造成困惑，有必要提前进行一下说明：在 pattern matching 匹配序列时候，() 和 [] 都是可选的。比如，case foo, bar 和 case (foo, bar) 和 case [foo, bar] 都是等价的。这点和我们给序列做 unpacking 的时候一致 ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:3:0","tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/"},{"categories":["Python"],"content":"Capture pattern Capture pattern 的意思是说我们在检查 pattern 是否匹配的时候，可以用变量名绑定到它的任意一个部分，我们就可以在匹配成功之后使用这些变量 some_list = [\"foo\", \"bar\"] match some_list: # we want to match a seq which has length = 2 # , we also use `first` and `second` to capture \\ # the 1st and 2nd elements here. case [first, second]: # we can access first, second now print(f'the 1st element: {first}, 2nd element: {second}') the 1st element: foo, 2nd element: bar 经常跟序列打交道的人想必对下面的代码不会陌生，我们可以用 *\u003cname\u003e 来 unpacking *before, last = [1, 2, 3, 4] assert last == 4, \"Error\" first, *middle, last = [1, 2, 3, 4] assert first == 1 and last == 4, \"Error\" first, *rest = [1, 2, 3, 4] assert first == 1, \"Error\" 类似的，在 pattern matching 里面也可以这样，用一个变量捕获多个值 some_list = [\"foo\", \"bar\", \"another_foo\", \"another_bar\"] match some_list: # we want to match a seq # , we also use `*rest` to capture the remaining elements case [first, *rest]: print(f'the 1st element: {first}, 2nd element: {rest}') the 1st element: foo, 2nd element: ['bar', 'another_foo', 'another_bar'] ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:3:1","tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/"},{"categories":["Python"],"content":"Literal pattern Literal pattern 指的是我们可以指定字面值来对 Pattern 进行约束。这里的字面值可以是 number literal, string literals, True, False 还有 None 📒 对于 number literals 和 string literals 这两者 Python 会使用 == 进行比较，而对于 True/False/None 这三个则是使用 is 来进行判断。注意这个细节 some_list = [\"foo\", \"bar\"] match some_list: # we want to match a seq which has length = 2 # , the 1st element should be equal to \"foo\" # , and we use `second` to capture the 2nd element case [\"foo\", second]: print(f'the 2nd element: {second}') the 2nd element: bar some_list = [True] match some_list: case [1]: print(f'Matched, 1 == True') Matched, 1 == True ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:3:2","tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/"},{"categories":["Python"],"content":"Wildcard pattern 这个其实在 Python 里面挺常见，我们常常使用 _ 表示我们不关心某个变量是多少。在 pattern matching 里面，_ 会和任何的东西匹配，但是不会绑定任何变量 some_list = [\"foo\", \"bar\"] match some_list: # we want to match a seq which has length = 2 # , the 1st element should be equal to \"foo\" # , and we use `_` to ignore the 2nd value case [\"foo\", _]: print(f'the 2nd value: {_}') # you should see empty output because we aren't binding value here the 2nd value: 另外一个常见的用法就是之前出现过的 case _，因为 _会匹配任何情况，所以常常把 case _ 放在最后表示默认情况 some_list = [\"foo\", \"bar\"] match some_list: # this case branch will not be matched case [\"bar\", _]: print('Match successfully') case _: print('Default case') Default case ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:3:3","tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/"},{"categories":["Python"],"content":"Or pattern 就像 if 条件语句我们可以使用 or 表示多种可能的匹配情况，在 pattern matching 里面我们也有类似的语法。跟其他大多数语言一样，Python 选择使用 | 来表达「或」的逻辑关系。我们可以很方便声明备选项 some_list1 = [\"foo\"] some_list2 = [\"bar\"] match some_list1: # we want to match a seq which has length = 1 # , the 1st element can be \"foo\" or \"bar\" case [\"foo\" | \"bar\"]: print('[First match] Match foo or bar') match some_list2: case [\"foo\" | \"bar\"]: print('[Second match] Match foo or bar') [First match] Match foo or bar [Second match] Match foo or bar 上面的 Or pattern 的缺点是：我们无法知道我们具体匹配到了什么哪一个 ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:3:4","tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/"},{"categories":["Python"],"content":"As pattern 在上一个例子中，我们可能匹配到多个选项，那么如何知道我们具体匹配到哪一个选项呢？因为我们可能需要根据具体匹配到的东西来决定要如何处理。在 pattern matching 里面，可以使用 as 来绑定变量 some_list = [\"foo\"] match some_list: # we want to match a seq which has length = 1 # , the 1st element can be \"foo\" or \"bar\" # we bind matched string literal with `matched_element` case (\"foo\" | \"bar\") as matched_element: print(f'Match {matched_element}') ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:3:5","tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/"},{"categories":["Python"],"content":"Class pattern Python 是一个动态类型语言，有时我们也会有需要根据类型来决定是否要匹配的时候。我们当然可以选择自己在后面使用 isinstance() 来判断，但还有更好的方法。下面我将从从基本的例子出发带大家看看如何加上类型约束 some_list = [\"foo\", 1, 3.14] match some_list: # match without type constraints case [s, v1, v2]: if isinstance(s, str) and isinstance(v1, int) and isinstance(v2, float): print(f'Match {s} - {v1} - {v2}') Match foo - 1 - 3.14 第一个写法：考虑用 Capture pattern，类型约束放代码块里 some_list = [\"foo\", 1, 3.14] match some_list: # match with type constraints case [str() as s, int() as v1, float() as v2]: print(f'Match {s} - {v1} - {v2}') Match foo - 1 - 3.14 此时我们在 pattern 里加上类型约束，这里写法上类似 Literal pattern，我们在对应位置声明我们想要匹配的类型，同时为了后面能输出，我们还需要 as 关键字将其绑定到变量上。但上面的写法过于冗长，好在 Python 为我们提供了语法糖🍬 some_list = [\"foo\", 1, 3.14] match some_list: # match with type constraints case [str(s), int(v1), float(v2)]: print(f'Match {s} - {v1} - {v2}') Match foo - 1 - 3.14 ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:3:6","tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/"},{"categories":["Python"],"content":"Mapping pattern 前面都是对于一个序列的匹配，这里则是对 dict 的匹配。相信在看完前面的各种 pattern 的例子之后，理解 dict 的匹配也没有什么难度。但有下面几点注意事项： dict 的匹配是通过限制 Key-Value 的结构。其中 Key 必须是字面值或者枚举类型的值（出于性能的考量），Value 则没有这个限制 使用 **\u003cname\u003e 来捕获我们没有写在 pattern 里面的 Key-Value pair。否则默认是忽略掉的 但是 **_ 是不行的，因为本来就忽略掉，而 **_ 中的 _ 表示不绑定任何匹配的东西，纯粹是多此一举 some_dict = { 'first_name': 'foo', 'second_name': 'bar' } match some_dict: case {'first_name': first_name}: print(f'[First match] The first_name: {first_name}') match some_dict: case {'first_name': first_name, **rest}: print(f'[Second match] The rest: {rest}') [First match] The first_name: foo [Second match] The rest: {'second_name': 'bar'} ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:3:7","tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/"},{"categories":["Python"],"content":"Value pattern 使用「有名字的变量」作为参数值或澄清特定值的含义是很好的编程风格，这是 Literal pattern 欠缺的。比如 case (HttpStatus.OK, body) 是比 case (200, body) 好的 在 Python 里面要实现 Value pattern 的挑战是要和前面的 Capture pattern 区分开，要让 Python 可以区分我们是要加一个「有名字的常量」这个约束还是我们在使用 Capture pattern 绑定变量。关于这点的讨论可以参见2 最后 Python 提供的解决方案是一个受限的 Value pattern，它仅支持 foo.bar 这种形式的 Value pattern。比较常见的就是用于枚举类型，看下面这个例子 from enum import Enum class HttpStatusCode(Enum): CONTINUE = 100 OK = 200 some_list = [HttpStatusCode[\"OK\"]] match some_list: case [HttpStatusCode.OK as status_code]: print(f\"Receive {status_code}\") Receive HttpStatusCode.OK ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:3:8","tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/"},{"categories":["Python"],"content":"将 Pattern matching 用在一个类上 如果只能将 pattern matching 用在内建的类型上，似乎用处没有那么大。但其实 Python 还允许我们对自己自定义的类的对象使用 pattern matching。 考虑到应用场景，我们对一个对象做 pattern matching 的时候常常是想要检查这个对象是否为某个类，我们还可能关心它的某些字段，想要提取对应的字段的值。但是在 Python 里，这个实现起来有困难2，主要是类的字段非常多，大部分是 __repr__ 这种 magic methods，而且这些字段是无序的。因为是无序的，我们无法直接在 pattern 里面按位置绑定变量，看下面这个例子： class Point: \"\"\" A simple class represents a Point in a 2D\"\"\" def __init__(x: int, y: int): self.x = x self.y = y some_point = Point(1, 2) match some_point: # the intuitive way, we want to match a Point type # , and we want to bind the `x` and `y` and their two fields respectively case Point(x, y): print(f\"The x: {x}\") print(f\"The y: {y}\") --------------------------------------------------------------------------- TypeError Traceback (most recent call last) Input In [17], in \u003ccell line: 7\u003e() 4 self.x = x 5 self.y = y ----\u003e 7 some_point = Point(1, 2) 9 match some_point: 10 # the intuitive way, we want to match a Point type 11 # , and we want to bind the `x` and `y` and their two fields respectively 12 case Point(x, y): 13 print(f\"The x: {x}\") 14 print(f\"The y: {y}\") TypeError: Point.__init__() takes 2 positional arguments but 3 were given Python 提供了两种解决办法，从语法上看，跟我们在调用函数的时候非常像：我们可以选择按照位置传递参数，也可以选择用 foo=bar 这种形式 先说简单的这种：用 foo=bar 的形式对字段进行约束，并且绑定变量到字段上。 foo=bar 的意思是我们要求这个类有 foo 字段，同时我们想要将 bar 绑定到实例上的 foo 字段上 class Point: \"\"\" A simple class represents a Point in a 2D\"\"\" def __init__(self, x: int, y: int): self.x = x self.y = y some_point = Point(1, 2) match some_point: # the intuitive way, we want to match a Point type # , and we want to bind the `x` and `y` and their two fields respectively case Point(x=x, y=y): print(f\"The x: {x}\") print(f\"The y: {y}\") The x: 1 The y: 2 另外一种解决办法是：修改类的 __match_args__ 属性，该属性规定了字段的顺序 class Point: \"\"\" A simple class represents a Point in a 2D\"\"\" # we tell python that the order is first \"x\" and then \"y\" __match_args__ = (\"x\", \"y\") def __init__(self, x: int, y: int): self.x = x self.y = y some_point = Point(1, 2) match some_point: # the intuitive way, we want to match a Point type # , and we want to bind the `x` and `y` and their two fields respectively case Point(x, y): print(f\"The x: {x}\") print(f\"The y: {y}\") The x: 1 The y: 2 如果你对 @dataclass 很熟悉的话3，上面的代码可以大大简化，看下面 from dataclasses import dataclass @dataclass(match_args=True) class Point: \"\"\" A simple class represents a Point in a 2D\"\"\" x: int y: int print(f\"The order is {Point.__match_args__}\") some_point = Point(1, 2) match some_point: # the intuitive way, we want to match a Point type # , and we want to bind the `x` and `y` and their two fields respectively case Point(x, y): print(f\"The x: {x}\") print(f\"The y: {y}\") The order is ('x', 'y') The x: 1 The y: 2 ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:4:0","tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/"},{"categories":["Python"],"content":"Guard 有时候我们不仅关心模式是否匹配，我们还要加上某些限制。 试考虑这么一种情况，你要匹配有两个 int 值的序列，但是第一个元素要比第二个大，那要怎么写呢？结合前面的 Class pattern，我们不难写出下面的代码： some_list = [3, 4] match some_list: case [int(first), int(second)]: if first \u003e second: ... else: print(\"Expect first \u003e second. Match failed\") Expect first \u003e second. Match failed 上面的写法固然可以，我们在代码块里面自己用 if 语句再检查一遍就行。但就像类型约束一样，Python 已经考虑到了这个需求，因此它提供了 Guard 💂‍♀️ 机制，使得我们可以把 if 语句这个判断挪到 pattern 的后面。这样可读性会强很多。遵循的语法规则如下所示： match subject: case \u003cpattern\u003e if \u003cexpression\u003e: ... 在 \u003cpattern\u003e 后面跟上一个 if 语句，用来在 \u003cpattern\u003e 匹配之后对其进行限制 注意 Python 在这里 Evaluate 的顺序 先看 \u003cpattern\u003e 是否匹配 匹配的话，如果有绑定变量就绑定对应的变量 此时再看 if \u003cexpression\u003e 语句是否返回 True。这里的 \u003cexpression\u003e 可以用上一步绑定的变量。 当且仅当 \u003cpattern\u003e 匹配 + if 语句返回 True 的时候才会执行相应的代码块。否则检查不通过，继续尝试匹配下一个 \u003cpattern\u003e some_list = [3, 4] match some_list: case [int(first), int(second)] if first \u003e second: print(\"Match successfully!\") ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:5:0","tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/"},{"categories":["Python"],"content":"总结 相比于使用 if...elif...elif...else，我会更喜欢 pattern matching 多一些，出于下面几点原因： 我们可以很方便地在匹配的时候绑定值用于后续处理 个人觉得可读性比较强，代码看起来没有那么乱 pattern matching 的各种 patterns 其实是可以嵌套组合的，这也是 pattern matching 真正强大的地方 上面就是 Python 3.10 引入的 pattern matching 的简短介绍🚀 ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:6:0","tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/"},{"categories":["Python"],"content":"参考 What’s new in Python 3.10 ↩︎ PEP 635 – Structural Pattern Matching: Motivation and Rationale ↩︎ ↩︎ dataclasses - documentation ↩︎ ","date":"2022-10-16","objectID":"/zh-cn/pattern-matching-in-python/:7:0","tags":["Python"],"title":"模式匹配简明教程（Python 3.10）","uri":"/zh-cn/pattern-matching-in-python/"},{"categories":["System-Programming"],"content":"引言 如果你一直都是是用动态语言，比如 Python、Javascript 这种，你很可能并不会注意到栈和堆的区别。因为这些语言有垃圾收集器（Garbage collector，GC）存在，会自动帮你做好内存管理，你只要集中注意力编程即可。坏消息是 GC 并不是没有成本的事情，实际上设计再好的 GC 算法，也会降低代码的性能。如果你接触编程的时间足够久，那么想必你可能会听到过什么“递归层数太深栈爆炸了”这种话，此时你可能会点开搜索引擎稍微了解一下栈和堆的区别，有可能你就刚好点进了这一篇文章 :) 📒 虽然 GC 会降低代码性能，但是免去了开发人员手动管理内存的心智负担，可以大大加速软件开发的速度，这是牺牲性能换取开发速度。但到了软件后期出现性能瓶颈的时候，就不得不研究如何重构甚至重写关键部分的代码提高性能了。 这里的栈和堆并不是数据结构里面的堆和栈，而是指内存管理的两种机制。了解栈和堆的细节差异有助于我们理解一些比较接近底层的编程语言，这里说的编程语言比如 Rust、C 和 C++ 等。在 Rust 中，最为重要的概念就是所有权的问题，Rust 的很多设计都是围绕它展开，掌握了所有权就能在学习 Rust 的时候如鱼得水😄。 ","date":"2022-09-19","objectID":"/zh-cn/what-is-the-heap-and-stack/:1:0","tags":["System-programming"],"title":"什么是堆和栈","uri":"/zh-cn/what-is-the-heap-and-stack/"},{"categories":["System-Programming"],"content":"程序在内存上的布局 我们知道，要运行一个程序必须将程序加载到内存里面，在程序运行的过程中，数据也是需要读取到内存上的，那么你有没有想过这一切在内存上是如何分布的呢？下面我会给出一个比较简单的示意图1：如下所示： 在上图中，不同部分存放的东西分别是： text：存放代码 data：存放初始化过的静态变量（Initialized static variables），比如全局变量、静态变量 bss：存放未经初始化的静态变量（Uninitialized static data），比如 C 语言的 static int i heap stack 关于栈和堆会在后面进行单独说明 📒 这里要记住的就是：栈和堆是在向彼此靠近的，栈是从高地址 -\u003e 低地址增长，而堆是低地址 -\u003e 高地址增长。这样你在看汇编代码的时候看到入栈时 sp 指针是做减法你就能理解了。 📒 虽然看起来，随着我们申请内存越来越多，栈和堆可能会冲突（因为他们在彼此靠近），但是实际上并不需要担心这个问题，因为：1）这个布局是发生在虚拟内存上的，现在的处理器一般是 64 位的，容量非常大。2）在它们冲突之前，很有可能你的物理内存早就耗尽了，还是先担心这个 ","date":"2022-09-19","objectID":"/zh-cn/what-is-the-heap-and-stack/:2:0","tags":["System-programming"],"title":"什么是堆和栈","uri":"/zh-cn/what-is-the-heap-and-stack/"},{"categories":["System-Programming"],"content":"栈 ","date":"2022-09-19","objectID":"/zh-cn/what-is-the-heap-and-stack/:3:0","tags":["System-programming"],"title":"什么是堆和栈","uri":"/zh-cn/what-is-the-heap-and-stack/"},{"categories":["System-Programming"],"content":"术语 Stack pointer(SP)：实际上是一个寄存器，里面存放栈顶的地址 Stack frame：当发生函数调用的时候就会创建 Stack frame。可以理解为它包含了函数调用的相关数据。比如函数的参数、函数的返回地址、函数的局部变量（除了分配在堆上的）等。一连串的 Stack frame 就构成了调用栈（Call stack） 入栈：在栈上申请空间 出栈：在栈上释放空间 ","date":"2022-09-19","objectID":"/zh-cn/what-is-the-heap-and-stack/:3:1","tags":["System-programming"],"title":"什么是堆和栈","uri":"/zh-cn/what-is-the-heap-and-stack/"},{"categories":["System-Programming"],"content":"栈上的内存管理是如何进行的 栈最大的特点就是先进后出（Last in first out, LIFO），这是我们在栈上申请空间和释放空间的时候的遵循的模式，这也是它叫做栈的原因。在内存上申请空间其实并不神秘，就是要标记哪些范围的地址是这个程序要用的。对栈来说，只要修改 stack pointer 的值即可，自然的，从栈底（下图中的 A）到栈顶（sp 指向的位置）就是我们栈上申请了的空间 下面的图1就展现了这个简单的逻辑： 这里仍要再次强调，栈是从高地址 -\u003e 低地址增长，所以上图从左到右是高地址 -\u003e 低地址，所以在栈上申请空间（入栈）的时候实际上 sp 是做减法. 函数调用也是用栈完成的，简单来说： 调用函数的时候：修改 sp 指针 -\u003e 构造被调用的函数的 stack frame，其中包括函数参数和其他一些必要的数据，将其入栈 -\u003e 进入 Callee 函数退出的时候：上面的过程反过来就行 对这个过程的详细解释可以参考 2 📒 在栈上申请内存空间的时候需要担心的问题是：不要申请太多导致栈爆了（也就是大名鼎鼎的 Stack Overflow）。这一点在写递归函数的时候要特别注意。你可以选择改成迭代的算法，也可以考虑增加栈的大小限制。比如在 Python 里面可以用 sys.getrecursionlimit() 来修改栈的大小限制。有的编程语言还会对尾递归进行优化，此时也可以选择将普通的递归函数改写为尾递归的形式。 ","date":"2022-09-19","objectID":"/zh-cn/what-is-the-heap-and-stack/:3:2","tags":["System-programming"],"title":"什么是堆和栈","uri":"/zh-cn/what-is-the-heap-and-stack/"},{"categories":["System-Programming"],"content":"以斐波那契数列的递归函数看栈的变化 CS 课程中讲解递归的时候一般都会讲到斐波那契数列，现在我们用 F(n) 表示斐波那契数列的第 n 个值，那么有： F(0) = 0 F(1) = 1 F(n) = F(n - 1) + F(n - 2) 以 F(4) 为例，递归计算的方式如下： F(4) = F(3) + F(2) = F(2) + F(1) + F(1) + F(0) = F(1) + F(0) + F(1) + F(1) + F(0) = 3 * F(1) + 2 * F(0) 如果我们忽略一些细节，感受函数调用的过程中栈的变化情况，那么大概如下所示： 注： 下面的 F(n) 表示每个函数自己的 stack frame stack: F(4) stack: F(4) | F(3) # F(4): enter F(3) stack: F(4) | F(3) | F(2) # F(3): enter F(2) stack: F(4) | F(3) | F(2) | F(1) # F(2): enter F(1), F(1) is the base case, ready to exit function call stack: F(4) | F(3) | F(2) # Function return, return to the body of F(2) stack: F(4) | F(3) | F(2) | F(0) # F(2): enter F(0), F(0) is the base case, ready to exit function call stack: F(4) | F(3) | F(2) # Function return, return to the body of F(2) stack: F(4) | F(3) | F(1) # F(3): enter F(1), F(1) is the base case, ready to exit function call stack: F(4) | F(3) # Function return, return to the body of F(3) stack: F(4) # Function return, return to the body of F(4) stack: F(4) | F(2) # F(4): enter F(2) stack: F(4) | F(2) | F(1) # F(2): enter F(1), F(1) is the base case, ready to exit function call stack: F(4) | F(2) # Function return, return to the body of F(2) stack: F(4) | F(2) | F(0) # F(2): enter F(0), F(0) is the base case, ready to exit function call stack: F(4) | F(2) # Function return, return to the body of F(2) stack: F(4) # Function return, return to the body of F(4) ","date":"2022-09-19","objectID":"/zh-cn/what-is-the-heap-and-stack/:3:3","tags":["System-programming"],"title":"什么是堆和栈","uri":"/zh-cn/what-is-the-heap-and-stack/"},{"categories":["System-Programming"],"content":"栈上存放的是什么数据 栈上的内存空间管理是通过修改 sp 指针的值实现的，很容易知道下面几点： 栈上的内存申请和释放都十分高效，为 O(1)，只要修改 sp 的值即可 栈的这种 LIFO 的逻辑比较简单，编译器其实就能帮我们处理好，作为开发者我们不需要干预这个过程 修改 sp 指针决定要申请多大的空间，意味着我们必须知道要申请的数据有多大（编译时要能确定），所以栈适合存放的数据是固定已知大小的。而大小不固定的数据是用堆来解决的 ","date":"2022-09-19","objectID":"/zh-cn/what-is-the-heap-and-stack/:3:4","tags":["System-programming"],"title":"什么是堆和栈","uri":"/zh-cn/what-is-the-heap-and-stack/"},{"categories":["System-Programming"],"content":"堆 栈的不足之处是：无法处理大小可变的数据，我们无法知道此时 sp 的值要修改为多少。 如何在大小可变的数据和栈之间搭建起桥梁呢？这就需要用到指针了。虽然实际存储的数据大小未知，但是指针的大小是固定已知的（只要保证寻址范围能覆盖到整个内存就行，一般跟机器字长相等），所以我们可以在栈上存储一个固定大小的指针，让这个它指向堆上存储的真正数据。 ","date":"2022-09-19","objectID":"/zh-cn/what-is-the-heap-and-stack/:4:0","tags":["System-programming"],"title":"什么是堆和栈","uri":"/zh-cn/what-is-the-heap-and-stack/"},{"categories":["System-Programming"],"content":"堆上的内存管理是如何进行的 正如前面提到的，在堆上申请内存其实就是在堆上找到一个足够大的空间，并返回这个位置的指针，而后指针入栈。 后面我们想要访问这个数据的时候，就对指针解引用即可。C 语言或者 Rust 里面的 * 操作符就是用来干这个的。不知道看到这里，以前难懂的指针是不是稍微能理解一点了 :) 不同于栈里面简单修改 sp 指针即可，堆上的内存管理复杂得多。包括下面几点： 堆上可以分配的内存的位置是任意的、大小也是任意的（不超过物理内存大小即可），而栈只要遵循先进后出就行。为了管理堆上已分配和待分配堆空间，我们需要设计相应的算法和数据结构，这就给堆上的内存管理带来很大的困难 在堆上申请空间的效率也比较低。最基本的，我们起码要找到一个足够大小的空间，这个找的过程肯定是比直接修改 sp 的值耗时的。 还要处理好「碎片化」的问题。因为堆上申请空间是这边分配一块那边分配一块，在重复的申请空间和释放空间的过程中，会在内存里面留下很多碎片。极端的情况是：碎片加起来的可分配大小满足你的要求，但是因为他们散落在内存各个地方无法利用从而导致了内存不足 📒 堆上可以分配的内存比较大，但是需要更良好的管理机制来处理这种比较复杂的情况。对开发人员来说，也造成了一定的负担，我们无法依赖编译器自动帮我们处理，而是要自己手动管理内存，比如在 C 语言中你进行了 malloc() 函数申请空间之后要是忘记用 free() 释放，那么你的程序就会存在内存泄露的问题。更别谈还有其他的诸如悬垂指针等问题。 ","date":"2022-09-19","objectID":"/zh-cn/what-is-the-heap-and-stack/:4:1","tags":["System-programming"],"title":"什么是堆和栈","uri":"/zh-cn/what-is-the-heap-and-stack/"},{"categories":["System-Programming"],"content":"堆上存放的是什么数据 对堆上内存空间的分配有一定了解之后，我们不难得出下面的几个结论： 堆上存放的是容量可变的数据。更灵活的同时，代价是牺牲了一点性能 有时候也可以是固定大小的数据，但是你不想放在栈上。为什么会有这种情况？比如，在 Rust 里面，栈上的数据是默认生成拷贝，有时候出于性能的考量，你可能想要把很大的数据放在堆上，避免多次拷贝带来的开销。不知道看到这里你们有没有想到我们常常说函数参数传递引用比传递值效率更高这个优化呢？ ","date":"2022-09-19","objectID":"/zh-cn/what-is-the-heap-and-stack/:4:2","tags":["System-programming"],"title":"什么是堆和栈","uri":"/zh-cn/what-is-the-heap-and-stack/"},{"categories":["System-Programming"],"content":"总结 栈和堆都是内存管理里面的概念，他们跟数据结构里的栈和堆的概念不一样。栈之所以叫做栈是因为我们在进行内存申请和分配的时候都遵循 LIFO 模式，而堆这个名字则是体现了堆上面的数据毫无组织。 通常来说，在栈上申请和释放内存空间是比较高效的。为此，Rust 里面默认都是在栈上操作 栈上一般放「固定大小」的数据，堆上一般放「大小可变」的数据。但是有时候出于性能的考量，也会在堆上存放固定大小的数据 在 CS 这门学科里面，经常可以看到分层的设计，比如计算机网络的 OSI 模型。包括编程语言本身也可以分为高级语言和低级语言。6.172 性能工程的老师说的一句话分享给你们—— “很多时候你要学好这一层的东西是必须了解下面一层的东西，你不一定要会用下一层的东西，但是知道下一层的细节会帮助你学这一层”。至少对我来说，知道了栈和堆的区别之后，下面的几个问题在我看来有了很合理的解释： C/C++ 语言的指针是用来干什么的？他们为什么存在？ 为什么尾递归优化会存在？为什么在写递归函数的时候都要考虑递归层数太深的问题？ 为什么 Rust 默认数据放在栈上？ 为什么以前会看到 C/C++ 传递函数参数的时候要用引用这种说法，说这样会比较快？ 📒 在 CS 里面，我认为最重要的概念就是封装。逐层封装，对上一层隐藏细节的这种设计实在很不错。 选择带有 GC 好上手但效率较低的语言还是选择自己手动管理内存让代码效率更高呢？这点其实取决于你手头的工作。如果要开发速度当然是前者了，如果注重性能那就是后者。当然，夹在中间的是没有 GC + 基本不用自己手动管理内存 + 效率高的 Rust 语言🚀，要不学点 Rust😉 ⚠️ 本文在组织的时候可以忽略了一些细节，我只讲了我认为比较重要的几点。如果想要了解更多，值得一看的材料参考下面的资料引用 ","date":"2022-09-19","objectID":"/zh-cn/what-is-the-heap-and-stack/:5:0","tags":["System-programming"],"title":"什么是堆和栈","uri":"/zh-cn/what-is-the-heap-and-stack/"},{"categories":["System-Programming"],"content":"参考 6.172. Performance engineering of software systems - Lecture 11 \u0026\u0026 Lecture 12 ↩︎ ↩︎ Stack frame ↩︎ ","date":"2022-09-19","objectID":"/zh-cn/what-is-the-heap-and-stack/:6:0","tags":["System-programming"],"title":"什么是堆和栈","uri":"/zh-cn/what-is-the-heap-and-stack/"},{"categories":["Vim"],"content":"How to use vim's macro system","date":"2022-07-02","objectID":"/zh-cn/vim-macro-101/","tags":["Vim"],"title":"Vim Macro 101","uri":"/zh-cn/vim-macro-101/"},{"categories":["Vim"],"content":"引言 在我学习 vim 的过程中，最具有启发意义的一句话是： vim 其实是一门编程语言 很早之前我就接触过 vim，但是当时 vim 的按键组合和按键的逻辑对我来说很难记忆，再加上 vim 的界面实在太过于复古，于是我就转向了比较现代的文本编辑器。但当我学完 Missing semester 的时候，我对 vim的看法完全改观：它远远不止是一个文本编辑器 这似乎和这篇博客要讨论的主题没有关系。但其实不是这样的，认识到 vim 是一门编程语言是一件重要的事情。程序员经常经常通过编程来完成很多枯燥重复的工作，不同人对编程语言的偏好各不相同。vim 也可以完成这样的任务，今天要讨论的宏就是。我希望看完这一篇之后 vim 也会被你们用来解决一些问题🚀 ","date":"2022-07-02","objectID":"/zh-cn/vim-macro-101/:1:0","tags":["Vim"],"title":"Vim Macro 101","uri":"/zh-cn/vim-macro-101/"},{"categories":["Vim"],"content":"什么是 vim 里面的宏 下面假定你对 vim 有一定的了解 : ) 在 vim 里面，我们可以用 . 重复上一次的“更改”，这里的“更改”一般指的是比较简单的操作，比如删除一个单词等。 但其实，vim 也提供了宏让我们可以重复执行一些比较复杂的操作，它会把我们的操作记录下来，存放到指定的寄存器里面。那么我们可以只录制宏一次而执行它很多次 ","date":"2022-07-02","objectID":"/zh-cn/vim-macro-101/:2:0","tags":["Vim"],"title":"Vim Macro 101","uri":"/zh-cn/vim-macro-101/"},{"categories":["Vim"],"content":"基本指南 ","date":"2022-07-02","objectID":"/zh-cn/vim-macro-101/:3:0","tags":["Vim"],"title":"Vim Macro 101","uri":"/zh-cn/vim-macro-101/"},{"categories":["Vim"],"content":"### 怎么录制一个宏 步骤： 在 Normal 模式下，按q\u003cregister\u003e. 这里的意思是说先按q 然后选择一个寄存器 register 来存放待会录制的宏 可以选用的寄存器 regitser 包括: 0-9, a-z, 和 \"。关于这里为什么没有大写字母我会在后面解释 开始录制宏，如果上一步正确执行的话，此时你应该会看到左下角显示 recording @\u003cregister\u003e。从此刻起，你所有的操作都会被录制下来 再次按下 q 退出录制 📒 要让自己录制的宏鲁棒性强一点，关键在于你在录制的时候要想想：不同的 文件可能会有哪些情况要处理，要保证自己的每一步都可以在各种不同的情况里面复现出来 ","date":"2022-07-02","objectID":"/zh-cn/vim-macro-101/:4:0","tags":["Vim"],"title":"Vim Macro 101","uri":"/zh-cn/vim-macro-101/"},{"categories":["Vim"],"content":"怎么查看宏的内容 前面提到，vim 会把我们录制的宏存放在指定的寄存器里面，所以查看宏的内容很简单，用一个简单的 :reg 命令就行，比如 :reg \u003cregister\u003e 里面你会看到一些奇怪的字符，比如： ^[ 是 \u003cESC\u003e 键 \u003c80\u003ekb 是 BAKESPACE 键 ","date":"2022-07-02","objectID":"/zh-cn/vim-macro-101/:4:1","tags":["Vim"],"title":"Vim Macro 101","uri":"/zh-cn/vim-macro-101/"},{"categories":["Vim"],"content":"怎么执行宏 在一个文件里面执行 @\u003cregister\u003e: 执行存放在 \u003cregister\u003e 这个寄存器里面的宏 @@: 执行我们上一次调用过的宏 如果想要多次执行的话，在命令的前面先输入 [COUNT] 表示要执行多少次。 e.g. 100@@ 的意思是：执行上一次调用的宏 100 次 有时候我们想要在这个文件里面重复执行直到整个文件都修改完，但是我们没有必要自己手动计算这个次数 [COUNT] 应该是多少，可以设置一个很大的值，超过的部分会被 vim 忽略 在多个文件里面执行 当然，如果只能在一个文件里面重复执行宏的话，能用它来解决的问题还比较局限。我们总不可能每次都要打开一个文件然后手动输入 @@ 执行宏。好在 vim 提供了方法让我们可以批量处理多文件 比如说现在我们想要编辑当前目录下的所有 txt 文件，只要在命令行输入 vim *.txt 就可以打开所有文件（每个文件对应一个 buffer，整体可以看成是一个列表）。在这个模式下我们可以一次编辑一个文件，编辑完毕之后按 :wn 保存当前文件的更改并跳转到下一个文件。但我们也能一次性对这个文件列表里的所有文件进行更改 此时我们位于文件列表的第一个文件，第一件要做的事情是以第一个文件文样本录制宏 注意录制完毕之后，需要使用 :edit! 命令撤销在录制宏对过程中对第一个文件的更改。因为我们之后会对文件列表中所有对文件应用我们对宏，如果没有这个撤销操作的话，第一个文件就会被更改两次 虽然界面看起来像是在编辑一个文件，但如果你要直接按 :x 保存退出的话就会弹出警告 输入命令： :bufdo execute \"normal @\u003cregister\u003e | update. 关于 bufdo 的说明可以在 vim 里面输入 :h bufdo 查看。可以理解为对所有的 buffer 执行操作 这里的 normal @\u003cregister\u003e 的意思就是在 Normal 模式下执行 @\u003cregister\u003e 里面的宏 更多的细节可以看这里 ","date":"2022-07-02","objectID":"/zh-cn/vim-macro-101/:4:2","tags":["Vim"],"title":"Vim Macro 101","uri":"/zh-cn/vim-macro-101/"},{"categories":["Vim"],"content":"怎么修改已经录制好的宏 简单情况 这里说的简单情况是，你只是想要在你本来录制好的宏后面追加一些操作。还记得之前我刻意跳过了把 A-Z 当作寄存器的这个情况吗？事实上，当你用大写字母的寄存器的时候，你录制的东西会追加在对应的小写寄存器的内容后面 复杂情况 此时你要编辑宏，但是要编辑的位置是在宏的中间，这也是可以实现的吗？当然，我们没有必要从头录制，宏其实本质上只是存储在寄存器里面的字符序列，vim 可以解读这些内容重复执行。我们要做的事情只是修改寄存器里面的内容而已。 具体步骤如下： 按下 G 跳转到当前文件的最后一行（其实别的行也可以，只是跳转到最后一行我们编辑宏的时候比较不会受到干扰），然后输入 :put \u003cregister\u003e 命令，对应寄存器里面的内容就会被粘贴在下一行 然后我们开始编辑就行 编辑完成之后（确保还在这一行），按下 :d \u003cregister\u003e 就可以把当前行的内容存回去 下面是我录制的一个简单的例子，我们来录制了一个宏放在寄存器 y 里面，功能是在当前行的末尾追加 world，现在我想要修改在当前行追加 hello world ","date":"2022-07-02","objectID":"/zh-cn/vim-macro-101/:4:3","tags":["Vim"],"title":"Vim Macro 101","uri":"/zh-cn/vim-macro-101/"},{"categories":["Vim"],"content":"和其他工具协同工作 在 Linux 中，我们可以将一些命令行工具和 vim 结合使用。一个使用场景比如：我们想要批量编辑一些文件，但是这个文件散落在不同的地方。那我们就可以使用 find 命令和 vim 做到这件事情。可以参考这个. 使用 find \u003cpattern\u003e -exec vim {} + 打开所有对应的文件 使用之前提到过的 bufdo 命令批量操作 ","date":"2022-07-02","objectID":"/zh-cn/vim-macro-101/:5:0","tags":["Vim"],"title":"Vim Macro 101","uri":"/zh-cn/vim-macro-101/"},{"categories":["Vim"],"content":"总结 这只是一个简单的关于 vim 里面宏的应用，这只是 vim 强大功能的冰山一角，当你掌握其他 vim 相关的功能的时候（比如搜索与替换，快速定位到某个位置），才能发挥出 vim 的最大效力。如果这篇博客可以让你对 vim 产生兴趣那就再好不过。别忘了一句著名的话：一开始我们挑选了我们喜欢的工具，后来工具会反过来塑造我们，它甚至影响着我们的思维😉 ","date":"2022-07-02","objectID":"/zh-cn/vim-macro-101/:6:0","tags":["Vim"],"title":"Vim Macro 101","uri":"/zh-cn/vim-macro-101/"},{"categories":["Compiler"],"content":"use the semantic actions to generate the symbol tables in ANTLR4","date":"2022-05-28","objectID":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/","tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/"},{"categories":["Compiler"],"content":"什么是 semantic actions 当 Parser 处理输入的代码的时候不仅要判断是否语法和句法都正确，还可以执行一些有用的操作，这些操作就叫做 Semantic actions。其实也就是一段代码，一般嵌入在在语法文件的规则里面。那么当 parser 应用这个规则的时候就会执行你设置的这段代码。换个角度理解，semantic actions 其实就是“触发器”，触发条件就是 parser 应用了对应的规则。 今天这篇文章要探讨的就是一个关于 semantic actions 的应用——实现一个简单的 symbol table，用到的工具是 ANTLR4。 ","date":"2022-05-28","objectID":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/:1:0","tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/"},{"categories":["Compiler"],"content":"什么是 symbol table 编译器在处理我们的代码的时候会在内部维护一个 symbol table，用来存储程序里面所有关于变量的信息：变量名、数据类型、变量所属的作用域等。symbol table 可以是下面这种形式： Symbol name Type Scope bar function, double extern x double function parameter foo function, double global count int function parameter sum double block local i int for-loop statement ","date":"2022-05-28","objectID":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/:2:0","tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/"},{"categories":["Compiler"],"content":"如何在 ANTLR 的语法文件里面注入动作 ANTLR4 是一个强大的 parse generator，我们只要编写好语法文件，就能让它帮我们自动生成 Parser，生成的 Parser 可以支持多种目标语言，比如我自己用的是 Python，那么最后生成的 Parser 就是 Python 文件。 ANTLR4 也提供了方法让我们可以在语法文件里面插入动作，这些动作最后都会被 ANTLR4 注入到生成的 Parser 文件里面。因此，动作用什么语言写取决于你输出 Parser 的目标语言是什么 ⚠️这里假定你对如何编写 ANTLR4 的语法文件（*.g4）有基本了解，不会进行赘述，本文只集中介绍如何在语法文件里面插入动作 ","date":"2022-05-28","objectID":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/:3:0","tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/"},{"categories":["Compiler"],"content":"动作注入的位置和方法 下面是简化的生成的 Parser 文件的代码模板。总体上来看，我们能注入的位置如下所示： \u003cheader\u003e class xxxParser(Parser): ... \u003cmember\u003e def rule(self): ... \u003caction\u003e 下面我对每个位置的不同语法进行说明： \u003cheader\u003e ANTLR4 本来就是用 Java 写的，所以如果你用的目标语言也是 Java 的话，这个会比较用得到。一般就是用来放 import 语句的。如果是 python 的话哪里都能 import 就比较没差。要往这个位置注入代码的格式如下（放在 *.g4 文件里面，下同） @header{ everything here will go to \u003cheader\u003e } \u003cmember\u003e 这个放的就是类的成员，可以是字段也可以是方法。ANTLR4 支持往 Lexer 和 Parser 分别或者同时注入代码。要往这个位置注入代码的格式如下： @members { everything here will go to \u003cmember\u003e in xxxLexer \u0026\u0026 xxxParser } @Lexer::members { everything here will go to \u003cmember\u003e in xxxLexer } @Parser::members { everything here will go to \u003cmember\u003e in xxxParser } ⚠️在我使用的 antlr4-python3-runtime 中（4.10），还无法在插入类的字段进行注释 \u003caction\u003e 在 ANTLR4 中，动作是用花括号 {\u003cspecific-language-here\u003e} 括起来的代码。正如前面提到的，看你最后输出的 Parser 想要是什么语言，你就用什么语言写动作。 动作一般会放在一条规则的某个 symbol 之后，意思是说在 parser 应用这条规则的时候执行到这里就执行相应的动作。这里的 symbol 可以是 terminal 也可以是 nonterminal。 我们可以用 $symbol.attr 的方式访问到对应的属性，有下面这几个： $terminal.text # origin text $terminal.type # an integer stands for type $terminal.attributes $terminal.line # the line number $terminal.pos # the position of the first char in the line，0-based $terminal.index $terminal.channel # the channel of this terminal, won't discuss in this post $terminal.int # return an interger if this terminal is an integer $nonterminal.text # origin text $nonterminal.start # 1st Token $nonterminal.stop # last Token $nonterminal.ctx # return context object ","date":"2022-05-28","objectID":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/:3:1","tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/"},{"categories":["Compiler"],"content":"举个例子 ⚠️下面都只会给出部分代码，完整的代码在我的 Github 项目 ⚠️因为这个项目要求把 warning 输出在其他输出前面，所以我用 warning_list 和 output_list 来存储，最后再一起输出 下面以普渡大学 2015 年的开设的编译器课程的项目作业为例，整个项目要实现一个 Micro 语言的编译器，关于 Micro 语言的语法，可以在这里看到。下面我会对步骤三的作业要求进行一个简单的介绍。 在这个作业中我们要构建一个 symbol table，并在相应的时刻输出相关的信息： 每当我们进入一个新的作用域之前（可以是函数，也可以是代码块），要进行相关的输出 如果遇到变量声明，就输出变量名和变量类型，有值的话也要输出。 如果声明的变量在外部作用域已经声明过的话要输出：SHADOW WARNING \u003cvar_name\u003e，适用于有嵌套的作用域出现的情况 如果在当前作用域已经有同名的变量，就要输出：DECLARATION ERROR \u003cvar_name\u003e。如果出现了这种情况，那么最后程序只输出这个信息 Symbol table \u003cscope_name\u003e name \u003cvar_name\u003e type \u003ctype_name\u003e name \u003cvar_name\u003e type \u003ctype_name\u003e value \u003cstring_value\u003e ","date":"2022-05-28","objectID":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/:4:0","tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/"},{"categories":["Compiler"],"content":"数据结构的选取及对应的方法 🤔先要解决的问题是，要用什么数据结构表示 symbol table？一个 symbol table 应该要满足下面的特点： 要能够支持高效率地查询 要能够支持高效率地插入，因为程序中可能包含大量的变量声明 要能够记录变量的作用域 不难想出，支持高效率查询和插入的数据结构就是「哈希表」。为了维护变量的作用域，可以把同个作用域下的变量放在同个哈希表里面，用一个列表来记住所有的变量作用域，也就是说是 [{scope1}, {scope2},...] 这样。同时维护一个 self.current_scope 来记住当前处于哪一个变量作用域里面。每当有一个新的作用域出现的时候，保存当前的作用域，往列表里插入一个新的作用域，再更新 self.current_scope。 📒 这里的 list 其实就是用来模拟栈 🤔我们要实现什么样的方法？起码要有下面这几个： lookup(identifier, value)：插入变量到当前的 symbol table 里面。根据这个项目作业的要求，还应该查询是否变量已经被声明过 enter_new_scope()：保存当前的 symbol table，进入下一个变量作用域并初始化为空 exit_scope()：清空当前的 symbol table，找到上一个 symbol table 所以对应 @parser:members 里面的代码如下 @parser::members { def init(self): self.current_scope = None self.block_count = 0 self.warning_list = [] # just for printing self.output_list = [] # just for printing self.declaration_error = '' def enter_new_scope(self): if not hasattr(self, '_scopes'): setattr(self, '_scopes', []) # save the current_scope import copy if len(self._scopes) \u003e 0: self._scopes.append(copy.deepcopy(self.current_scope)) self._scopes.append({}) self.current_scope = self._scopes[-1] def exit_scope(self): del self._scopes[-1] if len(self._scopes) \u003e 0: self.current_scope = self._scopes[-1] def lookup(self, identifier, value): # check all scopes found = False for scope in self._scopes[:-1][::-1]: #print(f\"the scope: {scope}\") if identifier in scope: found = True if found: self.warning_list.append(f\"SHADOW WARNING {identifier}\") # only record the 1st declaration error if identifier in self.current_scope and self.declaration_error == '': self.declaration_error = f\"DECLARATION ERROR {identifier}\" self.current_scope[identifier] = value } ","date":"2022-05-28","objectID":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/:4:1","tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/"},{"categories":["Compiler"],"content":"注入动作到变量声明中 🧐接下来就是要在对应的语法规则里面注入动作。我们想要在定义变量的时候输出相关的信息，所以我们先要观察在 Micro 语言中变量声明的规则是怎么样的，如下所示： ... var_decl : var_type id_list ';' ; var_type : 'FLOAT' | 'INT' ; any_type : var_type | 'VOID' ; id_list : id id_tail ; id_tail : ',' id id_tail | ; ... 可以看到，声明变量对应的是 var_decl 规则，一次可以声明一至多个变量，每一个变量之间用 , 隔开的，所以我们可以在这条规则的末尾最后注入如下的动作代码。 ⚠️要注意如果你也是使用 python 的话，这里所以缩进会有点怪，因为每一行都要从最左边开始，但最后生成的代码是没有问题的 ... var_decl : var_type id_list ';' { # NOTE: the indentation is correct, ANLTR4 will handle this for us :) # for all variable declarations, we should output the name \u0026\u0026 type # in the same variable declaration, it means all of the variables have the same type for variable in $id_list.text.split(','): self.lookup(variable, None) self.output_list.append(f\"name {variable} type {$var_type.text}\") } ; ... 我们用 $id_list.text 来获取本来的变量声明对应的文本，用 $var_type.text 来获取对应的变量类型 ","date":"2022-05-28","objectID":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/:4:2","tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/"},{"categories":["Compiler"],"content":"关于变量作用域的处理 下面以 program 规则为例（函数和代码块的类似），progarm 规则是 Micro 语法的起始规则，规定了 Micro 程序应该要有的大框架，规则如下所示： program : 'PROGRAM' id 'BEGIN' pgm_body 'END' ; 我们处理完 PROGRAM 这个 token 之后就可以初始化第一个作用域（全局作用域），最后要处理完程序再退出这个全局作用域，所以我们可以很快想到应该把动作注入在哪里 program : 'PROGRAM' id 'BEGIN' pgm_body 'END' ; ^ ^ | 2 最后插入相关的动作 program : 'PROGRAM' { self.init() self.output_list.append(\"Symbol table GLOBAL\") self.enter_new_scope() } id 'BEGIN' pgm_body 'END' { self.exit_scope() # output everything after we parsing this program if self.declaration_error != '': print(self.declaration_error) else: if len(self.warning_list) \u003e 0: print('\\n'.join(self.warning_list)) print('\\n'.join(self.output_list)) } ; ","date":"2022-05-28","objectID":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/:4:3","tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/"},{"categories":["Compiler"],"content":"扩展阅读 前面只涉及到简单的动作注入，ANTLR4 其实支持的功能还更多： 比如我们可以让 nonterminal 返回值 在同一条规则如果出现多个同名的 nonterminal 的话可以起名字 下面是来自书中的一个例子，就很好地展示了上面两个用法 e returns [int v] : a=e op=('*'|'/') b=e {$v = self.eval($a.v, $op, $b.v)} | a=e op=('+'|'-') b=e {$v = self.eval($a.v, $op, $b.v)} | INT {$v = $INT.int} | ID ","date":"2022-05-28","objectID":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/:5:0","tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/"},{"categories":["Compiler"],"content":"总结 从这个例子中我们可以学习到要如何在 ANTLR4 里面使用动作，生成 symbol table 只是其中一个运用。在代码里面注入动作是很符合直觉的做法，可以快速实现自己想要的功能。不过缺点也很明显，它是 language-dependent 的，也就是说你一旦换了 ANTLR 输出的目标语言，你注入的动作全部要改成新的目标语言。另外就是会让本来干净的语法文件一团糟。 ","date":"2022-05-28","objectID":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/:6:0","tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/"},{"categories":["Compiler"],"content":"参考 Symbol table - wiki 《ANTLR4 权威指南》 ","date":"2022-05-28","objectID":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/:7:0","tags":["Compiler","Course"],"title":"How to use the semantic actions to generate the symbol tables in ANTLR4","uri":"/zh-cn/how-to-use-antlr4-to-make-semantic-actions/"},{"categories":["Algorithm"],"content":"介绍了摩尔投票法","date":"2022-03-24","objectID":"/zh-cn/boyer-moore-majority-voting-algorithm-explained/","tags":["Algorithm"],"title":"摩尔投票法","uri":"/zh-cn/boyer-moore-majority-voting-algorithm-explained/"},{"categories":["Algorithm"],"content":"引言 今天又做到了 Leetcode 169. 多数元素 这一道题. 我依稀记得最优的解法叫做什么摩尔投票法. 但是我对它的印象竟然只有这个名字本身了 Orz. 对于这个算法本身倒是忘得一干二净. 于是我打算系统性地学习一下这个算法的原理, 并将它总结出来写成这篇博客. 不知道在哪里看到的一句话 : 当你开始教别人的时候, 你就真的掌握它了 所以, 我今天在这里打算跟大家分享这个算法, 并试图以浅显的语言让你也学会这个方法, 那么让我们开始吧 :) ","date":"2022-03-24","objectID":"/zh-cn/boyer-moore-majority-voting-algorithm-explained/:1:0","tags":["Algorithm"],"title":"摩尔投票法","uri":"/zh-cn/boyer-moore-majority-voting-algorithm-explained/"},{"categories":["Algorithm"],"content":"先从简单的方法开始聊起 如果从来没有听说过摩尔投票法, 我们会如何尝试解决这个问题, 起码要有下面的思路: 用空间换时间, 也就是用一个哈希表把每个元素出现的次数记下来, 然后我们再检查一遍我们的哈希表并找到其中出现次数大于 $\\lfloor n/2\\rfloor$ 的就可以.这样时间复杂度和空间复杂度都是 $O(n)$ 尝试对数组进行排序, 因为我们要找的元素超过了数组一半的长度, 这意味着它一定会出现在数组的中间位置. 这个也不难想到, 但是用排序的话虽然空间复杂度是 $O(1)$, 但是时间复杂度还是大于 $O(n)$ 的, *比如如果你采用的是快速排序的话, 时间复杂度就是 $O(nlogn)$ 那么有没有一种方法可以做到时间复杂度是 $O(n)$, 空间复杂度是 $O(1)$ 呢? 也就是结合了上面两个方法的优点. 有的, 答案就是摩尔投票法 ! ","date":"2022-03-24","objectID":"/zh-cn/boyer-moore-majority-voting-algorithm-explained/:2:0","tags":["Algorithm"],"title":"摩尔投票法","uri":"/zh-cn/boyer-moore-majority-voting-algorithm-explained/"},{"categories":["Algorithm"],"content":"摩尔投票法 问题描述: 假设我们的数组有 $n$ 个元素, 我们要找到其中出现次数超过一半的元素 算法流程: 从这 $n$ 个元素中选一个作为 candidate，记录它的票数为 votes = 1. 此时我们的数组中还有 $n-1$ 个元素, 我们每次都取出一个元素(记为 current), 并重复执行以下的步骤(一共 n-1 次) 将它和我们当前的 candidate 做比较, 如果它们的值一样, 那么 votes++, 也就是投赞同票 如果它们的值不一样, votes--, 也就是投反对票. 如果此时 votes = 0 的话, 那么 candidate \u003c- current, 也就是说我们让 current 成为了新的 candidate, 并记 votes = 1 最后 candidate 的值就可能是我们想要的出现次数超过一半的元素, 此时我们得再遍历一遍数组进行计数看它到底是不是 在看完上面的算法流程之后, 你可能跟我一样感到很困惑. 为什么这样最后我们就能找到出现次数超过一半的元素. 其实只要想明白一个原理就很简单 💡 出现次数超过 $\\lfloor n/2\\rfloor$ 次的元素如果存在, 此时数组中的其他元素一定是出现次数小于 $\\lfloor n/2\\rfloor$ 的 这句话有什么用呢 ? 因为摩尔投票法的做法其实就是投票 可以是投赞同票, 此时相当于我们在统计这个元素出现的次数 可以是投反对票. 相当于我们撤销了一个同意票, 就是抵消抵消抵消!!! 但是因为出现次数超过一半的元素加起来的票数(赞同票) \u003e 剩下所有不是的(反对票)这件事是一定成立的, 所以无论怎样最后赢的永远是出现次数超过一半的元素. 于是我们就找到了 :) 如果还是不懂可以看看下面的这个 GIF 图理解一下~ ","date":"2022-03-24","objectID":"/zh-cn/boyer-moore-majority-voting-algorithm-explained/:3:0","tags":["Algorithm"],"title":"摩尔投票法","uri":"/zh-cn/boyer-moore-majority-voting-algorithm-explained/"},{"categories":["Algorithm"],"content":"代码 class Solution { public int majorityElement(int[] nums) { if (nums.length \u003c 2) { return nums[0]; } int candidates = nums[0]; int votes = 1; // step 1. start to vote for (int i = 0; i \u003c nums.length; i++) { if (nums[i] != candidates) { votes -= 1; if (votes == 0) { candidates = nums[i]; votes = 1; } } else { votes += 1; } } // step2. check int occurs = 0; for (var val: nums) { if (candidates == val) { occurs += 1; } } if (occurs \u003e= nums.length / 2) { return candidates; } else { return -1; } } } ","date":"2022-03-24","objectID":"/zh-cn/boyer-moore-majority-voting-algorithm-explained/:4:0","tags":["Algorithm"],"title":"摩尔投票法","uri":"/zh-cn/boyer-moore-majority-voting-algorithm-explained/"},{"categories":["Algorithm"],"content":"FAQ Q: 为什么还需要第二轮检查呢? 能不能直接看 votes 呢? A: 不能, 首先这个「出现次数超过一半」的元素不一定存在. 比如 [1,2,3]. 另外就算它存在, 遍历完数组之后, 此时 votes 也不一定是它的真实票数. 比如 [1, 2, 2, 2, 3] 最后 3 会投反对票导致 votes - 1 ","date":"2022-03-24","objectID":"/zh-cn/boyer-moore-majority-voting-algorithm-explained/:5:0","tags":["Algorithm"],"title":"摩尔投票法","uri":"/zh-cn/boyer-moore-majority-voting-algorithm-explained/"},{"categories":["Course"],"content":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/","tags":["Course","Python"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Intro 前两个项目还算简单, 比较不复杂. 但是今天这个第三个项目难度确实是上升了(看游戏规则就知道这个有多复杂了). 感觉像是植物大战僵尸 所以我打算为他写一篇博客来整理一下写代码时候的思路. 话不多说, 让我们进入正题吧 ! ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:1:0","tags":["Course","Python"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Phase 1: Basic gameplay ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:2:0","tags":["Course","Python"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Problem 1 (1 pt) Part A: Currently, there is no cost for placing any type of Ant, and so there is no challenge to the game. The base class Ant has a food_cost of zero. Override this class attribute for HarvesterAnt and ThrowerAnt according to the “Food Cost” column in the table below. Part B: Now that placing an Ant costs food, we need to be able to gather more food! To fix this issue, implement the HarvesterAnt class. A HarvesterAnt is a type of Ant that adds one food to the gamestate.food total as its action. 根据题目的要求设置 HarversterAnt 和 ThrowerAnt 的属性, 同时实现 HarvesterAnt 的 action 方法, 让它可以在每次行动的时候给 food + 1 class HarvesterAnt(Ant): \"\"\"HarvesterAnt produces 1 additional food per turn for the colony.\"\"\" name = 'Harvester' implemented = True food_cost = 2 def action(self, gamestate): \"\"\"Produce 1 additional food for the colony. gamestate -- The GameState, used to access game state information. \"\"\" gamestate.food += 1 class ThrowerAnt(Ant): \"\"\"ThrowerAnt throws a leaf each turn at the nearest Bee in its range.\"\"\" name = 'Thrower' implemented = True damage = 1 food_cost = 3 ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:2:1","tags":["Course","Python"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Problem 2 (1 pt) In this problem, you’ll complete Place.__init__ by adding code that tracks entrances. Right now, a Place keeps track only of its exit. We would like a Place to keep track of its entrance as well. A Place needs to track only one entrance. Tracking entrances will be useful when an Ant needs to see what Bees are in front of it in the tunnel. However, simply passing an entrance to a Place constructor will be problematic; we would need to have both the exit and the entrance before creating a Place! (It’s a chicken or the egg problem.) To get around this problem, we will keep track of entrances in the following way instead. Place.__init__ should use this logic: A newly created Place always starts with its entrance as None. If the Place has an exit, then the exit’s entrance is set to that Place. 其实这个赛道有点像数据结构中的双向链表的结构, 往左边用 .exit, 往右边用 .entrance 方法. 要求已经在上面给出, 没什么难度 class Place: \"\"\"A Place holds insects and has an exit to another Place.\"\"\" is_hive = False def __init__(self, name, exit=None): \"\"\"Create a Place with the given NAME and EXIT. name -- A string; the name of this Place. exit -- The Place reached by exiting this Place (may be None). \"\"\" self.name = name self.exit = exit self.bees = [] # A list of Bees self.ant = None # An Ant self.entrance = None # A Place # Phase 1: Add an entrance to the exit if exit is not None: self.exit.entrance = self ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:2:2","tags":["Course","Python"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Problem 3 (1 pt) In order for a ThrowerAnt to throw a leaf, it must know which bee to hit. The provided implementation of the nearest_bee method in the ThrowerAnt class only allows them to hit bees in the same Place. Your job is to fix it so that a ThrowerAnt will throw_at the nearest bee in front of it that is not still in the Hive. This includes bees that are in the same Place as a ThrowerAnt Hint: All Places have an is_hive attribute which is True when that place is the Hive. Change nearest_bee so that it returns a random Bee from the nearest place that contains bees. Your implementation should follow this logic: Start from the current Place of the ThrowerAnt. For each place, return a random bee if there is any, and if not, inspect the place in front of it (stored as the current place’s entrance). If there is no bee to attack, return None. 现在我们要给 ThrowerAnt 加上功能, 这样才能让它攻击距离它最近的蜜蜂🐝. 注意如果蜜蜂和他在同一个格子里, 也是可以攻击的. 我们的工作要求是遍历每个格子(就跟你遍历链表一样)找到第一个有蜜蜂的格子, 随机返回一个蜜蜂 def nearest_bee(self): \"\"\"Return the nearest Bee in a Place that is not the HIVE, connected to the ThrowerAnt's Place by following entrances. This method returns None if there is no such Bee (or none in range). \"\"\" pos = self.place while pos.entrance is not None: if not pos.is_hive: if len(pos.bees) \u003e 0: return random_bee(pos.bees) pos = pos.entrance return None ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:2:3","tags":["Course","Python"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Phase 2: Ants! ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:3:0","tags":["Course","Python"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Problem 4 (2 pt) A ThrowerAnt is a powerful threat to the bees, but it has a high food cost. In this problem, you’ll implement two subclasses of ThrowerAnt that are less costly but have constraints on the distance they can throw: The LongThrower can only throw_at a Bee that is found after following at least 5 entrance transitions. It cannot hit Bees that are in the same Place as it or the first 4 Places in front of it. If there are two Bees, one too close to the LongThrower and the other within its range, the LongThrower should only throw at the farther Bee, which is within its range, instead of trying to hit the closer Bee. The ShortThrower can only throw_at a Bee that is found after following at most 3 entrance transitions. It cannot throw at any bees further than 3 Places in front of it. Neither of these specialized throwers can throw_at a Bee that is exactly 4 Places away. 现在我们要实现两个类, LongThrower 和 ShortThrower. 两个都是 ThrowererAnt 的子类, 其实从他们的名字可以看出来他们的区别在于攻击范围的不同. 思路: 我们如何表示攻击范围这个概念呢 ? 其实很简单, 在 problem 3 中我们找到最近的蜜蜂的时候就是一个格子一个格子前进的, 我们可以同时计算步数, 那么我们就这道这个距离, 再配合 min_range 和 max_range 这两个参数(类变量, 表示这个类对应的蚂蚁的攻击范围, 只有落在这个区间的才行) 同时要注意我们不能影响 problem 3 中的结果, 这也容易想到, 我们让 min_range=-1, max_range=float('inf'), 这样就相当于没有限制了 ~! 而且因为面向对象程序设计的优势, 我们省去了不少代码量. # In problem 3 class ThrowerAnt(Ant): \"\"\"ThrowerAnt throws a leaf each turn at the nearest Bee in its range.\"\"\" name = 'Thrower' implemented = True damage = 1 food_cost = 3 min_range = -1 max_range = float('inf') def nearest_bee(self): \"\"\"Return the nearest Bee in a Place that is not the HIVE, connected to the ThrowerAnt's Place by following entrances. This method returns None if there is no such Bee (or none in range). \"\"\" steps_cnt = 0 pos = self.place while pos.entrance is not None: if steps_cnt \u003e self.max_range: return None if not pos.is_hive: if len(pos.bees) \u003e 0 and steps_cnt \u003e= self.min_range: return random_bee(pos.bees) pos = pos.entrance steps_cnt += 1 return None class ShortThrower(ThrowerAnt): \"\"\"A ThrowerAnt that only throws leaves at Bees at most 3 places away.\"\"\" name = 'Short' food_cost = 2 # OVERRIDE CLASS ATTRIBUTES HERE implemented = True # Change to True to view in the GUI max_range = 3 class LongThrower(ThrowerAnt): \"\"\"A ThrowerAnt that only throws leaves at Bees at least 5 places away.\"\"\" name = 'Long' food_cost = 2 # OVERRIDE CLASS ATTRIBUTES HERE implemented = True # Change to True to view in the GUI min_range = 5 ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:3:1","tags":["Course","Python"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Problem 5 (3 pt) Implement the FireAnt, which does damage when it receives damage. Specifically, if it is damaged by amount health units, it does a damage of amount to all bees in its place (this is called reflected damage). If it dies, it does an additional amount of damage, as specified by its damage attribute, which has a default value of 3 as defined in the FireAnt class. To implement this, override FireAnt’s reduce_health method. Your overriden method should call the reduce_health method inherited from the superclass (Ant) to reduce the current FireAnt instance’s health. Calling the inherited reduce_health method on a FireAnt instance reduces the insect’s health by the given amount and removes the insect from its place if its health reaches zero or lower. 这个 FireAnt 有点意思的, 当他收到伤害的时候会反弹自己受到的伤害到当前格子所有的蜜蜂上, 同时如果它因此死了还能对这些蜜蜂再一次造成伤害(这一次取决于自己的攻击力) 这个比较 tricky 的地方是：当前格子的所有蜜蜂是一个 list, 也就是我们可能要在迭代访问 list 的时候修改这个 list, ==这个我们遍历它的拷贝即可== 最后代码如下: class FireAnt(Ant): \"\"\"FireAnt cooks any Bee in its Place when it expires.\"\"\" name = 'Fire' damage = 3 food_cost = 5 implemented = True # Change to True to view in the GUI def __init__(self, health=3): \"\"\"Create an Ant with a HEALTH quantity.\"\"\" super().__init__(health) def reduce_health(self, amount): \"\"\"Reduce health by AMOUNT, and remove the FireAnt from its place if it has no health remaining. Make sure to reduce the health of each bee in the current place, and apply the additional damage if the fire ant dies. \"\"\" # FireAnt attack bees for bee in self.place.bees[:]: bee.reduce_health(amount) # FireAnt will be dead if self.health \u003c= amount: for bee in self.place.bees[:]: bee.reduce_health(self.damage) super().reduce_health(amount) else: super().reduce_health(amount) ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:3:2","tags":["Course","Python"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Phase 3: More Ants! ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:4:0","tags":["Course","Python"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Problem 6 (1 pt) We are going to add some protection to our glorious home base by implementing the WallAnt, an ant that does nothing each turn. A WallAnt is useful because it has a large health value. Unlike with previous ants, we have not provided you with a class header. Implement the WallAnt class from scratch. Give it a class attribute name with the value 'Wall' (so that the graphics work) and a class attributeimplemented with the value True (so that you can use it in a game). 从零实现一个 WallAnt, 这种蚂蚁生命值高, 其他倒是没什么 class WallAnt(Ant): \"\"\"WallAnt has a large health value\"\"\" name = 'Wall' damage = 0 food_cost = 4 implemented = True def __init__(self, health=4): super().__init__(health) ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:4:1","tags":["Course","Python"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Problem 7 (3 pt) Implement the HungryAnt, which will select a random Bee from its place and eat it whole. After eating a Bee, a HungryAnt must spend 3 turns chewing before eating again. If there is no bee available to eat, HungryAnt will do nothing. Give HungryAnt a chew_duration class attribute that stores the number of turns that it will take a HungryAnt to chew (set to 3). Also, give each HungryAnt an instance attribute chew_countdown that counts the number of turns it has left to chew (initialized to 0, since it hasn’t eaten anything at the beginning. You can also think of chew_countdown as the number of turns until a HungryAnt can eat another Bee). Implement the action method of the HungryAnt: First, check if it is chewing; if so, decrement its chew_countdown. Otherwise, eat a random Bee in its place by reducing the Bee’s health to 0. Make sure to set the chew_countdownwhen a Bee is eaten! 从零实现一个 HungryAnt, 可以随机吞下一整只蜜蜂!!!!但是它要花费 chew_duration 来咀嚼才能进行下一次攻击. 这个不就是植物大战僵尸里面的食人花嘛!!! 我们只要判断当前它是否处于咀嚼状态即可. 这里题目是有挖坑的, 测试样例里面可能在运行的时候会修改 chew_duration 的值, 注意别被坑了! class HungryAnt(Ant): \"\"\"HungryAnt will select a random bee from its place and eat it whole\"\"\" name = 'Hungry' damage = 0 food_cost = 4 implemented = True chew_duration = 3 def __init__(self, health=1): super().__init__(health) self.chew_countdown = 0 def action(self, gamestate): # it is chewing if self.chew_countdown != 0: self.chew_countdown -= 1 # it is not chewing else: if len(self.place.bees) \u003e 0: # WARNING: the test cases may change the chew_duration variable in runtime self.chew_countdown = self.chew_duration bee = random_bee(self.place.bees) bee.reduce_health(bee.health) ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:4:2","tags":["Course","Python"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Problem 8 (3 pt) A BodyguardAnt differs from a normal ant because it is a ContainerAnt; it can contain another ant and protect it, all in one Place. When a Bee stings the ant in a Place where one ant contains another, only the container is damaged. The ant inside the container can still perform its original action. If the container perishes, the contained ant still remains in the place (and can then be damaged). Each ContainerAnt has an instance attribute ant_contained that stores the ant it contains. This ant, ant_contained, initially starts off as None to indicate that there is no ant being stored yet. Implement the store_ant method so that it sets the ContainerAnt’s ant_contained instance attribute to the passed in antargument. Also implement the ContainerAnt’s action method to perform its ant_contained’s action if it is currently containing an ant. 这里要实现的蚂蚁也很有意思, 它可以把其他蚂蚁保护起来. 甚至可以和被保护的蚂蚁一起呆在同一个格子里面. 这里注意几个细节: BodyguardAnt 不能保护 BodyguardAnt !(🈲️止套娃) 当 BodyguardAnt 和被保护的蚂蚁在同一个格子的时候, 要让 place.ant 始终指向 BodyguardAnt 这里其实还涉及到挺多要改的地方的(可能会漏放某些代码, 完整的建议看我的仓库) class Ant(Insect): \"\"\"An Ant occupies a place and does work for the colony.\"\"\" implemented = False # Only implemented Ant classes should be instantiated food_cost = 0 is_container = False ... def add_to(self, place): if place.ant is None: place.ant = self else: assert ( (place.ant is None) or self.can_contain(place.ant) or place.ant.can_contain(self) ), 'Two ants in {0}'.format(place) if place.ant.is_container and place.ant.can_contain(self): place.ant.store_ant(self) elif self.is_container and self.can_contain(place.ant): self.store_ant(place.ant) # the place.ant should refer to the container ant place.ant = self Insect.add_to(self, place) class ContainerAnt(Ant): \"\"\" ContainerAnt can share a space with other ants by containing them. \"\"\" is_container = True def __init__(self, *args, **kwargs): super().__init__(*args, **kwargs) self.ant_contained = None def can_contain(self, other): # we can't have two BodyguardAnt in the same place if self.ant_contained is None and not other.is_container: return True def store_ant(self, ant): self.ant_contained = ant def remove_ant(self, ant): if self.ant_contained is not ant: assert False, \"{} does not contain {}\".format(self, ant) self.ant_contained = None def remove_from(self, place): # Special handling for container ants (this is optional) if place.ant is self: # Container was removed. Contained ant should remain in the game place.ant = place.ant.ant_contained Insect.remove_from(self, place) else: # default to normal behavior Ant.remove_from(self, place) def action(self, gamestate): if self.ant_contained is not None: return self.ant_contained.action(gamestate) class BodyguardAnt(ContainerAnt): \"\"\"BodyguardAnt provides protection to other Ants.\"\"\" name = 'Bodyguard' food_cost = 4 implemented = True # Change to True to view in the GUI def __init__(self, health=2): super().__init__(health) ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:4:3","tags":["Course","Python"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Problem 9 (1 pt) The BodyguardAnt provides great defense, but they say the best defense is a good offense. The TankAnt is a container that protects an ant in its place and also deals 1 damage to all bees in its place each turn. We have not provided you with a class header. Implement the TankAnt class from scratch. Give it a class attribute name with the value 'Tank' (so that the graphics work) and a class attribute implemented with the value True (so that you can use it in a game). You should not need to modify any code outside of the TankAnt class. If you find yourself needing to make changes elsewhere, look for a way to write your code for the previous question such that it applies not just to BodyguardAnt and TankAnt objects, but to container ants in general. 根据题目的描述可以知道 TankAnt 是一种特殊的 ContainerAnt, 我们要从零实现它的功能, 它的攻击方式比较特殊, 是自己保护的蚂蚁的攻击方式 + 对当前格子的蜜蜂造成自己攻击力的伤害 class TankAnt(ContainerAnt): name = 'Tank' damage = 1 food_cost = 6 implemented = True def __init__(self, health=2): super().__init__(health) def action(self, gamestate): if self.ant_contained is not None: self.ant_contained.action(gamestate) # 1 damage for all the bees for bee in self.place.bees[:]: bee.reduce_health(self.damage) ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:4:4","tags":["Course","Python"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Phase 4: Water and Might ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:5:0","tags":["Course","Python"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Problem 10 (1 pt) Let’s add water to the colony! Currently there are only two types of places, the Hive and a basic Place. To make things more interesting, we’re going to create a new type of Place called Water. Only an insect that is waterproof can be placed in Water. In order to determine whether an Insect is waterproof, add a new class attribute to the Insect class named is_waterproof that is set to False. Since bees can fly, set their is_waterproof attribute to True, overriding the inherited value. Now, implement the add_insect method for Water. First, add the insect to the place regardless of whether it is waterproof. Then, if the insect is not waterproof, reduce the insect’s health to 0. Do not repeat code from elsewhere in the program. Instead, use methods that have already been defined. 为了让地形更有趣, 我们要增加一种地形 - Water, 只有能在水里的活动的生物才能被放在这种地形中(蜜蜂会飞当然都可以, 蚂蚁目前还没有) 记得还要修改很多类, 增加类属性 is_waterproof, 下面我就放 Water 类的代码 class Water(Place): \"\"\"Water is a place that can only hold waterproof insects.\"\"\" def add_insect(self, insect): \"\"\"Add an Insect to this place. If the insect is not waterproof, reduce its health to 0.\"\"\" super().add_insect(insect) if not insect.is_waterproof: insect.reduce_health(insect.health) ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:5:1","tags":["Course","Python"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Problem 11 (1 pt) Currently there are no ants that can be placed on Water. Implement the ScubaThrower, which is a subclass of ThrowerAnt that is more costly and waterproof, but otherwise identical to its base class. A ScubaThrower should not lose its health when placed in Water. We have not provided you with a class header. Implement the ScubaThrower class from scratch. Give it a class attribute name with the value 'Scuba' (so that the graphics work) and remember to set the class attributeimplemented with the value True (so that you can use it in a game). 从零实现一个 ScubaThrower, 听名字可以看出来应该是一种特殊的 ThrowerAnt. 特殊在: 能放在 Water 里 class ScubaThrower(ThrowerAnt): name = 'Scuba' food_cost = 6 is_waterproof = True implemented = True def __init__(self, health=1): super().__init__(health) ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:5:2","tags":["Course","Python"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Problem 12 (3 pt) Finally, implement the QueenAnt. The queen is a waterproof ScubaThrower that inspires her fellow ants through her bravery. In addition to the standard ScubaThrower action, the QueenAnt doubles the damage of all the ants behind her each time she performs an action. Once an ant’s damage has been doubled, it is not doubled again for subsequent turns. However, with great power comes great responsibility. The QueenAnt is governed by three special rules: If the queen ever has its health reduced to 0, the ants lose. You will need to override Ant.reduce_health in QueenAnt and call ants_lose() in that case in order to signal to the simulator that the game is over. (The ants also still lose if any bee reaches the end of a tunnel.) There can be only one queen. A second queen cannot be constructed. To check if an Ant can be constructed, we use the Ant.construct() class method to either construct an Ant if possible, or return None if not. You will need to override Ant.construct as a class method of QueenAnt in order to add this check. To keep track of whether a queen has already been created, you can use an instance variable added to the current GameState. The queen cannot be removed. Attempts to remove the queen should have no effect (but should not cause an error). You will need to override Ant.remove_from in QueenAnt to enforce this condition. 终于来到了最后一题(除了额外的题目以外), 我们要实现一个女王蚁🐜. 它有以下几个特性: 可以在水中行走 思路: 题目也说了它是一种 ScrubaThrower, 根据这个描述其实就抽象概括出了它是 ScrubaThrower 的子类. 它在行动后会把在它后面的蚂蚁们的攻击力都翻倍, 但是不可以多次翻倍 思路: 如何表示 “在后面” 这个关系 ? 根据前面的题目我们可以知道. 右边为正方向, 所以 “在后面” 实际上就是在左边, 我们可以通过访问 Place 的 .exit 方法不断获取到它左边(后面的)的 思路: 如何表示不能多次翻倍 ? 很容易想到, 我们需要通过设置一个标记来表示当前的蚂蚁是否已经攻击力翻倍过, 所以我们直接在 Ant 类里加一个实例变量即可 思路: 这里还要注意如何处理 GuardAnt, 因为实际上它守护的蚂蚁是可能被替换为新的蚂蚁, 此时我们就要让这个新的被守护的蚂蚁的攻击力翻倍. ==注意细细体会这里代码是怎么写的== 只能有一个女王蚁🐜 思路: 如何做到即使我们多次调用女王蚁🐜的构造函数也不会有多的女王蚁🐜 ? 这个依赖于一个游戏变量叫做 gamestate, 我们仍然是通过加标记的方式, 只不过这次我们是在 GameState 这个类里加一个 has_queen 表示当前是否已经有女王蚁🐜 女王蚁🐜不能被移除 思路: 这个简单, 我们什么都不做就行了 最后代码大概如下(结合上面的解释细细体会~~) class QueenAnt(ScubaThrower): \"\"\"The Queen of the colony. The game is over if a bee enters her place.\"\"\" name = 'Queen' food_cost = 7 implemented = True # Change to True to view in the GUI @classmethod def construct(cls, gamestate): \"\"\" Returns a new instance of the Ant class if it is possible to construct, or returns None otherwise. Remember to call the construct() method of the superclass! \"\"\" if cls.food_cost \u003e gamestate.food: print('Not enough food remains to place ' + cls.__name__) return # I add a class variable to indict if we have created a QueenAnt() if not gamestate.has_queen: gamestate.has_queen = True return super().construct(gamestate) else: return None def action(self, gamestate): \"\"\"A queen ant throws a leaf, but also doubles the damage of ants in her tunnel. \"\"\" super().action(gamestate) pos = self.place.exit while pos: if pos.ant is not None: if not pos.ant.is_doubled: pos.ant.is_doubled = True pos.ant.buff() if pos.ant.is_container and pos.ant.ant_contained is not None: # the pos.ant.ant_contained may change if not pos.ant.ant_contained.is_doubled: pos.ant.ant_contained.buff() pos.ant.ant_contained.is_doubled = True pos = pos.exit def reduce_health(self, amount): \"\"\"Reduce health by AMOUNT, and if the QueenAnt has no health remaining, signal the end of the game. \"\"\" if self.health \u003c= amount: ants_lose() def remove_from(self, place): return None ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:5:3","tags":["Course","Python"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Extra Credit (2 pt) Implement two final thrower ants that do zero damage, but instead apply a temporary “status” on the actionmethod of a Bee instance that they throw_at. This “status” lasts for a certain number of turns, after which it ceases to take effect. We will be implementing two new ants that inherit from ThrowerAnt. SlowThrower throws sticky syrup at a bee, slowing it for 3 turns. When a bee is slowed, it can only move on turns when gamestate.time is even, and can do nothing otherwise. If a bee is hit by syrup while it is already slowed, it is slowed for an additional 3 turns. ScaryThrower intimidates a nearby bee, causing it to back away instead of advancing. (If the bee is already right next to the Hive and cannot go back further, it should not move. To check if a bee is next to the Hive, you might find the is_hive instance attribute of Places useful). Bees remain scared until they have tried to back away twice. Bees cannot try to back away if they are slowed and gamestate.time is odd. Once a bee has been scared once, it can’t be scared ever again. 实现两种特殊的蚂蚁类, 本身没有伤害, 但是能给蜜蜂加上 debuff. SlowThrower 可以让蜜蜂减速, 让他们只能在当前时间为偶数的时候前进否则什么事情也干不了. 这个效果可以维持三个回合, 但是这个 debuff 可以无限叠加 ScaryThrower 会让蜜蜂后退, 注意如果不能再后退的话, 就要保持不动. 该效果维持两回合. 但是如果被减速就会继续保持不动, 这个 debuff 只能上一次 这一题, 真的, 难度完全是上来了. 我调了挺久的 bug 才成功. 下面我来讲一下设计思路: SlowThrower 设置 is_slow 变量表示当前的蜜蜂是否被减速, 同时设置 slow_turns 来记住剩余几回合可以解除这个状态 每个回合, 如果当前的蜜蜂被减速了, 它只能看当前的游戏时间是否为偶数, 如果是的话就可以前进, 否则在原地不动, **但不论你动不动, slow_turns -= 1 永远都成立 ScaryThrower 类似 is_slow 和 slow_turns 设置了 is_scared 和 scared_turns 我们暂时先不考虑当前蜜蜂是否被减速了(这样思考问题会比较简单). 显然, 我们每回合要做的事情是让 scared_turns -= 1, 然后是否为 scared 其实决定着蜜蜂的前进方向. 有了这个基础之后我们再来思考被减速带情况下又该如何, 显然我们前面这样是有问题的, 题目说了如果被减速会原地保持不动, 但是我们却让 scared_turns -= 1, 所以我们需要多加一个判断, 也就是被减速 + 被 scared 的情况下如果我们没有成功移动, 那么我们需要撤销我们对 scared_turns 的更改 知道了上面的设计思路, 理解下面的代码就不难了(这里删去了无关的代码): class Bee(Insect): \"\"\"A Bee moves from place to place, following exits and stinging ants.\"\"\" name = 'Bee' damage = 1 is_waterproof = True # 2 flags is_slow = False is_scared = False # turns remained slow_turns = 0 scared_turns = 0 # we can't scare a bee twice has_been_scared = False def action(self, gamestate): \"\"\"A Bee's action stings the Ant that blocks its exit if it is blocked, or moves to the exit of its current place otherwise. gamestate -- The GameState, used to access game state information. \"\"\" if self.is_scared: destination = self.place.entrance self.scared_turns -= 1 else: destination = self.place.exit if self.is_slow: self.slow_turns -= 1 if self.slow_turns == 0: self.is_slow = False if gamestate.time % 2 == 0 and self.health \u003e 0 and destination is not None: self.move_to(destination) else: # is_slow + is_scared, we need to cancel `self.scared_turns -= 1` \\ # if we didn't move self.scared_turns += 1 else: if self.blocked(): self.sting(self.place.ant) elif self.health \u003e 0 and destination is not None: self.move_to(destination) # we can't put this in side `if self.is_scared`, why? # because only when we run if self.is_slow we can know # should we cancel it or not if self.scared_turns == 0: self.is_scared = False # Extra credit: Special handling for bee direction def slow(self, length): \"\"\"Slow the bee for a further LENGTH turns.\"\"\" self.is_slow = True self.slow_turns += length def scare(self, length): \"\"\" If this Bee has not been scared before, cause it to attempt to go backwards LENGTH times. \"\"\" # a bee can't be scared twice if self.has_been_scared: return else: self.is_scared = True self.scared_turns += length self.has_been_scared = True ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:5:4","tags":["Course","Python"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Optional Problems ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:6:0","tags":["Course","Python"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Optional Problem 1 Implement the NinjaAnt, which damages all Bees that pass by, but can never be stung. A NinjaAnt does not block the path of a Bee that flies by. To implement this behavior, first modify the Ant class to include a new class attribute blocks_path that is set to True, then override the value of blocks_path to Falsein the NinjaAnt class. Second, modify the Bee’s method blocked to return False if either there is no Ant in the Bee’s place or if there is an Ant, but its blocks_path attribute is False. Now Bees will just fly past NinjaAnts. Finally, we want to make the NinjaAnt damage all Bees that fly past. Implement the action method in NinjaAntto reduce the health of all Bees in the same place as the NinjaAnt by its damage attribute. Similar to the FireAnt, you must iterate over a potentially changing list of bees. 忍者蚁🥷🐜哈哈哈哈, 注意几个细节: 无法被蜜蜂攻击 不会堵住蜜蜂的路, 但是会对经过的蜜蜂造成伤害 这个问题比较简单, 解法也几乎都写在了问题描述里面 class Bee(Insect): \"\"\"A Bee moves from place to place, following exits and stinging ants.\"\"\" def blocked(self): \"\"\"Return True if this Bee cannot advance to the next Place.\"\"\" if self.place.ant is None: return False if not self.place.ant.blocks_path: return False return True class NinjaAnt(Ant): \"\"\"NinjaAnt does not block the path and damages all bees in its place. This class is optional. \"\"\" name = 'Ninja' damage = 1 food_cost = 5 blocks_path = False implemented = True # Change to True to view in the GUI def action(self, gamestate): for bee in self.place.bees[:]: bee.reduce_health(self.damage) ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:6:1","tags":["Course","Python"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Optional Problem 2 The LaserAnt shoots out a powerful laser, damaging all that dare to stand in its path. Both Bees and Ants, of all types, are at risk of being damaged by LaserAnt. When a LaserAnt takes its action, it will damage all Insects in its place (excluding itself, but including its container if it has one) and the Places in front of it, excluding the Hive. If that were it, LaserAnt would be too powerful for us to contain. The LaserAnt has a base damage of 2. But, LaserAnt’s laser comes with some quirks. The laser is weakened by 0.25 each place it travels away fromLaserAnt’s place. Additionally, LaserAnt has limited battery. Each time LaserAnt actually damages an Insect its laser’s total damage goes down by 0.0625 (1/16). If LaserAnt’s damage becomes negative due to these restrictions, it simply does 0 damage instead. 激光🐜, 注意几个特性: 伤害自己格子所在的所有生物, 甚至包括整条路径上的所有生物 但是每次对其他生物造成伤害的时候伤害会衰减, 每次减去 0.0625 激光的威力跟它离激光蚁🐜的距离也有关系, 距离每多一个格子, 就会减去 0.25 只要处理好两个函数即可 calculate_damage : 这个要注意的地方是, 如果算出来的伤害 \u003c 0, 那么你就需要返回 0 insects_in_front : 这个要返回一个 dict 表示每个生物距离激光🐜的距离. 我这了是分成当前格子和剩下的格子这样来处理, 一边遍历所有格子一边计算距离和把生物加到我们的 dict里. class LaserAnt(ThrowerAnt): name = 'Laser' food_cost = 10 implemented = True # Change to True to view in the GUI damage = 2 def __init__(self, health=1): super().__init__(health) self.insects_shot = 0 self.current_damage = LaserAnt.damage def insects_in_front(self): \"\"\"Return a dict contains every Insect\"\"\" dis = {} for bee in self.place.bees: dis[bee] = 0 # take care of the ContainerAnt if self.place.ant is not self: dis[self.place.ant] = 0 pos = self.place.entrance distance = 1 while pos.entrance is not None: if not pos.is_hive: for bee in pos.bees: dis[bee] = distance if pos.ant is not None: dis[pos.ant] = distance # take care of the ContainerAnt if pos.ant.is_container and pos.ant.ant_contained is not None: dis[pos.ant.ant_contained] = distance distance += 1 pos = pos.entrance return dis def calculate_damage(self, distance): damage_result = self.damage - 0.0625 * self.insects_shot - 0.25 * distance return damage_result if damage_result \u003e 0 else 0 def action(self, gamestate): insects_and_distances = self.insects_in_front() for insect, distance in insects_and_distances.items(): damage = self.calculate_damage(distance) insect.reduce_health(damage) if damage: self.insects_shot += 1 ","date":"2022-03-10","objectID":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/:6:2","tags":["Course","Python"],"title":"CS61A 的项目三之 Ants vs SomeBees 实现 (2021-Fall)","uri":"/zh-cn/proj3.ants-vs-somebees-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"the simple solutions for lab14 of CS61A of UCB","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/","tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/"},{"categories":["Course"],"content":"Trees ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:1:0","tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q1: Prune Min Write a function that prunes a Tree t mutatively. t and its branches always have zero or two branches. For the trees with two branches, reduce the number of branches from two to one by keeping the branch that has the smaller label value. Do nothing with trees with zero branches. Prune the tree in a direction of your choosing (top down or bottom up). The result should be a linear tree. 递归的细节: 叶子结点 : 直接返回 只有一个分支 : 虽然当前节点满足条件, 但是它的子树里可能有不符合条件的节点, 所以我们要递归裁剪分支 有两个分支 : 找到较小的分支, 把较大的分支裁剪掉(用 del) def prune_min(t): \"\"\"Prune the tree mutatively. \"\"\" # base case: the leaf node has 0 children if t.is_leaf(): return # go deeper if it has 1 child if len(t.branches) == 1: prune_min(t.branches[0]) left, right = t.branches[0], t.branches[1] if left.label \u003c right.label: del t.branches[1] # prune right branch prune_min(left) else: del t.branches[0] # prune left branch prune_min(right) ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:1:1","tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/"},{"categories":["Course"],"content":"Regex ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:2:0","tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q4: Address First Line Write a regular expression that parses strings and returns any expressions which contain the first line of a US mailing address. US mailing addresses typically contain a block number, which is a sequence of 3-5 digits, following by a street name. The street name can consist of multiple words but will always end with a street type abbreviation, which itself is a sequence of 2-5 English letters. The street name can also optionally start with a cardinal direction (“N”, “E”, “W”, “S”). Everything should be properly capitalized. Proper capitalization means that the first letter of each name is capitalized. It is fine to have things like “WeirdCApitalization” match. See the doctests for some examples. 我们在这里要匹配美国的邮件地址, 下面是关于这个的正则表达式的细节: 开头有 3 - 5 个数字 然后是一个街道的名字, 可能会有多个单词, 但是结尾一定是街道类型的缩写(2 - 5 个英文字母) 但是街道名字也有可能是 “N”, “E”, “W”, “S” 这四个字母开头 ps. 上面说到的是 “properly capitalized“ 的单词, 具体定义可以看问题描述. 我的理解就是单词的开头一定要是大写, 后面就随便了~~ 下面我们分解问题, 把整个要匹配的地址分为上面提到的几个部分: 区号 : 这个简单, \\d{2,5} 即可 可能的 “N”, “E”, “W”, “S” 开头, 这个也简单, 用 (?:[NSWE] )? 注意里面有一个空格 然后就是街道名字要怎么写了, 街道名字可能包含多个单词, 每个单词都要求开头大写, 所以我们可以整合出这样的正则表达式: [A-Z][A-Za-z]*(?: [A-Z][A-Za-z]*)*. 首先要有一个单词, 然后后面可以有任意个空格 + 单词的组合 最后是要有街道类型的缩写, 注意这里仍然要是单词开头大写, 其他任意, 本来是 2 - 5 个字母, 现在去掉了开头的第一个大写字母之后, 剩下 1 - 4 个字母. [A-Z][A-Za-z]{1,4}\\b. 最后的 \\b 是让正则表达式只匹配单词的结尾. def address_oneline(text): \"\"\" Finds and returns expressions in text that represent the first line of a US mailing address. \"\"\" block_number = r'\\d{3,5}' cardinal_dir = r'(?:[NSWE] )?' # whitespace is important! street = r'[A-Z][A-Za-z]*(?: [A-Z][A-Za-z]*)*' type_abbr = r' [A-Z][A-Za-z]{1,4}\\b' street_name = f\"{cardinal_dir}{street}{type_abbr}\" return re.findall(f\"{block_number} {street_name}\", text) ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:2:1","tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/"},{"categories":["Course"],"content":"SQL ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:3:0","tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q5: Opening Times You’d like to have lunch before 1pm. Create a opening table with the names of all Pizza places that open before 1pm, listed in reverse alphabetical order. 找到开店时间在下午一点前的, 注意数据库里的时间是 24 小时制 CREATE TABLE opening AS SELECT name FROM pizzas WHERE open \u003c 13 ORDER BY name DESC; ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:3:1","tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q6: Double Pizza If two meals are more than 6 hours apart, then there’s nothing wrong with going to the same pizza place for both, right? Create a double table with three columns. The first columns is the earlier meal, the second is the later meal, and the third is the name of a pizza place. Only include rows that describe two meals that are more than 6 hours apart and a pizza place that is open for both of the meals. The rows may appear in any order. 考察表的联合, 注意细节: 两顿饭之间间隔要超过六个小时 第一顿饭的开始时间到第二顿饭的结束时间要在饭店的营业时间内 create TABLE double AS SELECT m1.meal, m2.meal, p.name FROM meals AS m1, meals AS m2, pizzas AS p WHERE m2.time - m1.time \u003e 6 AND m1.time \u003e= p.open AND m2.time \u003c= p.close; ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:3:2","tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/"},{"categories":["Course"],"content":"Objects ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:4:0","tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q7: Player First, let’s implement the Player class. Fill in the debate and speech methods, that take in another Player other, and implement the correct behavior as detailed above. Here are two additional things to keep in mind: In the debate method, you should call the provided random function, which returns a random float between 0 and 1. The player should gain 50 popularity if the random number is smaller than the probability described above, and lose 50 popularity otherwise. Neither players’ popularity should ever become negative. If this happens, set it equal to 0 instead. 计算方法在规则里面已经给出, 这里要注意 speech 方法里面要修改 votes 和 popularity class Player: def __init__(self, name): self.name = name self.votes = 0 self.popularity = 100 def debate(self, other): prob1 = max(0.1, self.popularity / (self.popularity + other.popularity)) #prob2 = max(0.1, other.popularity / (self.popularity + other.popularity)) if random() \u003e prob1: self.popularity -= 50 else: self.popularity += 50 if self.popularity \u003c 0: self.popularity = 0 def speech(self, other): self.votes += (self.popularity // 10) self.popularity += (self.popularity // 10) other.popularity -= (other.popularity // 10) def choose(self, other): return self.speech ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:4:1","tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q8: Game Now, implement the Game class. Fill in the play method, which should alternate between the two players, starting with p1, and have each player take one turn at a time. The choose method in the Player class returns the method, either debate or speech, that should be called to perform the action. In addition, fill in the winner property method, which should return the player with more votes, or None if the players are tied. 根据 self.turn 是奇数还是偶数来决定当前轮到谁, 注意 choose 方法返回的仍然是函数, 所以你需要给他参数才行 class Game: def __init__(self, player1, player2): self.p1 = player1 self.p2 = player2 self.turn = 0 def play(self): while not self.game_over: if self.turn % 2 == 0: self.p1.choose(self.p2)(self.p2) else: self.p2.choose(self.p1)(self.p1) self.turn += 1 return self.winner @property def game_over(self): return max(self.p1.votes, self.p2.votes) \u003e= 50 or self.turn \u003e= 10 @property def winner(self): if self.p1.votes \u003e self.p2.votes: return self.p1 else: return self.p2 ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:4:2","tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q9: New Players The choose method in the Player class is boring, because it always returns the speech method. Let’s implement two new classes that inherit from Player, but have more interesting choose methods. Implement the choose method in the AggressivePlayer class, which returns the debate method if the player’s popularity is less than or equal to other’s popularity, and speech otherwise. Also implement the choose method in the CautiousPlayer class, which returns the debate method if the player’s popularity is 0, and speech otherwise. 翻译一下题目的意思即可 :) class AggressivePlayer(Player): def choose(self, other): if self.popularity \u003c= other.popularity: return self.debate else: return self.speech class CautiousPlayer(Player): def choose(self, other): if self.popularity == 0: return self.debate else: return self.speech ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:4:3","tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/"},{"categories":["Course"],"content":"Tree Recursion Define the function add_trees, which takes in two trees and returns a new tree where each corresponding node from the first tree is added with the node from the second tree. If a node at any particular position is present in one tree but not the other, it should be present in the new tree as well. Hint: You may want to use the built-in zip function to iterate over multiple sequences at once. 这一题要我们把一棵树合并到另外一棵树上去. 注意区分谁是主体(对后面思考如何递归解决很有用). 如何用递归解决? base case: 我们是把树 t2 加到树 t1 上, 那如果 t2 是 None 的话不就不用加了吗 ? 是的, 这个就是我们的一个 base case 🤗 在 t2 不为空的基础上, 如果 t1 因为空呢 ? 显然, 这个时候两棵树相加的结果就是 t2, 所以我们返回 t2 即可. 递归分解 这个时候我们可以保证 t1 和 t2 都是非空的, 但是我们无法保证他们两个的孩子数目是一样多的, 所以我们无法根据提示里使用 zip. 因为 zip 在处理两个两个不一样长的序列的时候, 长的序列多的部分是被忽略的. 这里应该用 itertools 里面的 zip_longest, 如果一个序列已经为空会返回 None. 这样我们才能保证这样递归调用最后可以回到我们前面讨论的 base case 中. 那我们在当前节点做的事情就是: 相加两个节点的 label, 然后对他们的子树都递归调用即可. 🚀 def add_trees(t1, t2): # base case: no need to add_trees anymore if t2 is None: return t1 if t1 is None: return t2 else: # both of t1 and t2 are not None # however, the number of children may not equal return Tree(t1.label + t2.label, [add_trees(x, y) for x, y in zip_longest(t1.branches, t2.branches)]) ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:5:0","tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/"},{"categories":["Course"],"content":"Linked Lists ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:6:0","tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q11: Fold Left Write the left fold function by filling in the blanks. 这个是自顶向下计算的, 也就是我们在进入更深层的递归调用之前会先计算结果, 并将这个结果传递下去, 当我们到达了空结点(说明我们做完了所有的运算)就得到了结果. 所以 base case 里面的 z 已经不是一开始的 z 了, 而是我们最后要得到的运算结果的 z def foldl(link, fn, z): \"\"\" Left fold \u003e\u003e\u003e lst = Link(3, Link(2, Link(1))) \u003e\u003e\u003e foldl(lst, sub, 0) # (((0 - 3) - 2) - 1) -6 \u003e\u003e\u003e foldl(lst, add, 0) # (((0 + 3) + 2) + 1) 6 \u003e\u003e\u003e foldl(lst, mul, 1) # (((1 * 3) * 2) * 1) 6 \"\"\" if link is Link.empty: return z z = fn(z, link.first) return foldl(link.rest, fn, z) ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:6:1","tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q12: Fold Right Now write the right fold function. 其实这个问题会比 Q1 更为简单, 更符合我们对递归的认知. 我们从最底层逐层返回结果运算. 可以看下面的例子理解一下 def foldr(link, fn, z): \"\"\" Right fold \u003e\u003e\u003e lst = Link(3, Link(2, Link(1))) \u003e\u003e\u003e foldr(lst, sub, 0) # (3 - (2 - (1 - 0))) 2 \u003e\u003e\u003e foldr(lst, add, 0) # (3 + (2 + (1 + 0))) 6 \u003e\u003e\u003e foldr(lst, mul, 1) # (3 * (2 * (1 * 1))) 6 \"\"\" if link.rest is Link.empty: return fn(link.first, z) return fn(link.first, foldr(link.rest, fn, z)) ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:6:2","tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/"},{"categories":["Course"],"content":"Regex ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:7:0","tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q13: Basic URL Validation In this problem, we will write a regular expression which matches a URL. URLs look like the following: For example, in the link https://cs61a.org/resources/#regular-expressions, we would have: Scheme: https Domain Name: cs61a.org Path to the file: /resources/ Anchor: #regular-expressions The port and parameters are not present in this example and you will not be required to match them for this problem. You can reference this documentation from MDN if you’re curious about the various parts of a URL. For this problem, a valid domain name consists of any sequence of letters, numbers, dashes, and periods. For a URL to be “valid,” it must contain a valid domain name and will optionally have a scheme, path, and anchor. A valid scheme will either be http or https. Valid paths start with a slash and then must be a valid path to a file or directory. This means they should match something like /composingprograms.html or path/to/file but not /composing.programs.html/. A valid anchor starts with #. While they are more complicated, for this problem assume that valid anchors will then be followed by letters, numbers, hyphens, or underscores. Hint 1: You can use \\ to escape special characters in regex. \u003eHint 2: The provided code already handles making the scheme, path, and anchor optional by using non-capturing groups. 要学会将复杂的正则表达式进行拆解, 一个部分一个部分的完成. 题目已经为我们完成了这个工作. 接下来我讲解一下每个部分的设计要点 scheme : 这个简单, 要么是 http 要么是 https, 我们可以用 (?:...) 来写 domain : www 可以有也可以没有, 可以用 (?:...)? 来表达这点 path to the file: 包含下面三种可能的格式: /path/to/file.extension, /path, /file.extension anchor : 这个可能包括字母、数字、短横线 -, 下划线 _ def match_url(text): scheme = r'(?:https|http)://' domain = r'(?:\\w+\\.)?\\w+\\.\\w+' path = r'(?:/\\w+|/(\\w+/)*)(\\w+\\.\\w+)?' anchor = r'#[\\w\\-_]*' return bool(re.match(rf\"^(?:{scheme})?{domain}(?:{path})?(?:{anchor})?$\", text)) ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:7:1","tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/"},{"categories":["Course"],"content":"BNF ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:8:0","tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q14: Simple CSV CSV, which stands for “Comma Separated Values,” is a file format to store columnar information. We will write a BNF grammar for a small subset of CSV, which we will call SimpleCSV. Create a grammar that reads SimpleCSV, where a file contains rows of words separated by commas. Words are characters [a-zA-Z] (and may be blank!) Spaces are not allowed in the file. 写一个简单的 csv 文件的 BNF, 这里说的简单是因为: 值只能是单词, 分隔符一定是 , 细节: 有可能有 ,,, 的情况出现, 所以我们需要在 word 里面用 | 来算上不放任何字符的情况 lines: line (newline line)* | line newline | line line: word (\",\" word)* word: WORD | newline: \"\\n\" %import common.WORD ","date":"2022-03-03","objectID":"/zh-cn/lab14-cs61a-of-ucb/:8:1","tags":["Course","Python"],"title":"Lab14 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab14-cs61a-of-ucb/"},{"categories":["Course"],"content":"The simple solutions of hw10 of CS61A of UCB","date":"2022-03-02","objectID":"/zh-cn/hw10-of-cs61a-of-ucb/","tags":["Course","BNF","Mysql"],"title":"Hw10 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/hw10-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"BNF ","date":"2022-03-02","objectID":"/zh-cn/hw10-of-cs61a-of-ucb/:1:0","tags":["Course","BNF","Mysql"],"title":"Hw10 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/hw10-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q1: Grouping and Pipes In this question, you will add support for grouping and piping. Recall that grouping allows for an entire regular expression to be treated as a single unit, and piping allows for a pattern to match an expression on either side. Combined, these will let us create patterns which match multiple strings! Define the group and pipe expressions in your grammar. A group consists of any regex expression surrounded by parentheses (()). A pipe operator consists of a regex expression, followed by a pipe (|) character, and lastly followed by another regex expression. For example, r\"apples\" would match exactly the phrase “apples” in an input. If we wanted our pattern from before to match “oranges” as well, we could expand our rstring to do so using groupings and pipes: r\"(apples)|(oranges)\". Hint: note that groups and pipes are valid regex expressions on their own! You may need to update a previously defined expression. 给本来用来匹配正则表达式的 BNF 添加功能: group 和 pipe. 其实怎么实现这一写已经在描述里面给出了, 我这里就提一点: group 和 pipe 本身也是 ?regex 的一部分, 所以要把他们加到 ?regex 里面 ?start: rstring rstring: \"r\\\"\" regex* \"\\\"\" ?regex: character | word | group | pipe group: \"(\" regex* \")\" pipe: regex \"|\" regex character: LETTER | NUMBER word: WORD %ignore /\\s+/ %import common.LETTER %import common.NUMBER %import common.WORD ","date":"2022-03-02","objectID":"/zh-cn/hw10-of-cs61a-of-ucb/:1:1","tags":["Course","BNF","Mysql"],"title":"Hw10 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/hw10-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q2: Classes Now, we will add support for character classes. Recall that character classes allow for the pattern to match any singular character defined within the class. The class itself consists either of individual characters, or ranges of characters. Specifically, we define the following: A range consists of either NUMBERs or LETTERs separated by a hyphen (-). A class expression consists of any number of characters or character ranges surrounded by square brackets ([]). Note that for this question, a range may only consist of either NUMBERs or LETTERs; this means that while [0-9] and [A-Z] are valid ranges, [0-Z] would not be a valid range. In addition, the characters and ranges in a class may appear in any order and any number of times. For example, [ad-fc0-9], [ad-f0-9c], [a0-9d-fc], and [0-9ad-fc] are all valid classes. 这次要加上的功能是 ?-? 和 [] 的功能, 具体怎么做同样在问题描述里面给出了. 这里讲一下注意的点: range 的 - 左右两边要是对应的, 所以 character \"-\" character 这种写法是错的 因为在 [] 里 range 和 character 出现的顺序是任意的, 我们可以用 *, 这两种都有可能在 [] 中的开头或者结尾位置 [] 本身也是合法的正则表达式, 所以要放在 ?regex 里面 ?start: rstring rstring: \"r\\\"\" regex* \"\\\"\" ?regex: character | word | group | pipe | class group: \"(\" regex* \")\" pipe: regex \"|\" regex range: NUMBER \"-\" NUMBER | LETTER \"-\" LETTER class: \"[\" range* character* range* character* \"]\" character: LETTER | NUMBER word: WORD %ignore /\\s+/ %import common.LETTER %import common.NUMBER %import common.WORD ","date":"2022-03-02","objectID":"/zh-cn/hw10-of-cs61a-of-ucb/:1:2","tags":["Course","BNF","Mysql"],"title":"Hw10 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/hw10-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q3: Quantifiers Lastly, we will add support for quantifiers. Recall that quantifiers allow for a pattern to match a specified number of a unit. Specifically, we define the following: A plus_quant expression consists of a group, a character, or a class, followed by a plus symbol (+). A star_quant expression consists of a group, a character, or a class, followed by a star symbol (*). A num_quant expression consists of either a group, a character, or a class, followed by one of the following: a NUMBER enclosed in curly braces ({}); a range of NUMBERs (separated by a comma (,), which may potentially be open on only one side. For example, {2,7}, {2,}, and {,7} are valid numeric quantifiers. {,} is not valid. Hint: these three quantifiers share many similarities. Consider defining additional expressions in this question! 可以发现这三个 _quant 都是 group 或者 character 或者 class开头, 所以我们可以定义一个 ?tmp: class | group | character, 这样后面就会比较好些了, 同时可以定义一个 ?quants: plus_quant | star_quant | num_quant, 放在 ?regex 里会比较方便 rstring: \"r\\\"\" regex* \"\\\"\" ?regex: character | word | group | pipe | class | quants group: \"(\" regex* \")\" pipe: regex \"|\" regex range: NUMBER \"-\" NUMBER | LETTER \"-\" LETTER class: \"[\" range* character* range* character* \"]\" ?tmp: class | group | character plus_quant: tmp \"+\" star_quant: tmp \"*\" num_quant: tmp \"{\" ((NUMBER \",\" NUMBER) | (NUMBER \",\" NUMBER?) | (\",\" NUMBER)) \"}\" ?quants: plus_quant | star_quant | num_quant character: LETTER | NUMBER word: WORD %ignore /\\s+/ %import common.LETTER %import common.NUMBER %import common.WORD ","date":"2022-03-02","objectID":"/zh-cn/hw10-of-cs61a-of-ucb/:1:3","tags":["Course","BNF","Mysql"],"title":"Hw10 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/hw10-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"SQL ","date":"2022-03-02","objectID":"/zh-cn/hw10-of-cs61a-of-ucb/:2:0","tags":["Course","BNF","Mysql"],"title":"Hw10 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/hw10-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q4: Size of Dogs The Fédération Cynologique Internationale classifies a standard poodle as over 45 cm and up to 60 cm. The sizes table describes this and other such classifications, where a dog must be over the min and less than or equal to the max in height to qualify as a size. Create a size_of_dogs table with two columns, one for each dog’s name and another for its size. 要根据狗的体型大小来决定它的 size. 这个就是一个基本的 select ... from ... where 的写法. 我们这里可以把两个表连接起来得到所有可能的结果, 然后用 where 来选出符合条件的. 注意这里用 alias 会比较简洁 CREATE TABLE size_of_dogs AS SELECT d.name, s.size FROM dogs as d, sizes as s where d.height \u003c= s.max and d.height \u003e s.min; ","date":"2022-03-02","objectID":"/zh-cn/hw10-of-cs61a-of-ucb/:2:1","tags":["Course","BNF","Mysql"],"title":"Hw10 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/hw10-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q5: By Parent Height Create a table by_parent_height that has a column of the names of all dogs that have a parent, ordered by the height of the parent from tallest parent to shortest parent. 用 ORDER BY 来进行排序, 注意是降序所以用 DESC CREATE TABLE siblings AS SELECT p1.child AS dogone, p2.child AS dogtwo, s1.size AS dogonesize, s2.size AS dogtwosize FROM parents AS p1, parents AS p2, size_of_dogs AS s1, size_of_dogs AS s2 WHERE p1.parent = p2.parent AND p1.child \u003c p2.child AND p1.child = s1.name AND p2.child = s2.name; -- Use `\u003c` to filter the result -- `!=` is not enough, you will get `barack clinton` and `clinton barack` in the same time ","date":"2022-03-02","objectID":"/zh-cn/hw10-of-cs61a-of-ucb/:2:2","tags":["Course","BNF","Mysql"],"title":"Hw10 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/hw10-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q6: Sentences There are two pairs of siblings that have the same size. Create a table that contains a row with a string for each of these pairs. Each string should be a sentence describing the siblings by their size. Each sibling pair should appear only once in the output, and siblings should be listed in alphabetical order (e.g. \"barack plus clinton...\" instead of \"clinton plus barack...\"), as follows: Hint: First, create a helper table containing each pair of siblings. This will make comparing the sizes of siblings when constructing the main table easier. Hint: If you join a table with itself, use AS within the FROM clause to give each table an alias. Hint: In order to concatenate two strings into one, use the || operator. 完成了 Q5 之后这一题就很简单了. CREATE TABLE sentences AS SELECT \"The two siblings, \" || dogone || \" plus \" || dogtwo || \" have the same size: \" || dogonesize FROM siblings WHERE dogonesize = dogtwosize AND dogone \u003c dogtwo; ","date":"2022-03-02","objectID":"/zh-cn/hw10-of-cs61a-of-ucb/:2:3","tags":["Course","BNF","Mysql"],"title":"Hw10 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/hw10-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"the simple solutions for lab10 of CS61A of UCB","date":"2022-02-27","objectID":"/zh-cn/lab10-cs61a-of-ucb/","tags":["Course","Scheme"],"title":"Lab10 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab10-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q2: Over or Under Define a procedure over-or-under which takes in a number num1 and a number num2 and returns the following: -1 if num1 is less than num2 0 if num1 is equal to num2 1 if num1 is greater than num2 Challenge: Implement this in 2 different ways using if and cond! (define (over-or-under num1 num2) 'YOUR-CODE-HERE ) 代码其实本身不难, 主要是适应 scheme 语言的写法, 条件分支有两种写法: (if \u003cpredicate\u003e \u003cconsequent\u003e \u003calternative\u003e) (cond (\u003ccondition\u003e \u003cconsequent\u003e) ...) (define (over-or-under num1 num2) (if (\u003c num1 num2) (print -1)) (if (= num1 num2) (print 0)) (if (\u003e num1 num2) (print 1)) ) (define (over-or-under num1 num2) (cond ( (\u003c num1 num2) (print -1) ) ( (= num1 num2) (print 0) ) ( (\u003e num1 num2) (print 1) )) ) ","date":"2022-02-27","objectID":"/zh-cn/lab10-cs61a-of-ucb/:1:0","tags":["Course","Scheme"],"title":"Lab10 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab10-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q3: Make Adder Write the procedure make-adder which takes in an initial number, num, and then returns a procedure. This returned procedure takes in a number inc and returns the result of num + inc. Hint: To return a procedure, you can either return a lambda expression or define another nested procedure. Remember that Scheme will automatically return the last clause in your procedure. You can find documentation on the syntax of lambda expressions in the 61A scheme specification! 实现高阶函数的功能, 依旧是锻炼 scheme 语言的掌握程度的. 题目都是之前课上讲过的. 这里我用匿名函数来实现 (define (make-adder num) (lambda (inc) (+ num inc)) ) ","date":"2022-02-27","objectID":"/zh-cn/lab10-cs61a-of-ucb/:1:1","tags":["Course","Scheme"],"title":"Lab10 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab10-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q4: Compose Write the procedure composed, which takes in procedures f and g and outputs a new procedure. This new procedure takes in a number x and outputs the result of calling f on g of x. 用 scheme 语言实现符合数学中的复合函数, 也就是高阶函数. 这里同样可以用 lambda 函数 (define (composed f g) (lambda (x) (f (g x) ) ) ) ","date":"2022-02-27","objectID":"/zh-cn/lab10-cs61a-of-ucb/:1:2","tags":["Course","Scheme"],"title":"Lab10 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab10-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q5: Make a List In this problem you will create the list with the following box-and-pointer diagram: Challenge: try to create this list in multiple ways, and using multiple list constructors!要求 题目要求我们按照给定的链表结构来生成对应的链表. 主要考察的是对 scheme 语言中 list 的掌握. 可以有多种实现方式 cons 的方式, 这个方式很容易眼花, 最好是写完之后在这里 验证一下. 这里我真的写得头有点晕 😢 list 的方式, 这个代码会比较短, 注意我们每次在调用 (list ...) 相当于在链表中多创建了一个方向 (define lst (cons (cons 1 nil) (cons 2 (cons (cons 3 (cons 4 nil)) (cons 5 nil)))) ) (define lst (list (list 1) 2 (list 3 4) 5) ) ","date":"2022-02-27","objectID":"/zh-cn/lab10-cs61a-of-ucb/:1:3","tags":["Course","Scheme"],"title":"Lab10 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab10-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q6: Remove Implement a procedure remove that takes in a list and returns a new list with all instances of item removed from lst. You may assume the list will only consist of numbers and will not have nested lists. Hint: You might find the built-in filter procedure useful (though it is definitely possible to complete this question without it). You can find information about how to use filter in the 61A Scheme builtin specification! 这一题就是要我们在 scheme 的列表中移除掉值等于 item 的元素然后返回新的这个列表. 其实 scheme 的列表也就是链表. 所以这一题等效于我们要在链表中移除指定值的元素. 显然, 这可以用递归来解决! 而且这一道题说没有嵌套列表的情况存在, 这一道题就更简单了 ! 显然 base case 就是链表为空的情况, 我们直接返回空. 否则: 当前节点的值 = item, 我们删除它, 递归处理子链表 当前节点的值 != item, 我们保留它, 递归处理子链表 (define (remove item lst) (cond ( (null? lst) '() ) ; base case ( (= item (car lst)) (remove item (cdr lst))) ; exclude item ( else (cons (car lst) (remove item (cdr lst))))) ; include item ) ","date":"2022-02-27","objectID":"/zh-cn/lab10-cs61a-of-ucb/:1:4","tags":["Course","Scheme"],"title":"Lab10 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab10-cs61a-of-ucb/"},{"categories":["Course"],"content":"the simple solutions for lab09 of CS61A of UCB","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/","tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/"},{"categories":["Course"],"content":"Recursion and Tree Recursion ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:1:0","tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q1: Subsequences A subsequence of a sequence S is a subset of elements from S, in the same order they appear in S. Consider the list [1, 2, 3]. Here are a few of it’s subsequences [], [1, 3], [2], and [1, 2, 3]. Write a function that takes in a list and returns all possible subsequences of that list. The subsequences should be returned as a list of lists, where each nested list is a subsequence of the original input. In order to accomplish this, you might first want to write a function insert_into_all that takes an item and a list of lists, adds the item to the beginning of each nested list, and returns the resulting list. 这一道题要求我们返回一个列表的所有可能子序列, 返回的格式是列表的列表, 每一个都是可能的子序列 题目要求我们首先完成一个函数: 功能是把 item 添加到嵌套列表的每个子列表的开头, 这个其实用 list comprehension 就可以了. def insert_into_all(item, nested_list): \"\"\"Return a new list consisting of all the lists in nested_list, but with item added to the front of each. You can assume that nested_list is a list of lists. \"\"\" return [[item] + l for l in nested_list] 这其实是题目给我们的提示, 我们现在思考有了这个函数我们要怎么找到所有可能的子序列呢? 我们可以递归分解问题: 当前元素 + 剩下元素的所有可能子序列(假设是 tmp). 那么我们只要把当前元素加到 tmp 中的每个列表再加上 tmp 即可. 这刚好就用上了题目让我们实现的 insert_into_all() 函数. 那么最后我们要思考什么对应这个 base case. 显然如果一个空的列表的子序列为空列表, 如果列表长度为 1, 则存在两个可能子序列 - 它自己 + 空列表. 最后我们就可以写出这样的代码 def subseqs(s): \"\"\"Return a nested list (a list of lists) of all subsequences of S. The subsequences can appear in any order. You can assume S is a list. \"\"\" if len(s) \u003c= 1: return [[], s] if s !=[] else [[]] else: tmp = subseqs(s[1:]) return insert_into_all(s[0], tmp) + tmp ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:1:1","tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q2: Non-Decreasing Subsequences Just like the last question, we want to write a function that takes a list and returns a list of lists, where each individual list is a subsequence of the original input. This time we have another condition: we only want the subsequences for which consecutive elements are nondecreasing. For example, [1, 3, 2] is a subsequence of [1, 3, 2, 4], but since 2 \u003c 3, this subsequence would not be included in our result. Fill in the blanks to complete the implementation of the non_decrease_subseqs function. You may assume that the input list contains no negative elements. You may use the provided helper function insert_into_all, which takes in an item and a list of lists and inserts the item to the front of each list. 这一道题是在 Q1 的基础上改编而来的, 相当于提出了一个更高的要求, 我们要求子序列同时是非降序的. 这一题的提示告诉我们要实现一个 subseq_helper 函数, 这其实很好理解, 因为我们现在对子序列的大小顺序有要求, 那么我们就要多一个参数用来比较大小, 这样我们在插入 item 到列表的时候才知道可不可以插入(维持非降序). 比如 [1, 3, 2], 当我们在检查 3 的时候我们发现 3 \u003c 1, 显然我们不能把 3 插入到之前生成的子序列列表里. 而其他情况我们则可以选择把 s[0] 加到子序列列表中或者不加. def non_decrease_subseqs(s): \"\"\"Assuming that S is a list, return a nested list of all subsequences of S (a list of lists) for which the elements of the subsequence are strictly nondecreasing. The subsequences can appear in any order. \"\"\" def subseq_helper(s, prev): if not s: return [[]] elif s[0] \u003c prev: return subseq_helper(s[1:], prev) else: a = subseq_helper(s[1:], s[0]) # include s[0] b = subseq_helper(s[1:], prev) # exclude s[0] return insert_into_all(s[0], a) + b return subseq_helper(s, 0) ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:1:2","tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q3: Number of Trees A full binary tree is a tree where each node has either 2 branches or 0 branches, but never 1 branch. Write a function which returns the number of unique full binary tree structures that have exactly n leaves. For those interested in combinatorics, this problem does have a closed form solution): 题意: 有 n 个叶子结点的完全二叉树可能有几种 ? 答案是卡特兰数, 所以我们要实现的其实是卡特兰数的递归写法. 至于为什么是卡特兰数我也想不大明白, 比较能接受的解释是, 完全二叉树的左右子树肯定也是完全二叉树, 假设左子树有 1 个叶子结点, 右子树就有 n - 1 个叶子结点, 那么此时就有 f(1) * f(n - 1) 种可能, 类似的, 如果左子树有 2 个叶子结点, 那就是 f(2) * f(n - 2), 这样累加起来就是卡特兰数. ps: 这里的完全二叉树不是严格意义上的, 确切来说这里指的是所有节点的度只能为 0 或者 2 的树 def num_trees(n): \"\"\"Returns the number of unique full binary trees with exactly n leaves. E.g., \"\"\" if n == 1 or n == 2: return 1 # catalan number ans = 0 for i in range(1, n): ans += num_trees(i) * num_trees(n - i) return ans ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:1:3","tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/"},{"categories":["Course"],"content":"Generators ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:2:0","tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q4: Merge Implement merge(incr_a, incr_b), which takes two iterables incr_a and incr_b whose elements are ordered. merge yields elements from incr_a and incr_b in sorted order, eliminating repetition. You may assume incr_aand incr_b themselves do not contain repeats, and that none of the elements of either are None. You may notassume that the iterables are finite; either may produce an infinite stream of results. You will probably find it helpful to use the two-argument version of the built-in next function: next(incr, v) is the same as next(incr), except that instead of raising StopIteration when incr runs out of elements, it returns v. See the doctest for examples of behavior. merge 函数的功能是合并两个有序的可迭代对象, 同时要做去重的工作, 可以假设两个有序的可迭代对象本身是没有元素重复的, 而且没有任何一个元素是 None. 同时不可以假定这两个可迭代对象是有限序列, 它们可能无序的(这样你就不能暴力合并为一个有序可迭代对象再去重) 因为两个可迭代对象本身不包含重复元素, 所以这一道题处理起来比较简单, 我们只要重复下面的过程: 如果两个可迭代对象都是非空 各取一个元素进行比较 如果一样大: 返回一个, 同时两个 iterator 都要往后移动 其中一个比较小: 返回小的这个, 移动小的这个可迭代对象的 iterator, 大的元素的 iterator 不动 如果重复上面的操作导致其中一个已经空了, 那么接下来的问题就比较简单了, 此时我们只要用 while 循环不断从某一个可迭代对象中返回元素即可. 代码如下: def merge(incr_a, incr_b): \"\"\"Yield the elements of strictly increasing iterables incr_a and incr_b, removing repeats. Assume that incr_a and incr_b have no repeats. incr_a or incr_b may or may not be infinite sequences. \"\"\" iter_a, iter_b = iter(incr_a), iter(incr_b) next_a, next_b = next(iter_a, None), next(iter_b, None) # both are non-empty while next_a is not None and next_b is not None: val_a, val_b = next_a, next_b if val_a == val_b: yield next_a next_a, next_b = next(iter_a, None), next(iter_b, None) elif val_a \u003c val_b: yield next_a next_a = next(iter_a, None) else: yield next_b next_b = next(iter_b, None) # incr_a is not empty while next_a: yield next_a next_a = next(iter_a, None) # incr_b is not empty while next_b: yield next_b next_b = next(iter_b, None) ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:2:1","tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/"},{"categories":["Course"],"content":"Objects ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:3:0","tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q5: Bank Account Implement the class Account, which acts as a a Bank Account. Account should allow the account holder to deposit money into the account, withdraw money from the account, and view their transaction history. The Bank Account should also prevents a user from withdrawing more than the current balance. Transaction history should be stored as a list of tuples, where each tuple contains the type of transaction and the transaction amount. For example a withdrawal of 500 should be stored as (‘withdraw’, 500) Hint: You can call the str function on an integer to get a string representation of the integer. You might find this function useful when implementing the __repr__ and __str__ methods. Hint: You can alternatively use fstrings to implement the __repr__ and __str__ methods cleanly. 实现一个 Account 类, 要求有以下功能: 存款 取款, 钱不够的时候不让取 查看操作历史. 转账历史是 tuple 的列表, 每个 tuple 包括了操作的类型和转账的金额 整体上而言这题不难, 看 __repr__ 我们可以知道要求返回存款和取款的次数, 这里可以用两个变量来记住. class Account: \"\"\"A bank account that allows deposits and withdrawals. It tracks the current account balance and a transaction history of deposits and withdrawals. \"\"\" interest = 0.02 def __init__(self, account_holder): self.balance = 0 self.holder = account_holder self.transactions = [] self.withdraw_cnt = 0 self.deposit_cnt = 0 def deposit(self, amount): \"\"\"Increase the account balance by amount, add the deposit to the transaction history, and return the new balance. \"\"\" self.balance += amount self.transactions.append(('deposit', amount)) self.deposit_cnt += 1 return self.balance def withdraw(self, amount): \"\"\"Decrease the account balance by amount, add the withdraw to the transaction history, and return the new balance. \"\"\" if self.balance \u003e amount: self.balance -= amount self.transactions.append(('withdraw', amount)) self.withdraw_cnt += 1 return self.balance # prevent illegal withdraw return self.balance def __str__(self): return f\"{self.holder}'s Balance: ${self.balance}\" def __repr__(self): return f\"Accountholder: {self.holder}, Deposits: {self.deposit_cnt}, Withdraws: {self.withdraw_cnt}\" ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:3:1","tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/"},{"categories":["Course"],"content":"Mutable Lists ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:4:0","tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q6: Trade In the integer market, each participant has a list of positive integers to trade. When two participants meet, they trade the smallest non-empty prefix of their list of integers. A prefix is a slice that starts at index 0. Write a function trade that exchanges the first m elements of list first with the first n elements of list second, such that the sums of those elements are equal, and the sum is as small as possible. If no such prefix exists, return the string 'No deal!' and do not change either list. Otherwise change both lists and return 'Deal!'. A partial implementation is provided. Hint: You can mutate a slice of a list using slice assignment. To do so, specify a slice of the list [i:j] on the left-hand side of an assignment statement and another list on the right-hand side of the assignment statement. The operation will replace the entire given slice of the list from i inclusive to j exclusive with the elements from the given list. The slice and the given list need not be the same length. \u003e\u003e\u003e a = [1, 2, 3, 4, 5, 6] \u003e\u003e\u003e b = a \u003e\u003e\u003e a[2:5] = [10, 11, 12, 13] \u003e\u003e\u003e a [1, 2, 10, 11, 12, 13, 6] \u003e\u003e\u003e b [1, 2, 10, 11, 12, 13, 6] Additionally, recall that the starting and ending indices for a slice can be left out and Python will use a default value. lst[i:] is the same as lst[i:len(lst)], and lst[:j] is the same as lst[0:j]. 题意: 交换两个列表的开头几个元素(m 和 n 可以不等长), 使得两边被用来交换的子列表的和(前缀和)是一样的, 而且这个和要越小越好. 在代码里已经为我们提供了交换元素的函数, 我们要做的就是让 m 和 n 停在正确的位置(他们的和一样), 这里用 while 循环来实现, 只要两个的索引是有效的(不然他们会一直增加, while 循环就会变为死循环)而且前缀和不想等, 我们移动 m 或者 n 指针. def trade(first, second): \"\"\"Exchange the smallest prefixes of first and second that have equal sum. \"\"\" m, n = 1, 1 equal_prefix = lambda: sum(first[:m]) == sum(second[:n]) while m \u003c= len(first) and n \u003c= len(second) and not equal_prefix(): if sum(first[:m]) \u003c sum(second[:n]): m += 1 else: n += 1 if equal_prefix(): first[:m], second[:n] = second[:n], first[:m] return 'Deal!' else: return 'No deal!' ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:4:1","tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q7: Shuffle Define a function shuffle that takes a sequence with an even number of elements (cards) and creates a new list that interleaves the elements of the first half with the elements of the second half. To interleave two sequences s0 and s1 is to create a new sequence such that the new sequence contains (in this order) the first element of s0, the first element of s1, the second element of s0, the second element of s1, and so on. If the two lists are not the same length, then the leftover elements of the longer list should still appear at the end. Note: If you’re running into an issue where the special heart / diamond / spades / clubs symbols are erroring in the doctests, feel free to copy paste the below doctests into your file as these don’t use the special characters and should not give an “illegal multibyte sequence” error. 这一道题就是要我们完成洗牌的功能, 洗牌的意思是前一半和后一半的元素交替出现, 举例来说:[0, 1, 2, 3, 4, 5] = [0, 3, 1, 4, 2, 5]. 你可以看到奇数索引的是后一半的元素, 偶数索引的是前一半元素. 这一道题的关键在于弄清楚洗牌之后的索引和原来的索引对应的关系, 总结来来说:[0, 1, ..., len(cards) // 2, len(cards) // 2 + 1, ...]. 你可以发现前一半和后一半对应位置的元素的索引相差 len(cards) // 2 def shuffle(cards): \"\"\"Return a shuffled list that interleaves the two halves of cards. \"\"\" assert len(cards) % 2 == 0, 'len(cards) must be even' half = len(cards) // 2 shuffled = [] for i in range(half): shuffled.append(cards[i]) shuffled.append(cards[i + half]) return shuffled ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:4:2","tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/"},{"categories":["Course"],"content":"Linked Lists ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:5:0","tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q8: Insert Implement a function insert that takes a Link, a value, and an index, and inserts the value into the Link at the given index. You can assume the linked list already has at least one element. Do not return anything – insert should mutate the linked list. Note: If the index is out of bounds, you should raise an IndexError with: raise IndexError('Out of bounds!') 根据指定的索引 index 在链表中插入元素, 如果索引非法, 抛出错误 这一题有点奇怪的地方在于, 它要求我们在原来的链表上进行修改, 但是如果我们要在链表的开头进行插入一个新节点, 会无法通过它的 link is other_link 的判断(因为插入后链表头是一个新的节点), 所以我这里想的办法是每次在插入前我们拷贝当前结点, 然后修改当前结点的值为想要插入的值, 这样等效于我们做了插入 def insert(link, value, index): \"\"\"Insert a value into a Link at the given index. \"\"\" pos = link current_index = 0 while pos is not Link.empty: if current_index == index: # make a copy of current node, and modify the current node's value \\ # which is equal to insert a new node :) current_copy = Link(pos.first, pos.rest) origin_next = pos.rest pos.first = value pos.rest = current_copy #print(f\"link: {link.first}\") return pos = pos.rest current_index += 1 raise IndexError('Out of bounds!') ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:5:1","tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q9: Deep Linked List Length A linked list that contains one or more linked lists as elements is called a deep linked list. Write a function deep_len that takes in a (possibly deep) linked list and returns the deep length of that linked list. The deep length of a linked list is the total number of non-link elements in the list, as well as the total number of elements contained in all contained lists. See the function’s doctests for examples of the deep length of linked lists. Hint: Use isinstance to check if something is an instance of an object. Deep Linked List Length 其实就是一个可能包含链表为结点的嵌套链表结构. 这一道题要求我们算这种嵌套列表一共有多少个元素. 其实就是之前做的摊平链表的那种题目. 显然, 这是符合递归的嵌套结构, 所以我们可以用递归的办法解决. base case 就是空链表或者它是一个元素而不是链表. 其他情况我们就递归处理链表的第一个节点和除了第一个结点以外的子链表 🤗 def deep_len(lnk): \"\"\" Returns the deep length of a possibly deep linked list. \"\"\" # base case 1. an empty node if lnk is Link.empty: return 0 # base case 2. an integer elif isinstance(lnk, int): return 1 else: return deep_len(lnk.first) + deep_len(lnk.rest) ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:5:2","tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q10: Linked Lists as Strings Kevin and Jerry like different ways of displaying the linked list structure in Python. While Kevin likes box and pointer diagrams, Jerry prefers a more futuristic way. Write a function make_to_string that returns a function that converts the linked list to a string in their preferred style. Hint: You can convert numbers to strings using the str function, and you can combine strings together using +. \u003e\u003e\u003e str(4) '4' \u003e\u003e\u003e 'cs ' + str(61) + 'a' 'cs 61a' 简单来说就是想要根据不同人的需求来打印链表, 具体格式就是 front + 当前结点的值 + mid + 子链表的 + back 这样 def make_to_string(front, mid, back, empty_repr): \"\"\" Returns a function that turns linked lists to strings. \"\"\" def printer(lnk): if lnk is Link.empty: return empty_repr else: return front + str(lnk.first) + mid + printer(lnk.rest) + back return printer ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:5:3","tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/"},{"categories":["Course"],"content":"Trees ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:6:0","tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q11: Long Paths Implement long_paths, which returns a list of all paths in a tree with length at least n. A path in a tree is a list of node labels that starts with the root and ends at a leaf. Each subsequent element must be from a label of a branch of the previous value’s node. The length of a path is the number of edges in the path (i.e. one less than the number of nodes in the path). Paths are ordered in the output list from left to right in the tree. See the doctests for some examples. 返回一个嵌套列表, 每个子列表表示长度至少为 n 的路径. 这里说的路径一定是叶子结点的路径 ! 路径的长度可以理解为从根结点出发到达叶子结点经过的边数. 这一道题其实是经典的递归与回溯问题, 我们要为其写一个 helper 函数, 要记住我们当前经过的点的路径, 以及路径的长度. 递归与回溯的模板大概如下: def function_name(p): # base case ... dothing thing ... # recursively solve this problem recall what you have done 放到我们这里就是我们要在往更深层递归的时候加上当前节点的 label, 当我们回溯的时候撤销我们对之前的添加. 代码如下: def long_paths(t, n): \"\"\"Return a list of all paths in t with length at least n. \"\"\" path_list = [] def helper(t, current_path, length): nonlocal path_list if t.is_leaf(): current_path.append(t.label) if length \u003e= n: # warning: we need to pass a copy instead fo a ref path_list.append(current_path[:]) current_path.pop() return current_path.append(t.label) for b in t.branches: helper(b, current_path, length + 1) current_path.pop() helper(t, [], 0) return path_list ","date":"2022-02-26","objectID":"/zh-cn/lab09-cs61a-of-ucb/:6:1","tags":["Course","Python"],"title":"Lab09 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab09-cs61a-of-ucb/"},{"categories":["Course"],"content":"the simple solutions for lab08 of CS61A of UCB","date":"2022-02-24","objectID":"/zh-cn/lab08-cs61a-of-ucb/","tags":["Course","Python"],"title":"Lab08 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab08-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q2: Convert Link Write a function convert_link that takes in a linked list and returns the sequence as a Python list. You may assume that the input list is shallow; that is none of the elements is another linked list. Try to find both an iterative and recursive solution for this problem! 迭代的算法很简单, 我们只要创建一个 result list 来存储结果, 遍历链表的同时记住访问过的数即可 def convert_link(link): \"\"\"Takes a linked list and returns a Python list with the same elements. \"\"\" result = [] while link is not Link.empty: result.append(int(link.first)) link = link.rest return result 递归的算法也简单, base case 就是我们遇到了空结点的时候, 这个时候返回的是空的值, 其他情况我们递归分解: 当前结点 + 链表的剩余结点 def convert_link(link): \"\"\"Takes a linked list and returns a Python list with the same elements. \"\"\" # recursive solution if link is Link.empty: return [] else: return [int(link.first)] + convert_link(link.rest) ","date":"2022-02-24","objectID":"/zh-cn/lab08-cs61a-of-ucb/:0:1","tags":["Course","Python"],"title":"Lab08 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab08-cs61a-of-ucb/"},{"categories":["Course"],"content":"Trees ","date":"2022-02-24","objectID":"/zh-cn/lab08-cs61a-of-ucb/:1:0","tags":["Course","Python"],"title":"Lab08 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab08-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q4: Square Write a function label_squarer that mutates a Tree with numerical labels so that each label is squared. 遍历树的所有节点, 将它的 label 都改为 label 的平方 def label_squarer(t): \"\"\"Mutates a Tree t by squaring all its elements. \"\"\" # base case if t.is_leaf(): t.label = t.label ** 2 # check every branch for b in t.branches: t.label = t.label ** 2 # change the current node's label label_squarer(b) # change branches ","date":"2022-02-24","objectID":"/zh-cn/lab08-cs61a-of-ucb/:1:1","tags":["Course","Python"],"title":"Lab08 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab08-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q5: Cumulative Mul Write a function cumulative_mul that mutates the Tree t so that each node’s label becomes the product of its label and all labels in the subtrees rooted at the node. 这一题的意思是: 我们要让每个节点的 label 等于它的所有孩子节点的 label 的乘积, 显然, 这是一个递归问题 base case 就是叶子结点, 此时返回叶子节点的 label. 递归分解问题就是遍历节点的每一个子树, 获得每个子节点返回值再乘以当前结点的 label. 注意我这里用到了 math.prod 这个函数返回可迭代对象的连乘结果, 如果你也要这样使用, 你应该在文件的开头写 import math def cumulative_mul(t): \"\"\"Mutates t so that each node's label becomes the product of all labels in \"\"\" # base case if t.is_leaf(): return t.label # get all label value in subtree vals = [cumulative_mul(b) for b in t.branches] # calculate t.label *= math.prod(vals) ","date":"2022-02-24","objectID":"/zh-cn/lab08-cs61a-of-ucb/:1:2","tags":["Course","Python"],"title":"Lab08 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab08-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q6: Add Leaves Implement add_d_leaves, a function that takes in a Tree instance t and a number v. We define the depth of a node in t to be the number of edges from the root to that node. The depth of root is therefore 0. For each node in the tree, you should add d leaves to it, where d is the depth of the node. Every added leaf should have a label of v. If the node at this depth has existing branches, you should add these leaves to the end of that list of branches. For example, you should be adding 1 leaf with label v to each node at depth 1, 2 leaves to each node at depth 2, and so on. Here is an example of a tree t(shown on the left) and the result after add_d_leaves is applied with v as 5. 翻译一下这一道题的意思: 我们要根据结点在树中的高度(根结点高度为 0)来给结点添加子节点, 这里说的符合条件是 label 为 v. 高度为 d 就增加 d 个子节点. 这题第一个困难是要如何获取当前结点的高度, 因为有了高度我们才能知道要增加多少个子节点, 我们可以维护一个参数表示当前结点的高度. 每当我们往树的更深一层前进的时候我们就将它 +1. base case 就是在叶子结点, 我们根据它的高度增加子结点. 然后对于当前的节点, 我们需要对它的每个孩子节点重复这个步骤, 同时也要判断当前节点是否需要添加子节点 def add_d_leaves(t, v): \"\"\"Add d leaves containing v to each node at every depth d. \"\"\" def helper(t, v, depth): # base case if t.is_leaf(): for i in range(depth): t.branches.append(Tree(v)) return # check every branch for b in t.branches: helper(b, v, depth + 1) # check current node for i in range(depth): t.branches.append(Tree(v)) helper(t, v, 0) ","date":"2022-02-24","objectID":"/zh-cn/lab08-cs61a-of-ucb/:1:3","tags":["Course","Python"],"title":"Lab08 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab08-cs61a-of-ucb/"},{"categories":["Course"],"content":"Optional Questions ","date":"2022-02-24","objectID":"/zh-cn/lab08-cs61a-of-ucb/:2:0","tags":["Course","Python"],"title":"Lab08 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab08-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q7: Every Other Implement every_other, which takes a linked list s. It mutates s such that all of the odd-indexed elements (using 0-based indexing) are removed from the list. For example: \u003e\u003e\u003e s = Link('a', Link('b', Link('c', Link('d')))) \u003e\u003e\u003e every_other(s) \u003e\u003e\u003e s.first 'a' \u003e\u003e\u003e s.rest.first 'c' \u003e\u003e\u003e s.rest.rest is Link.empty True If s contains fewer than two elements, s remains unchanged. Do not return anything! every_other should mutate the original list. 我们可以用迭代的方法来处理这个问题, 首先要处理的是长度的问题, 如果链表的长度小于 2, 那么直接返回. 否则我们就维护两个指针指向当前位置和上一个访问的位置, 当我们要删除索引为奇数(索引从 0 开始)的点的时候就让上一个节点直接指向当前这个节点的下一个节点即可. def every_other(s): \"\"\"Mutates a linked list so that all the odd-indiced elements are removed \"\"\" # if it contains fewer than 2, do nothing if s is Link.empty or s.rest is Link.empty: return last_pos, pos = s, s.rest current_index = 1 # start from 2nd position while pos is not Link.empty: if current_index % 2 == 1: last_pos.rest = pos.rest last_pos = pos pos = pos.rest current_index += 1 ","date":"2022-02-24","objectID":"/zh-cn/lab08-cs61a-of-ucb/:2:1","tags":["Course","Python"],"title":"Lab08 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab08-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q8: Prune Small Complete the function prune_small that takes in a Tree t and a number n and prunes t mutatively. If t or any of its branches has more than n branches, the n branches with the smallest labels should be kept and any other branches should be pruned, or removed, from the tree. 这一道题要我们裁剪这棵树, 具体要求是才见到每个节点最多 n 个子树, 如果超过了 n 就优先移除 label 比较大的, 其实这一道题已经为我们提供了代码, 只要挖空填写就好了. 不难相处, 我们应该自顶向下(从根节点出发)裁剪, 所以第一个 while 循环要完成的动作是如果分支数 \u003e n, 那么找到最大的删掉 而后面的 for 循环则是要让我们到子树中递归裁减 def prune_small(t, n): \"\"\"Prune the tree mutatively, keeping only the n branches of each node with the smallest label. \"\"\" while len(t.branches) \u003e n: largest = max(t.branches, key=lambda x: x.label) t.branches.remove(largest) for b in t.branches: prune_small(b, n) ","date":"2022-02-24","objectID":"/zh-cn/lab08-cs61a-of-ucb/:2:2","tags":["Course","Python"],"title":"Lab08 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/lab08-cs61a-of-ucb/"},{"categories":["Course"],"content":"The simple solutions of hw05 of CS61A of UCB","date":"2022-02-22","objectID":"/zh-cn/hw05-of-cs61a-of-ucb/","tags":["Course","Python"],"title":"Hw05 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/hw05-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q1: Generate Permutations Given a sequence of unique elements, a permutation of the sequence is a list containing the elements of the sequence in some arbitrary order. For example, [2, 1, 3], [1, 3, 2], and [3, 2, 1] are some of the permutations of the sequence [1, 2, 3]. Implement gen_perms, a generator function that takes in a sequence seq and returns a generator that yields all permutations of seq. For this question, assume that seq will not be empty. Permutations may be yielded in any order. Note that the doctests test whether you are yielding all possible permutations, but not in any particular order. The built-in sorted function takes in an iterable object and returns a list containing the elements of the iterable in non-decreasing order. Hint: If you had the permutations of all the elements in seq not including the first element, how could you use that to generate the permutations of the full seq? Hint: Remember, it’s possible to loop over generator objects because generators are iterators! 题意就是要我们返回一个 generator, 这个 generator 会一个个返回列表的所有排列组合. 这个 Hint 明摆着我们要用递归的方法解决这个问题. 很容易想到这一道题的 base case, 如下 def gen_perms(seq): if len(seq) \u003c= 1: yield seq ... 现在的问题就是要如何过渡到子问题, 根据提示我们可以猜: 我们应该递归处理除了第一个位置以外的元素, 再根据题目的另一个提示, 我们应该假定我们的 gen_perms(seq) 就是返回 seq 的全排列, 那我们只要将我们的第一个元素插入到全排列的任意一个位置即可. 举个例子来说, 比如我们处理 [1, 2, 3] 的全排列, 假设我们现在已经得到了 [2, 3] 的全排列——[[2, 3], [3, 2]], 那么我们只要将 1 插入到 [2, 3] 的不同位置, 我们就可以得到 [1, 2, 3], [2, 1, 3], [2, 3, 1], 然后我们对 [3, 2] 进行同样的步骤. 这样我们就得到了所有的全排列, 然后我们可以写出如下的代码 def gen_perms(seq): \"\"\"Generates all permutations of the given sequence. Each permutation is a list of the elements in SEQ in a different order. The permutations may be yielded in any order. \u003e\u003e\u003e perms = gen_perms([100]) \u003e\u003e\u003e type(perms) \u003cclass 'generator'\u003e \u003e\u003e\u003e next(perms) [100] \u003e\u003e\u003e try: #this piece of code prints \"No more permutations!\" if calling next would cause an error ... next(perms) ... except StopIteration: ... print('No more permutations!') No more permutations! \u003e\u003e\u003e sorted(gen_perms([1, 2, 3])) # Returns a sorted list containing elements of the generator [[1, 2, 3], [1, 3, 2], [2, 1, 3], [2, 3, 1], [3, 1, 2], [3, 2, 1]] \u003e\u003e\u003e sorted(gen_perms((10, 20, 30))) [[10, 20, 30], [10, 30, 20], [20, 10, 30], [20, 30, 10], [30, 10, 20], [30, 20, 10]] \u003e\u003e\u003e sorted(gen_perms(\"ab\")) [['a', 'b'], ['b', 'a']] \"\"\" # This problem requires list type, see example above if type(seq) != list: seq = list(seq) # base case if len(seq) \u003c= 1: yield seq else: # iterate every permutation in the generator for perm in gen_perms(seq[1:]): # enumerate every position for insertation for i in range(len(seq)): yield perm[:i] + seq[:1] + perm[i:] ","date":"2022-02-22","objectID":"/zh-cn/hw05-of-cs61a-of-ucb/:0:1","tags":["Course","Python"],"title":"Hw05 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/hw05-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q2: Yield Paths Define a generator function path_yielder which takes in a tree t, a value value, and returns a generator object which yields each path from the root of t to a node that has label value. Each path should be represented as a list of the labels along that path in the tree. You may yield the paths in any order. We have provided a skeleton for you. You do not need to use this skeleton, but if your implementation diverges significantly from it, you might want to think about how you can get it to fit the skeleton. 题目让我们返回从根结点出发到达所有标签为 value 的路径. 注意给我们的提示, 我们要实现的函数应该如下所示: def path_yielder(t, value): \"*** YOUR CODE HERE ***\" for _______________ in _________________: for _______________ in _________________: \"*** YOUR CODE HERE ***\" 如果你仔细观察, 或许可以发现这一题的代码跟 Q1 竟是如此相似, 现在我们开始思考如何来解决这个问题. 首先要处理什么是 base case, 显然当我们遇到 label 是 value 的结点时候就到达了 base case 可以返回. 而将这个问题分解为更简单的子问题的方式也很简单, 我们要从当前结点出发, 遍历它的每一个子树, 只要路径上有就返回, 注意这里我们返回的是子路径(不包括当前结点), 然后我们加上当前结点的 label 即可. 用一个例子来说, 看下面的 docstring 里面的例子, 假设我们现在要找到所有到达 label 为 3 的所有路径, 我们从根结点 1 出发, 检查的它的每一个子树, 分别是 2 和 5. 然后我们接着对 2 这么处理, 在 2 的第一个子树中我们找到了 3, 此时我们 yield [3]. 当我们回溯到 2 的时候加上 2, 我们又得到了子路径 [2, 3], 最后我们接着回溯到根结点, 得到 [1] + [2, 3] = [1, 2, 3] 代码如下: def path_yielder(t, value): \"\"\"Yields all possible paths from the root of t to a node with the label value as a list. \u003e\u003e\u003e t1 = tree(1, [tree(2, [tree(3), tree(4, [tree(6)]), tree(5)]), tree(5)]) \u003e\u003e\u003e print_tree(t1) 1 2 3 4 6 5 5 \u003e\u003e\u003e next(path_yielder(t1, 6)) [1, 2, 4, 6] \u003e\u003e\u003e path_to_5 = path_yielder(t1, 5) \u003e\u003e\u003e sorted(list(path_to_5)) [[1, 2, 5], [1, 5]] \u003e\u003e\u003e t2 = tree(0, [tree(2, [t1])]) \u003e\u003e\u003e print_tree(t2) 0 2 1 2 3 4 6 5 5 \u003e\u003e\u003e path_to_2 = path_yielder(t2, 2) \u003e\u003e\u003e sorted(list(path_to_2)) [[0, 2], [0, 2, 1, 2]] \"\"\" if label(t) == value: yield [label(t)] for b in branches(t): for path in path_yielder(b, value): yield [label(t)] + path ","date":"2022-02-22","objectID":"/zh-cn/hw05-of-cs61a-of-ucb/:0:2","tags":["Course","Python"],"title":"Hw05 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/hw05-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q3: Preorder Define the function preorder, which takes in a tree as an argument and returns a list of all the entries in the tree in the order that print_tree would print them. The following diagram shows the order that the nodes would get printed, with the arrows representing function calls. 又是树的先序遍历问题, 这真的是一个十分经典的问题. 我们要递归访问这一棵树的所有结点, 从根结点出发, 注意我们是先记住根结点的值再去看它的子树, 并递归式处理这样的问题. def preorder(t): \"\"\"Return a list of the entries in this tree in the order that they would be visited by a preorder traversal (see problem description). \u003e\u003e\u003e numbers = tree(1, [tree(2), tree(3, [tree(4), tree(5)]), tree(6, [tree(7)])]) \u003e\u003e\u003e preorder(numbers) [1, 2, 3, 4, 5, 6, 7] \u003e\u003e\u003e preorder(tree(2, [tree(4, [tree(6)])])) [2, 4, 6] \"\"\" result = [] def helper(t): if t is not None: result.append(label(t)) for b in branches(t): helper(b) helper(t) return result ","date":"2022-02-22","objectID":"/zh-cn/hw05-of-cs61a-of-ucb/:0:3","tags":["Course","Python"],"title":"Hw05 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/hw05-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q4: Generate Preorder Similarly to preorder in Question 3, define the function generate_preorder, which takes in a tree as an argument and now instead yields the entries in the tree in the order that print_tree would print them. Hint: How can you modify your implementation of preorder to yield from your recursive calls instead of returning them? 仍旧是先序遍历的问题, 整体解法上很像 Q3, 只是现在我们不需要用一个 result 来存储遍历的序列, 因为我们要返回的是 generator. 但这个算法的逻辑还是一致的, 先看根结点, 然后去看它的子树的结点. 如果想对 yield from 有更深的了解, 我们可以看看这个人的这篇文章 def generate_preorder(t): \"\"\"Yield the entries in this tree in the order that they would be visited by a preorder traversal (see problem description). \u003e\u003e\u003e numbers = tree(1, [tree(2), tree(3, [tree(4), tree(5)]), tree(6, [tree(7)])]) \u003e\u003e\u003e gen = generate_preorder(numbers) \u003e\u003e\u003e next(gen) 1 \u003e\u003e\u003e list(gen) [2, 3, 4, 5, 6, 7] \"\"\" yield label(t) for b in branches(t): yield from generate_preorder(b) ","date":"2022-02-22","objectID":"/zh-cn/hw05-of-cs61a-of-ucb/:0:4","tags":["Course","Python"],"title":"Hw05 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/hw05-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q5: Remainder Generator Like functions, generators can also be higher-order. For this problem, we will be writing remainders_generator, which yields a series of generator objects. remainders_generator takes in an integer m, and yields m different generators. The first generator is a generator of multiples of m, i.e. numbers where the remainder is 0. The second is a generator of natural numbers with remainder 1 when divided by m. The last generator yields natural numbers with remainder m - 1 when divided by m. Hint: To create a generator of infinite natural numbers, you can call the naturals function that’s provided in the starter code. Hint: Consider defining an inner generator function. Each yielded generator varies only in that the elements of each generator have a particular remainder when divided by m. What does that tell you about the argument(s) that the inner function should take in? 这个问题如果你对 python 的 generator 一点都不了解的话, 一时要写出这样的代码是比较困难的, 我会推荐你先阅读这个教程. 在阅读上面的材料之后我们开始以前来想这个问题要怎么解决. 其实它就是要返回 m 个 generator, 第 i 个 generator 里面分别是除以 m 得到余数为 i 的所有数. 注意, 我们要的是所有数, 所以我们可以现象我们要怎么得到第一个 generator, 其他 generator 其实都是类似的. 我们只要用一个 while True 死循环来一直找就行, 因为我们用的是 yield, 它每次找到一个就会暂停执行并返回那个数. 这样我们就得到了这个无限产生我们想要的数的 generator def helper(i, m): num = 1 # loop variable while True: if num % m == i: yield num num += 1 # you can give it a test \u003e\u003e\u003e it = helper(2, 3) \u003e\u003e\u003e next(it) 2 # 2 % 3 == 2 \u003e\u003e\u003e next(it) 5 # 5 % 3 == 2 \u003e\u003e\u003e next(it) 8 # 8 % 3 == 2 那么我们如何得到一个 generator 的 list 呢, 也很简单, 我们用 for 循环就好了 def remainders_generator(m): \"\"\" Yields m generators. The ith yielded generator yields natural numbers whose remainder is i when divided by m. \u003e\u003e\u003e import types \u003e\u003e\u003e [isinstance(gen, types.GeneratorType) for gen in remainders_generator(5)] [True, True, True, True, True] \u003e\u003e\u003e remainders_four = remainders_generator(4) \u003e\u003e\u003e for i in range(4): ... print(\"First 3 natural numbers with remainder {0} when divided by 4:\".format(i)) ... gen = next(remainders_four) ... for _ in range(3): ... print(next(gen)) First 3 natural numbers with remainder 0 when divided by 4: 4 8 12 First 3 natural numbers with remainder 1 when divided by 4: 1 5 9 First 3 natural numbers with remainder 2 when divided by 4: 2 6 10 First 3 natural numbers with remainder 3 when divided by 4: 3 7 11 \"\"\" def helper(i, m): num = 1 # loop variable while True: if num % m == i: yield num num += 1 for i in range(m): yield helper(i, m) ","date":"2022-02-22","objectID":"/zh-cn/hw05-of-cs61a-of-ucb/:0:5","tags":["Course","Python"],"title":"Hw05 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/hw05-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"The simple solutions of hw04 of CS61A of UCB","date":"2022-02-20","objectID":"/zh-cn/hw04-of-cs61a-of-ucb/","tags":["Course","Python"],"title":"Hw04 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/hw04-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Mobiles ","date":"2022-02-20","objectID":"/zh-cn/hw04-of-cs61a-of-ucb/:1:0","tags":["Course","Python"],"title":"Hw04 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/hw04-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q2: Weights Implement the planet data abstraction by completing the planet constructor and the size selector so that a planet is represented using a two-element list where the first element is the string 'planet' and the second element is its size. 从问题的描述中我们可以知道什么是 planet. 就是一个长度为 2 的 list, 内容是 ['planet', size]. 可以参考 mobile 函数, 这两个函数的代码是很类似的 def planet(size): \"\"\"Construct a planet of some size.\"\"\" assert size \u003e 0 return ['planet', size] def size(w): \"\"\"Select the size of a planet.\"\"\" assert is_planet(w), 'must call size on a planet' return w[1] ","date":"2022-02-20","objectID":"/zh-cn/hw04-of-cs61a-of-ucb/:1:1","tags":["Course","Python"],"title":"Hw04 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/hw04-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q3: Balanced Implement the balanced function, which returns whether m is a balanced mobile. A mobile is balanced if both of the following conditions are met: The torque applied by its left arm is equal to that applied by its right arm. The torque of the left arm is the length of the left rod multiplied by the total weight hanging from that rod. Likewise for the right. For example, if the left arm has a length of 5, and there is a mobile hanging at the end of the left arm of weight 10, the torque on the left side of our mobile is 50. Each of the mobiles hanging at the end of its arms is balanced. Planets themselves are balanced, as there is nothing hanging off of them. 这个问题需要用递归的方法来解决. 我们判断一个 mobile 平衡的条件如下 它是 planet, 根据描述可以知道本身是平衡的 它是 arm, 并且 total_weight(left_arm) == total_weight(right_arm). 并且它的所有子树都要符合这个平衡的条件. 注意不要漏掉对子树的判断 写出代码的关键: 要区分开 arm, planet, mobile 这三个概念并且要能够知道用什么对应的函数来处理. 😢 def balanced(m): \"\"\"Return whether m is balanced. \u003e\u003e\u003e t, u, v = examples() \u003e\u003e\u003e balanced(t) True \u003e\u003e\u003e balanced(v) True \u003e\u003e\u003e w = mobile(arm(3, t), arm(2, u)) \u003e\u003e\u003e balanced(w) False \u003e\u003e\u003e balanced(mobile(arm(1, v), arm(1, w))) False \u003e\u003e\u003e balanced(mobile(arm(1, w), arm(1, v))) False \u003e\u003e\u003e from construct_check import check \u003e\u003e\u003e # checking for abstraction barrier violations by banning indexing \u003e\u003e\u003e check(HW_SOURCE_FILE, 'balanced', ['Index']) True \"\"\" # planet is balanced if is_planet(m): return True left_arm, right_arm = left(m), right(m) # end(...arm) will is a mobile or a planet left_val = length(left_arm) * total_weight(end(left_arm)) right_val = length(right_arm) * total_weight(end(right_arm)) return left_val == right_val and balanced(end(left_arm)) and balanced(end(right_arm)) ","date":"2022-02-20","objectID":"/zh-cn/hw04-of-cs61a-of-ucb/:1:2","tags":["Course","Python"],"title":"Hw04 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/hw04-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q4: Totals Implement totals_tree, which takes in a mobile or planet and returns a tree whose root is the total weight of the input. For a planet, totals_tree should return a leaf. For a mobile, totals_tree should return a tree whose label is that mobile’s total weight, and whose branches are totals_trees for the ends of its arms. As a reminder, the description of the tree data abstraction can be found here. 我们在这个问题中想要把 mobile 转换为 tree. 递归解法的 base case 是当我们遇到叶子结点而且是 planet 的时候. 否则我们就递归分析它的子树 def totals_tree(m): \"\"\"Return a tree representing the mobile with its total weight at the root. \u003e\u003e\u003e t, u, v = examples() \u003e\u003e\u003e print_tree(totals_tree(t)) 3 2 1 \u003e\u003e\u003e print_tree(totals_tree(u)) 6 1 5 3 2 \u003e\u003e\u003e print_tree(totals_tree(v)) 9 3 2 1 6 1 5 3 2 \u003e\u003e\u003e from construct_check import check \u003e\u003e\u003e # checking for abstraction barrier violations by banning indexing \u003e\u003e\u003e check(HW_SOURCE_FILE, 'totals_tree', ['Index']) True \"\"\" if is_planet(m): return tree(size(m)) return tree(total_weight(m), [totals_tree(i) for i in [end(left(m)), end(right(m))]]) ","date":"2022-02-20","objectID":"/zh-cn/hw04-of-cs61a-of-ucb/:1:3","tags":["Course","Python"],"title":"Hw04 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/hw04-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"More trees ","date":"2022-02-20","objectID":"/zh-cn/hw04-of-cs61a-of-ucb/:2:0","tags":["Course","Python"],"title":"Hw04 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/hw04-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q5: Replace Loki at Leaf Define replace_loki_at_leaf, which takes a tree t and a value lokis_replacement. replace_loki_at_leaf returns a new tree that’s the same as t except that every leaf label equal to \"loki\" has been replaced with lokis_replacement. If you want to learn about the Norse mythology referenced in this problem, you can read about it here. 递归解法的 base case 仍然是叶子结点, 我们要检查它的 label 是否为 ’loki’. 如果是的话, 我们就创建一个新的叶子结点并返回. 否则我们返回本来的叶子结点即可. def replace_loki_at_leaf(t, lokis_replacement): \"\"\"Returns a new tree where every leaf value equal to \"loki\" has been replaced with lokis_replacement. \u003e\u003e\u003e yggdrasil = tree('odin', ... [tree('balder', ... [tree('loki'), ... tree('freya')]), ... tree('frigg', ... [tree('loki')]), ... tree('loki', ... [tree('sif'), ... tree('loki')]), ... tree('loki')]) \u003e\u003e\u003e laerad = copy_tree(yggdrasil) # copy yggdrasil for testing purposes \u003e\u003e\u003e print_tree(replace_loki_at_leaf(yggdrasil, 'freya')) odin balder freya freya frigg freya loki sif freya freya \u003e\u003e\u003e laerad == yggdrasil # Make sure original tree is unmodified True \"\"\" if is_leaf(t): if label(t) == 'loki': return tree(lokis_replacement) return t return tree(label(t), [replace_loki_at_leaf(b, lokis_replacement) for b in branches(t)]) ","date":"2022-02-20","objectID":"/zh-cn/hw04-of-cs61a-of-ucb/:2:1","tags":["Course","Python"],"title":"Hw04 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/hw04-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q6: Has Path Write a function has_path that takes in a tree t and a string word. It returns True if there is a path that starts from the root where the entries along the path spell out the word, and False otherwise. (This data structure is called a trie, and it has a lot of cool applications, such as autocomplete). You may assume that every node’s labelis exactly one character. 什么是这道题的 base case ? 我们要记住从根结点出发到当前所在结点一路经过的结点拼起来的字符串是什么. 举例来说, 在一开始的时候我们在根结点, 我们的字符串是 label(t). 也就是 h. 当我们到了根结点的第一个子结点的时候, 我们就得到了 h + i = hi. 为了实现这样的功能我们可以另外写个递归函数. 然后在 has_path 里面调用即可. 一个提高效率的方法是如果我们当前得到的字符串不是目标字符串的一部分(开头位置), 那么我们显然没有必要继续到更深的子树里面寻找. 这也是递归的剪枝操作. 怎么把问题分解为更简单的子问题 ? 我们可以使用 python 提供的 any 函数, 只要任意一个子树上存在这样的路径即可. def has_path(t, word): \"\"\"Return whether there is a path in a tree where the entries along the path spell out a particular word. \u003e\u003e\u003e greetings = tree('h', [tree('i'), ... tree('e', [tree('l', [tree('l', [tree('o')])]), ... tree('y')])]) \u003e\u003e\u003e print_tree(greetings) h i e l l o y \u003e\u003e\u003e has_path(greetings, 'h') True \u003e\u003e\u003e has_path(greetings, 'i') False \u003e\u003e\u003e has_path(greetings, 'hi') True \u003e\u003e\u003e has_path(greetings, 'hello') True \u003e\u003e\u003e has_path(greetings, 'hey') True \u003e\u003e\u003e has_path(greetings, 'bye') False \u003e\u003e\u003e has_path(greetings, 'hint') False \"\"\" assert len(word) \u003e 0, 'no path for empty word.' def helper(t, cur): if cur == word: return True if cur not in word: return False return any([helper(b, cur + label(b)) for b in branches(t)]) return helper(t, label(t)) ","date":"2022-02-20","objectID":"/zh-cn/hw04-of-cs61a-of-ucb/:2:2","tags":["Course","Python"],"title":"Hw04 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/hw04-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Trees ","date":"2022-02-20","objectID":"/zh-cn/hw04-of-cs61a-of-ucb/:3:0","tags":["Course","Python"],"title":"Hw04 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/hw04-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q7: Preorder Define the function preorder, which takes in a tree as an argument and returns a list of all the entries in the tree in the order that print_tree would print them. The following diagram shows the order that the nodes would get printed, with the arrows representing function calls. 先序遍历是遍历树的一个基本方法. 我们要先记住根结点的值再去访问它的子树上的结点. def preorder(t): \"\"\"Return a list of the entries in this tree in the order that they would be visited by a preorder traversal (see problem description). \u003e\u003e\u003e numbers = tree(1, [tree(2), tree(3, [tree(4), tree(5)]), tree(6, [tree(7)])]) \u003e\u003e\u003e preorder(numbers) [1, 2, 3, 4, 5, 6, 7] \u003e\u003e\u003e preorder(tree(2, [tree(4, [tree(6)])])) [2, 4, 6] \"\"\" result = [] def helper(t): if t is not None: result.append(label(t)) for b in branches(t): helper(b) helper(t) return result ","date":"2022-02-20","objectID":"/zh-cn/hw04-of-cs61a-of-ucb/:3:1","tags":["Course","Python"],"title":"Hw04 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/hw04-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Data Abstraction ","date":"2022-02-20","objectID":"/zh-cn/hw04-of-cs61a-of-ucb/:4:0","tags":["Course","Python"],"title":"Hw04 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/hw04-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q8: Interval Abstraction Acknowledgements. This interval arithmetic example is based on a classic problem from Structure and Interpretation of Computer Programs, Section 2.1.4. Introduction. Alyssa P. Hacker is designing a system to help people solve engineering problems. One feature she wants to provide in her system is the ability to manipulate inexact quantities (such as measurements from physical devices) with known precision, so that when computations are done with such approximate quantities the results will be numbers of known precision. For example, if a measured quantity x lies between two numbers a and b, Alyssa would like her system to use this range in computations involving x. Alyssa’s idea is to implement interval arithmetic as a set of arithmetic operations for combining “intervals” (objects that represent the range of possible values of an inexact quantity). The result of adding, subracting, multiplying, or dividing two intervals is also an interval, one that represents the range of the result. Alyssa suggests the existence of an abstraction called an “interval” that has two endpoints: a lower bound and an upper bound. She also presumes that, given the endpoints of an interval, she can create the interval using data abstraction. Using this constructor and the appropriate selectors, she defines the following operations: Alyssa’s program is incomplete because she has not specified the implementation of the interval abstraction. She has implemented the constructor for you; fill in the implementation of the selectors. 这道题的计算系统其实是用来计算电阻的. 我们知道电阻会存在误差(比如 $\\pm5%$), 所以真正的电阻值应该是在一个区间里面的. 这就是这个所谓的的 interval 表示的. 所以 interval 其实也就是一个长度为 2 的 list 而已. 要得到它两侧的范围我们只要根据索引返回 x[0] 或 x[1] 即可. def interval(a, b): \"\"\"Construct an interval from a to b.\"\"\" assert a \u003c= b, 'Lower bound cannot be greater than upper bound' return [a, b] def lower_bound(x): \"\"\"Return the lower bound of interval x.\"\"\" return x[0] def upper_bound(x): \"\"\"Return the upper bound of interval x.\"\"\" return x[1] ","date":"2022-02-20","objectID":"/zh-cn/hw04-of-cs61a-of-ucb/:4:1","tags":["Course","Python"],"title":"Hw04 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/hw04-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q9: Interval Arithmetic After implementing the abstraction, Alyssa decided to implement a few interval arithmetic functions. This is her current implementation for interval multiplication. Unfortunately there are some data abstraction violations, so your task is to fix this code before someone sets it on fire. def mul_interval(x, y): \"\"\"Return the interval that contains the product of any value in x and any value in y.\"\"\" p1 = x[0] * y[0] p2 = x[0] * y[1] p3 = x[1] * y[0] p4 = x[1] * y[1] return [min(p1, p2, p3, p4), max(p1, p2, p3, p4)] 这里面有很多违反了数据抽象原则的操作, 比如我们访问电阻的上下界的时候不应该直接用 x[0] 或 x[1]. ⚠️ 这其实是破坏了封装性, 万一以后我们换个一个实现电阻的方式, 这个代码就用不了了. 所以正确的方法应该是用前面实现的 lower_bound() 和 upper_bound() 这两个函数. 除此之外, 我们在创建一个 interval 的时候也应该用 interval 这个构造函数. def mul_interval(x, y): \"\"\"Return the interval that contains the product of any value in x and any value in y.\"\"\" p1 = lower_bound(x) * lower_bound(y) p2 = lower_bound(x) * upper_bound(y) p3 = upper_bound(x) * lower_bound(y) p4 = upper_bound(x) * upper_bound(y) return interval(min(p1, p2, p3, p4), max(p1, p2, p3, p4)) Interval Subtraction Using a similar approach as mul_interval and add_interval, define a subtraction function for intervals. If you find yourself repeating code, see if you can reuse functions that have already been implemented. 这个代码如果和 mul_interval 的几乎一模一样, 只是换了个操作符而已. 如果你跟我一样用的是 vim 作为编辑器, 那么用 \u003cctrl-v\u003e 选中四个 * 之后我们用 r- 就可以快速替换掉了. def sub_interval(x, y): \"\"\"Return the interval that contains the difference between any value in x and any value in y.\"\"\" p1 = lower_bound(x) - lower_bound(y) p2 = lower_bound(x) - upper_bound(y) p3 = upper_bound(x) - lower_bound(y) p4 = upper_bound(x) - upper_bound(y) return interval(min(p1, p2, p3, p4), max(p1, p2, p3, p4)) Interval Division Alyssa implements division below by multiplying by the reciprocal of y. A systems programmer looks over Alyssa’s shoulder and comments that it is not clear what it means to divide by an interval that spans zero. Add an assertstatement to Alyssa’s code to ensure that no such interval is used as a divisor: 检查是否除数 \u003e 0 def div_interval(x, y): \"\"\"Return the interval that contains the quotient of any value in x divided by any value in y. Division is implemented as the multiplication of x by the reciprocal of y.\"\"\" assert lower_bound(y) \u003e 0, \"AssertionError!\" reciprocal_y = interval(1 / upper_bound(y), 1 / lower_bound(y)) return mul_interval(x, reciprocal_y) ","date":"2022-02-20","objectID":"/zh-cn/hw04-of-cs61a-of-ucb/:4:2","tags":["Course","Python"],"title":"Hw04 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/hw04-of-cs61a-of-ucb/"},{"categories":["Course"],"content":"Q10: Par Diff After considerable work, Alyssa P. Hacker delivers her finished system. Several years later, after she has forgotten all about it, she gets a frenzied call from an irate user, Lem E. Tweakit. It seems that Lem has noticed that theformula for parallel resistors can be written in two algebraically equivalent ways: par1(r1, r2) = (r1 * r2) / (r1 + r2) or par2(r1, r2) = 1 / (1/r1 + 1/r2) He has written the following two programs, each of which computes the parallel_resistors formula differently: def par2(r1, r2): one = interval(1, 1) rep_r1 = div_interval(one, r1) rep_r2 = div_interval(one, r2) return div_interval(one, add_interval(rep_r1, rep_r2)) Lem points out that Alyssa’s program gives different answers for the two ways of computing. Find two intervals r1 and r2 that demonstrate the difference in behavior between par1 and par2 when passed into each of the two functions. Demonstrate that Lem is right. Investigate the behavior of the system on a variety of arithmetic expressions. Make some intervals r1 and r2, and show that par1 and par2 can give different results. 如果你想知道这个的详细解释的话, 可以看一下这个 链接 def check_par(): \"\"\"Return two intervals that give different results for parallel resistors. \u003e\u003e\u003e r1, r2 = check_par() \u003e\u003e\u003e x = par1(r1, r2) \u003e\u003e\u003e y = par2(r1, r2) \u003e\u003e\u003e lower_bound(x) != lower_bound(y) or upper_bound(x) != upper_bound(y) True \"\"\" r1 = interval(5, 7) r2 = interval(5, 7) return r1, r2 ","date":"2022-02-20","objectID":"/zh-cn/hw04-of-cs61a-of-ucb/:4:3","tags":["Course","Python"],"title":"Hw04 - CS61A of UCB(2021-Fall)","uri":"/zh-cn/hw04-of-cs61a-of-ucb/"},{"categories":["Tool"],"content":"Explain how to use hammerspoon to manage windows","date":"2022-01-21","objectID":"/zh-cn/how-to-manage-windows-using-hammerspoon/","tags":["Tool"],"title":"How to Manage Windows Using Hammerspoon","uri":"/zh-cn/how-to-manage-windows-using-hammerspoon/"},{"categories":["Tool"],"content":"引言 虽然 macOS 自带窗口管理这个功能, 但是实际上是用下来发现还是很难受的. 功能不足以满足自己的需求. 所以我常常发现自己在用鼠标拖动窗口和重新调整窗口大小. 长此以往, 我觉得这样效率实在太低, 恰好前阵子在看 MIT-Missing-Semester 的课, 里面提到了 hammerspoon 这个工具. 我去稍微了解了一下发现这工具真的不错. ","date":"2022-01-21","objectID":"/zh-cn/how-to-manage-windows-using-hammerspoon/:1:0","tags":["Tool"],"title":"How to Manage Windows Using Hammerspoon","uri":"/zh-cn/how-to-manage-windows-using-hammerspoon/"},{"categories":["Tool"],"content":"什么是 hammerspoon ? 根据官方文档介绍, hammerspoon 是 macOS 上一个用于自动化的工具, 充当了 Lua 语言和操作系统的系统调用之间的桥梁. 也就是说我们可以使用 Lua 语言和 hammerspoon 提供的 API 来来完成很多自动化操作. 目前我还只看了窗口管理相关的. 因为要用到 Lua 语言, 但是我又根本没有接触过这个语言, 所以我大概跟着 Learn Lua in Y minutes 稍微学习了一下. ","date":"2022-01-21","objectID":"/zh-cn/how-to-manage-windows-using-hammerspoon/:2:0","tags":["Tool"],"title":"How to Manage Windows Using Hammerspoon","uri":"/zh-cn/how-to-manage-windows-using-hammerspoon/"},{"categories":["Tool"],"content":"怎么管理窗口? 我主要想要有下面的几个功能 可以把窗口移动到屏幕的左边或者是右边(1 / 2 屏幕) 可以把窗口弄成全屏的 可以把窗口移动到左上角/右上角/左下角/右下角(1 / 4 屏幕) 把当前的窗口移动到屏幕中央 我的方案主要是写了三个 *.lua file(我放在了我的 github 仓库 dotfiles 里) 👉config.lua MACBOOK_MONITOR = 'Built-in Retina Display' -- disable animations, default value = 0.2 hs.window.animationDuration = 0 👉init.lua require('config') require('window') 👉window.lua 这个是主要的代码 -- half of screen -- {frame.x, frame.y, window.w, window.h} -- First two elements: we decide the position of frame -- Last two elements: we decide the size of frame hs.hotkey.bind({'alt', 'cmd'}, 'left', function() hs.window.focusedWindow():moveToUnit({0, 0, 0.5, 1}) end) hs.hotkey.bind({'alt', 'cmd'}, 'right', function() hs.window.focusedWindow():moveToUnit({0.5, 0, 0.5, 1}) end) hs.hotkey.bind({'alt', 'cmd'}, 'up', function() hs.window.focusedWindow():moveToUnit({0, 0, 1, 0.5}) end) hs.hotkey.bind({'alt', 'cmd'}, 'down', function() hs.window.focusedWindow():moveToUnit({0, 0.5, 1, 0.5}) end) -- quarter of screen --[[ u i j k --]] hs.hotkey.bind({'ctrl', 'alt', 'cmd'}, 'u', function() hs.window.focusedWindow():moveToUnit({0, 0, 0.5, 0.5}) end) hs.hotkey.bind({'ctrl', 'alt', 'cmd'}, 'k', function() hs.window.focusedWindow():moveToUnit({0.5, 0.5, 0.5, 0.5}) end) hs.hotkey.bind({'ctrl', 'alt', 'cmd'}, 'i', function() hs.window.focusedWindow():moveToUnit({0.5, 0, 0.5, 0.5}) end) hs.hotkey.bind({'ctrl', 'alt', 'cmd'}, 'j', function() hs.window.focusedWindow():moveToUnit({0, 0.5, 0.5, 0.5}) end) -- full screen hs.hotkey.bind({'alt', 'cmd'}, 'f', function() hs.window.focusedWindow():moveToUnit({0, 0, 1, 1}) end) -- center screen hs.hotkey.bind({'alt', 'cmd'}, 'c', function() hs.window.focusedWindow():centerOnScreen() end) 你应该把上面三个文件放在 ~/.hammerspoon/ 这个路径下然后在 hammerspoon 里面点击 Reload config 就可以正常使用了🤗 ","date":"2022-01-21","objectID":"/zh-cn/how-to-manage-windows-using-hammerspoon/:3:0","tags":["Tool"],"title":"How to Manage Windows Using Hammerspoon","uri":"/zh-cn/how-to-manage-windows-using-hammerspoon/"},{"categories":["Tool"],"content":"代码解释 hs.hotkey.bind(mods, key, pressedfn) 这个主要是把按键 mods 和 key 绑定到 pressedfn 这个函数上. 在使用的时候先按下 mods 对应的按键组合并保持, 然后再按下 key 对应的按键. 比如我们要让窗口全屏, 我们首先按下并保持 alt(option) 和 cmd, 再按下 f. 就可以让窗口全屏了 pressedfn 这个就是用 Lua 语言写的一个函数 函数的关键在于 hs.window.focusedWindow():moveToUnit({...}) 这个方法. 他的主要功能是获得当前被激活的窗口然后做一些位置和大小上的修改. 参数是 Lua 语言里的 table, 我已经把参数的具体含义写在了注释里, 可以结合下面我画的图来进行理解. ","date":"2022-01-21","objectID":"/zh-cn/how-to-manage-windows-using-hammerspoon/:4:0","tags":["Tool"],"title":"How to Manage Windows Using Hammerspoon","uri":"/zh-cn/how-to-manage-windows-using-hammerspoon/"},{"categories":["Tool"],"content":"参考 Anish’s Hammerspoon config ","date":"2022-01-21","objectID":"/zh-cn/how-to-manage-windows-using-hammerspoon/:5:0","tags":["Tool"],"title":"How to Manage Windows Using Hammerspoon","uri":"/zh-cn/how-to-manage-windows-using-hammerspoon/"},{"categories":["Mac"],"content":"简单介绍怎么用 homebrew 安装本地安装包","date":"2022-01-04","objectID":"/zh-cn/how-to-use-local-file-in-homebrew/","tags":["Mac","Homebrew"],"title":"怎么在 homebrew 里面安装本地安装包","uri":"/zh-cn/how-to-use-local-file-in-homebrew/"},{"categories":["Mac"],"content":"引言 最近想要在 homebrew 上面下载 qbittorent, 发现我即使用的是中科大的源也下载不下来, 终端显示如下内容⬇️ ==\u003e Downloading https://downloads.sourceforge.net/qbittorrent/qbittorrent-mac/qbittorrent-4.3.9/qbittorrent-4.3.9.dmg curl: (35) error:06FFF089:digital envelope routines:CRYPTO_internal:bad key length=# # # Error: Download failed on Cask 'qbittorrent' with message: Download failed: https://downloads.sourceforge.net/qbittorrent/qbittorrent-mac/qbittorrent-4.3.9/qbittorrent-4.3.9.dmg 此时我就想到要不干脆把这个文件下载下来, 然后用 homebrew 本地安装(应该是有这个功能的), 做了一番检索之后, 终于知道要怎么弄了, 下面我将以 qbittorrent-4.3.9.dmg 为例 ","date":"2022-01-04","objectID":"/zh-cn/how-to-use-local-file-in-homebrew/:1:0","tags":["Mac","Homebrew"],"title":"怎么在 homebrew 里面安装本地安装包","uri":"/zh-cn/how-to-use-local-file-in-homebrew/"},{"categories":["Mac"],"content":"Step 1. 获取路径文件名 可以先运行 brew --cache 查看 homebrew 的缓存路径, 一般来说应该是在 ~/Library/Caches/Homebrew 下. homebrew 会把安装包下载到里面的 downloads 文件夹里面, 也就是在 ~/Library/Caches/Homebrew/downloads 下, 进入这个文件夹可以发现里面的文件名的格式都是 \u003curl-hash\u003e--\u003cformula\u003e-\u003cversion\u003e, 显然, 我们也要把我们的安装包弄成这种格式放在里面. 📒 使用 brew --cache -s \u003cformula\u003e 来获取对应的路径文件名 对应我们这篇文章的例子就是 brew --cache -s qbittorrent, 可以看到输出内容是 /Users/\u003c对应你的用户名\u003e/Library/Caches/Homebrew/downloads/7ee479ba2a19cf904e4c415805a6adaead76e7c191d595c016c86b72044c22fa--qbittorrent-4.3.9.dmg ","date":"2022-01-04","objectID":"/zh-cn/how-to-use-local-file-in-homebrew/:2:0","tags":["Mac","Homebrew"],"title":"怎么在 homebrew 里面安装本地安装包","uri":"/zh-cn/how-to-use-local-file-in-homebrew/"},{"categories":["Mac"],"content":"Step 2. 移动本地安装包到对应的目录下 在 Step 1. 中我们已经可以知道该把文件放到什么地方, 接下来要做的无非就是移动文件可以, 如果打开文件浏览器移动那就慢了, 直接在命令行输入对应命令即可 📒 使用 mv \u003clocal-file\u003e \"$(brew --cache -s \u003cformula\u003e)\" 移动本地安装包到对应目录下 对应我们的例子就是 mv qbittorrent-4.3.9.dmg \"$(brew --cache -s qbittorrent)\" ","date":"2022-01-04","objectID":"/zh-cn/how-to-use-local-file-in-homebrew/:3:0","tags":["Mac","Homebrew"],"title":"怎么在 homebrew 里面安装本地安装包","uri":"/zh-cn/how-to-use-local-file-in-homebrew/"},{"categories":["Mac"],"content":"Step 3. 再次运行 brew install 此时再次运行 brew install qbittorrent 即可, 可以看到命令行找到了缓存文件🤗, 而且安装成功了 📒 再次运行 brew install \u003cformula\u003e ==\u003e Downloading https://downloads.sourceforge.net/qbittorrent/qbittorrent-mac/qbittorrent-4.3.9/qbittorrent-4.3.9.dmg Already downloaded: /Users/\u003c对应你的用户名\u003e/Library/Caches/Homebrew/downloads/7ee479ba2a19cf904e4c415805a6adaead76e7c191d595c016c86b72044c22fa--qbittorrent-4.3.9.dmg ==\u003e Installing Cask qbittorrent ==\u003e Moving App 'qbittorrent.app' to '/Applications/qBittorrent.app' 🍺 qbittorrent was successfully installed! ","date":"2022-01-04","objectID":"/zh-cn/how-to-use-local-file-in-homebrew/:4:0","tags":["Mac","Homebrew"],"title":"怎么在 homebrew 里面安装本地安装包","uri":"/zh-cn/how-to-use-local-file-in-homebrew/"},{"categories":["Mac"],"content":"参考 homebrew 文档 ","date":"2022-01-04","objectID":"/zh-cn/how-to-use-local-file-in-homebrew/:5:0","tags":["Mac","Homebrew"],"title":"怎么在 homebrew 里面安装本地安装包","uri":"/zh-cn/how-to-use-local-file-in-homebrew/"},{"categories":["Python"],"content":"简单介绍了用 ipdb 对 Python 文件进行 debug","date":"2021-12-28","objectID":"/zh-cn/how-to-debug-in-python/","tags":["Debug","Python"],"title":"怎么 debug Python 代码","uri":"/zh-cn/how-to-debug-in-python/"},{"categories":["Python"],"content":"引言 PS. 有兴趣的可以查看我翻译的一个项目 - pdb 教程 🙌 很长一段时间内我写代码都是用最简单的 debug 方法, 手动在程序里面插入 print 代码来看具体的变量的值, 然后自己推断程序到底是在哪里出问题。根据 print 的结果可能还要到别的地方重复这个步骤。debug 完之后还得去把这些 print 语句注释掉，即我是一名 print debugger 😢 最近在看 MIT.Missing semester 的课讲到 debug, 顿时感到应该系统学习一下在 Python 里面如何 debug, 虽然用 print 也凑合, 学完之后只恨自己没有早点了解😢 ","date":"2021-12-28","objectID":"/zh-cn/how-to-debug-in-python/:1:0","tags":["Debug","Python"],"title":"怎么 debug Python 代码","uri":"/zh-cn/how-to-debug-in-python/"},{"categories":["Python"],"content":"快速上手 ","date":"2021-12-28","objectID":"/zh-cn/how-to-debug-in-python/:2:0","tags":["Debug","Python"],"title":"怎么 debug Python 代码","uri":"/zh-cn/how-to-debug-in-python/"},{"categories":["Python"],"content":"安装 虽然 Python 有自带的 pdb, 但是 ipdb 的跟它大差不差, 还带颜色输出, 当然用这个了(其实就跟你在命令行要用 python 还是 ipython 一样, 肯定是选择 UI 比较好的 $ pip install ipdb ","date":"2021-12-28","objectID":"/zh-cn/how-to-debug-in-python/:2:1","tags":["Debug","Python"],"title":"怎么 debug Python 代码","uri":"/zh-cn/how-to-debug-in-python/"},{"categories":["Python"],"content":"开始 debug 直接在命令行输入以下内容即可, 其中 \u003cfilename\u003e 表示你要 debug 的文件 $ python -m ipdb \u003cfilename\u003e ","date":"2021-12-28","objectID":"/zh-cn/how-to-debug-in-python/:2:2","tags":["Debug","Python"],"title":"怎么 debug Python 代码","uri":"/zh-cn/how-to-debug-in-python/"},{"categories":["Python"],"content":"ipdb 📒 [ ] 表示是可选参数, 如果没有 [ ] 表示一定要给这个参数 📒 ( ) 表示括号里面的可以不写, 简写命令 ","date":"2021-12-28","objectID":"/zh-cn/how-to-debug-in-python/:3:0","tags":["Debug","Python"],"title":"怎么 debug Python 代码","uri":"/zh-cn/how-to-debug-in-python/"},{"categories":["Python"],"content":"常用 Debug 指令 l(ist) 显示当前行附近的代码, 具体来说是附近的 11 行, 但是记这个具体的数字好像也没啥意义 也可以使用 ll 命令, 会显示当前所在函数或者是堆栈帧的源代码 可以传入参数, 比如要看 1 到 12 行的内容可以用 l 1,12 s(tep) 单步执行下一步, 如果是函数调用, 会进到函数里一步步执行 n(ext) 单步执行下一步, 如果是函数调用, 不会进去函数里一步步执行, 它会一直跳到函数调用执行完成的后一行 c(ontinue) 继续执行, 直到程序发生错误或者正常退出 如果程序是正常退出的, 那么就会输出 The program finished and will be restarted q(uit) 退出 r(eturn) 继续运行到当前函数返回结果为止 w(here) 打印 Stack trace, 看调用轨迹, 从上到下分别是从最内层到最外层的调用入口 可以根据这个调用栈, 用 d(own) [count] 和 u(up) [count] 来在不同的层次间移动 ","date":"2021-12-28","objectID":"/zh-cn/how-to-debug-in-python/:3:1","tags":["Debug","Python"],"title":"怎么 debug Python 代码","uri":"/zh-cn/how-to-debug-in-python/"},{"categories":["Python"],"content":"程序断点专题 每次设置程序断点的时候都会输出你当前这个程序断点的序号 📒 序号默认从 1 开始, 也就是后面提到的 breakpoint [count] b(reak) [line_number] 在 line_number 这一行设置断点 不提供参数的话就是查看我们设置的所有程序断点 高级用法, 你还可以指定文件! 比如你想停在 util.py 文件的第 10 行, 你可以用 b util:10 高级用法, 你在指定文件的同时, 可以指定函数, 还是刚才那个例子, 比如 util.py 文件里面有个 get_result 函数, 你可以用 b util.get_result 高级用法: 你还可以指定满足某些条件才会设置程序断点, 用法如下: b ..., condition tbreak [line_number] 暂时的程序断点, 第一次命中之后就会自己取消 disable [breakpoint count] 暂时不用这个程序断点, 和 clear 不同, 你后面可以通过 enable 重新激活这个程序断点 enable [breakpoint count] 激活程序断点 cl(ear) [breakpoint count | line_number] 通过程序断点的序号或者是对应的行来清除程序断点 unt(il) [line_number] 运行大于等于 line_number 的地方 当然你也可以不提供参数, 此时 unt(il) 命令会继续运行程序到行数比当前行大的那一行(有点绕口, 但意思其实就是下一行🧐), 此时它的功能类似于 n(ext) unt(il) 命令默认会停在当前函数(或者是堆栈帧) return 的地方, 而 c(ontinue) 会一直运行到下去 restart [args...] - 可以给定不同的参数再次重新运行 debug ","date":"2021-12-28","objectID":"/zh-cn/how-to-debug-in-python/:3:2","tags":["Debug","Python"],"title":"怎么 debug Python 代码","uri":"/zh-cn/how-to-debug-in-python/"},{"categories":["Python"],"content":"查看各种信息 h(elp) [command] 不知道命令可以查询一下 p expression 相当于 print expression, 也可以使用 pp(对应 pprint) 一个比较特殊的 expression 是 locals(), 可以查看当前所在位置的 context 要深刻理解这里是 expression 的好处, 如果本来的 expression 不对, 其实你可以直接在这里想要怎么改, 然后直接进行测试 a(rgs) - 打印当前所有的变量的值 whatis expression 相当于 type(expression) source expression 查看 expression 的源码。 常用的 expression 是函数名 ","date":"2021-12-28","objectID":"/zh-cn/how-to-debug-in-python/:3:3","tags":["Debug","Python"],"title":"怎么 debug Python 代码","uri":"/zh-cn/how-to-debug-in-python/"},{"categories":["Python"],"content":"常见问题 Q: 我的变量名跟命令重复了怎么办, 比如变量名是 p ? A: 这个其实不影响, 你还是可以通过 p p 来获取变量名的值. 如果你直接输入 p 显示 p 对应的值的话, 你可以使用 !p, 用 ! 来告诉 ipdb 在它后面的是 python 语句 Q: 每次单步执行之后都要用 p expression 的方式来看变量的值, 有没有更为简便的方法? A: 可以用 display expression, 那么在 expression 的值发生变动的时候, 它就会输出对应的值. 如果要取消就用 undisplay expression Q: 觉得命令有点少不满足自己的需要 ? A: 可以在 ipdb 里面直接写 python 的代码 🤗 Q: 不想使用 python -m ipdb \u003cfilename\u003e 想直接在代码里插入程序断点 ? A: 这也是可以的, 你可以在要插入的行之前设置, 像这样: ... import ipdb; ipdb.set_trace(); ... 📒 如果你是用是 Python 3.7+ 的版本, 可以插入 breakpoint() 而不是 import ipdb; ipdb.set_trace();, 这样设置的好处是你可以一次性取消所有的程序断点，你就可以区分开正常运行的模式和调试程序的模式 Q: -\u003e 指向的行运行了吗 ? A: 没有 Q: 如果我一直在调用 step 命令, 难道我每一次都要输入 s 吗, 有没有更快捷的方法 ? A: 可以直接使用回车键(ENTER), 会自动重复上一次的命令 ","date":"2021-12-28","objectID":"/zh-cn/how-to-debug-in-python/:4:0","tags":["Debug","Python"],"title":"怎么 debug Python 代码","uri":"/zh-cn/how-to-debug-in-python/"},{"categories":["Python"],"content":"参考 pdb 的官方文档 ","date":"2021-12-28","objectID":"/zh-cn/how-to-debug-in-python/:5:0","tags":["Debug","Python"],"title":"怎么 debug Python 代码","uri":"/zh-cn/how-to-debug-in-python/"},{"categories":["Git"],"content":"简单介绍 Git LFS 的使用方法和使用场景","date":"2021-12-06","objectID":"/zh-cn/gitlfs/","tags":["Git"],"title":"Git LFS 使用指南","uri":"/zh-cn/gitlfs/"},{"categories":["Git"],"content":"为什么需要 Git LFS 如果你在命令行用 git push \u003e 50MB 的文件，你会收到一个 warning，但是你仍然可以正常 push，但是 \u003e 100MB 的时候就无法 push 了。如果你是在浏览器要上传文件的话，这个限制更为严重，不能超过 25MB，这是 Github 对仓库的限制。Git lfs 就是用于解决这个问题1 ","date":"2021-12-06","objectID":"/zh-cn/gitlfs/:1:0","tags":["Git"],"title":"Git LFS 使用指南","uri":"/zh-cn/gitlfs/"},{"categories":["Git"],"content":"什么情况下不需要用 Git LFS 下面几个场景不需要用 文件大小没有超过限制当然就没有必要用了 如果是要分发二进制文件（比如 *.exe）等，此时直接用 Github 提供的 release 功能就好了 ","date":"2021-12-06","objectID":"/zh-cn/gitlfs/:1:1","tags":["Git"],"title":"Git LFS 使用指南","uri":"/zh-cn/gitlfs/"},{"categories":["Git"],"content":"Git LFS 原理 使用 Git LFS 之后，在仓库中存储的其实是对大文件的引用，可以理解为指针。而真正的大文件托管在 Git Lfs 的服务器上。Github 给不同用户的提供的存储空间不一样，免费用户和 Pro 用户都是 2 GB，而如果是企业用户则会高点2 ","date":"2021-12-06","objectID":"/zh-cn/gitlfs/:2:0","tags":["Git"],"title":"Git LFS 使用指南","uri":"/zh-cn/gitlfs/"},{"categories":["Git"],"content":"引用文件长什么样子 比如官方文档里面提到的例子： version https://git-lfs.github.com/spec/v1 oid sha256:4cac19622fc3ada9c0fdeadb33f88f367b541f38b89102a3f1261ac81fd5bcb5 size 84977953 其中 version 是你正在使用的 git-lfs 的版本，oid 是标志符，size 是文件的实际大小 ","date":"2021-12-06","objectID":"/zh-cn/gitlfs/:2:1","tags":["Git"],"title":"Git LFS 使用指南","uri":"/zh-cn/gitlfs/"},{"categories":["Git"],"content":"开始使用 Git LFS ","date":"2021-12-06","objectID":"/zh-cn/gitlfs/:3:0","tags":["Git"],"title":"Git LFS 使用指南","uri":"/zh-cn/gitlfs/"},{"categories":["Git"],"content":"如何安装 Git LFS 如果用的是 Mac，那么用 Homebrew 就可以很方便安装 \u003e $ brew install git-lfs \u003e $ git lfa install # 如果输出为 Git LFS initialized. 就是正常安装好了 ","date":"2021-12-06","objectID":"/zh-cn/gitlfs/:3:1","tags":["Git"],"title":"Git LFS 使用指南","uri":"/zh-cn/gitlfs/"},{"categories":["Git"],"content":"Case 1. 从 0 开始配置使用 Git LFS 我们要指定 Git LFS 会把哪些文件当作大文件，指定方式比如有： 指定文件后缀名——git lfs track \"*.filetype\" 指定某个目录下的所有文件——git lfs track \"directory/*\" 具体指定某个文件——git lfs track \"path/to/file\" \u003e $ mkdir \u003crepo\u003e \u003e $ cd \u003crepo\u003e \u003e $ git init \u003e $ git lfs track \"*.filetype\" # 比如 *.zip # git lfs track 会修改 .gitattributes 文件的内容，可以验证一下 # \u003e cat .gitattributes # *.zip filter=lfs diff=lfs merge=lfs -text # 下面假定在 Github 有一个远程仓库供我们使用 # 往仓库里加你先前指定的文件类型的大文件 \u003e $ git add . \u003e $ git commit -m \"\u003cmsg\u003e\" \u003e $ git branch -M main # 这里替换为自己的用户名和远程仓库名 \u003e $ git remote add origin git@github.com:\u003cusername\u003e/\u003cremote_repo_name\u003e.github \u003e $ git push -u origin main # 此时命令行会显示 # \u003e uploading LFS objects # 如果没有采用 git-lfs，则显示如下内容 # \u003e Enumerating objects: 3, done. # Counting objects: 100% (3/3), done. # Delta compression using up to 8 threads # Compressing objects: 100% (2/2), done. ","date":"2021-12-06","objectID":"/zh-cn/gitlfs/:3:2","tags":["Git"],"title":"Git LFS 使用指南","uri":"/zh-cn/gitlfs/"},{"categories":["Git"],"content":"Case 2. 要在已有的仓库上用 Git LFS 追踪某些文件 此时只是简单的使用 git lfs track ... 是没用的，因为你之前的 commit 已经生成了快照，你无法追踪历史中的这些大文件。Git LFS 只会在你开始设置的此刻之后追踪新生成的指定文件 可以快速做个验证，假设我们还在这个仓库里⬇️ \u003e $ ls \u003e test1.txt \u003e $ ls -l \u003e test2.txt \u003e $ git add test1.txt test2.txt \u003e $ git commit -m \"Add txt files\" # 假设我们现在要把 txt 文件当成是大文件，我们可能会想这么做 \u003e $ git lfs track \"*.txt\" \u003e $ git add .gitattributes \u003e $ git commit -m \"Track *.txt files\" \u003e $ git lfs ls-files # 此时你会发现 git-lfs 并没有追踪 txt 文件 \u003e $ echo \"hello\" \u003e test3.txt \u003e $ git add test3.txt \u003e $ git commit -m \"Add test3.txt\" \u003e $ git lfs ls-files # 而用 LFS 追踪新文件是没问题的 正确的方法是使用 git lfs migrate，这里只列举了简单的用法，更复杂的可以看看手册 \u003e $ man git-lfs-migrate 比如可以用 --include=，Git LFS 会自动根据我们指定的模式进行选择。下面的 --include=\"*.txt 的意思就是选中之前的 txt 文件 \u003e git lfs migrate import --include=\"*.txt\" # 此时可以发现 text1.txt 和 text2.txt 也被追踪到了 \u003e git lfs ls-files # 让远程仓库也改过来 \u003e git push --force ","date":"2021-12-06","objectID":"/zh-cn/gitlfs/:3:3","tags":["Git"],"title":"Git LFS 使用指南","uri":"/zh-cn/gitlfs/"},{"categories":["Git"],"content":"Case 3. 不再跟踪某些文件 \u003e git lfs untrack \"*.filetype\" \u003e git rm --cached \"*.filetype\" ","date":"2021-12-06","objectID":"/zh-cn/gitlfs/:3:4","tags":["Git"],"title":"Git LFS 使用指南","uri":"/zh-cn/gitlfs/"},{"categories":["Git"],"content":"其他常用命令 查看当前 Git LFS 正在追踪的文件类型——git lfs track 查看当前 Git LFS 正在追踪哪些文件——git lfs ls-file ","date":"2021-12-06","objectID":"/zh-cn/gitlfs/:4:0","tags":["Git"],"title":"Git LFS 使用指南","uri":"/zh-cn/gitlfs/"},{"categories":["Git"],"content":"参考 About large files on GitHub ↩︎ About Git Large File Storage ↩︎ ","date":"2021-12-06","objectID":"/zh-cn/gitlfs/:5:0","tags":["Git"],"title":"Git LFS 使用指南","uri":"/zh-cn/gitlfs/"},{"categories":["Machine-Learning"],"content":"简单介绍 Precision 和 Recall 以及 F1 score 的计算方式","date":"2021-12-05","objectID":"/zh-cn/f1score/","tags":["Machine-Learning"],"title":"从混淆矩阵到 F1 score","uri":"/zh-cn/f1score/"},{"categories":["Machine-Learning"],"content":"什么是混淆矩阵 每一列表示实际情况，每一行表示我们的预测，这样组合起来就得到了一个混淆矩阵，比如一个二分类的任务，可以画出如下的混淆矩阵⬇️ Positive Negative True TP = True Positive FP = False Positive False FN = False Negative TN = True Negative ","date":"2021-12-05","objectID":"/zh-cn/f1score/:1:0","tags":["Machine-Learning"],"title":"从混淆矩阵到 F1 score","uri":"/zh-cn/f1score/"},{"categories":["Machine-Learning"],"content":"accuracy 有多少样本我们预测正确了 预测正确的其实有下面两种情形⬇️ TP：本来是 positive，你也认为是 positive 的 TN：本来是 negative，你也认为是 negative 的 那么用 TP + TN（其实就是主对角线）除以总的样本数就可以得到 accuracy， 📒或者直接看表格，其实就是 $\\frac{主对角线}{四个单元格} =\\frac{TP+TN}{TP+TN+FN+FP}$ 一般来说 accuracy 是好用的评估指标，但是在某些情况下不是这样子的，比如样本数据不均衡的时候 类别 A 类别 B 判断是类别 A 0 0 判断是类别 B 1 99 假设类别 A 有 1 个，类别 B 有 99 个，如果不管输入的是什么都返回类别 B 的正确率是多少呢？ 答案是 $\\frac{0+99}{0+0+1+99}=99%$，我们可以说这个分类器效果很好吗，这显然是很荒谬的😂 ","date":"2021-12-05","objectID":"/zh-cn/f1score/:1:1","tags":["Machine-Learning"],"title":"从混淆矩阵到 F1 score","uri":"/zh-cn/f1score/"},{"categories":["Machine-Learning"],"content":"Precision 所有预测为 True 的样本里面，有多少是真的 positive 的 从定义出发可以知道，其实就是表格中判断为 True 的这一行中 positive 的比例，那么就是 $\\frac{TP}{TP+FP}$ ","date":"2021-12-05","objectID":"/zh-cn/f1score/:1:2","tags":["Machine-Learning"],"title":"从混淆矩阵到 F1 score","uri":"/zh-cn/f1score/"},{"categories":["Machine-Learning"],"content":"Recall 所有本来是 positive 的，有多少被我们成功预测了出来 从定义出发，所有本来是 positive 的就是 Positive 这一列之和，我们成功预测的是 TP，那么就是 $\\frac{TP}{TP+FN}$ 📒我们常常要在 Precision 和 Recall 中进行 tradeoff，因为其中一个升高，另一个就会降低 ","date":"2021-12-05","objectID":"/zh-cn/f1score/:1:3","tags":["Machine-Learning"],"title":"从混淆矩阵到 F1 score","uri":"/zh-cn/f1score/"},{"categories":["Machine-Learning"],"content":"F1 score 正是因为 Precision 和 Recall 的互斥特性，在衡量分类器好坏的时候会给我们带来困扰，特别是两者相差不多的情况下，于是就需要将这两个指标合并起来用另一个指标表示，也就是 F1 score F1 score 的计算方式如下： $$F1\\ score = \\frac{2PR}{P+R}$$ 其中 Precision = $P$； Recall = $R$ ","date":"2021-12-05","objectID":"/zh-cn/f1score/:2:0","tags":["Machine-Learning"],"title":"从混淆矩阵到 F1 score","uri":"/zh-cn/f1score/"},{"categories":["Machine-Learning"],"content":"F1 score 的不同计算方法 Macro：分别计算每个类别的 $P$ 和 $R$，再计算总的平均的 $P$ 和 $R$，最后用这个计算 F1 score Micro：合并多个类别的统计结果到一个表格里面，在分别算 $P$ 和 $R$ 和 F1 score 配合后面的例子🌰食用 ","date":"2021-12-05","objectID":"/zh-cn/f1score/:2:1","tags":["Machine-Learning"],"title":"从混淆矩阵到 F1 score","uri":"/zh-cn/f1score/"},{"categories":["Machine-Learning"],"content":"F1 score 的几个规律 F1 score 永远在 precision 和 recall 之间， F1 score 会给低的部分（$P\\ or\\ R$）更多的权重，所以如果算术平均值是一样的情况下，哪个分类器的短板更短，它的 F1 就会越差 情况一：比如 $P$ 和 $R$ 分别是 $60%$ 和 $60%$，可以算他们的 F1 score = $60%$ 情况二：比如 $P$ 和 $R$ 分别是 $50%$ 和 $70%$，可以看到他们和上一种情况的平均值是一样的，但是他们的 F1 score = $58.3%$ 由 1. 可知：📒 高 F1 score 不意味着分类器更好或更适合你的任务，有时候你可能更关注 Precision 或者 Recall 这两个中的一个 ","date":"2021-12-05","objectID":"/zh-cn/f1score/:2:2","tags":["Machine-Learning"],"title":"从混淆矩阵到 F1 score","uri":"/zh-cn/f1score/"},{"categories":["Machine-Learning"],"content":"一个完整的例子🌰 class 0 class 1 class 2 predict_class0 2 0 0 predict_class1 1 0 1 predict_class2 0 2 0 ","date":"2021-12-05","objectID":"/zh-cn/f1score/:3:0","tags":["Machine-Learning"],"title":"从混淆矩阵到 F1 score","uri":"/zh-cn/f1score/"},{"categories":["Machine-Learning"],"content":"Macro 的计算方式 要先得到每一个类别的 Precision 和 Recall，先画出表格⬇️ class 0 Not class 0 predict_class0 2 1 predict_not_class0 0 3 class 1 Not class 1 predict_class1 0 2 predict_not_class1 2 2 class 2 Not class 2 predict_class2 0 1 predict_not_class2 2 3 可以得到如下的结果 class 0：Precision = $\\frac{2}{3}$；Recall = $1$ class 1：Precision = $0$；Recall = $0$ class 2：Precision = $0$；Recall = $0$ 那么平均的 Precision 就是 $\\frac{2}{3} * \\frac{1}{3} = \\frac{2}{9}$；平均的 Recall 是 $\\frac{1}{3}$，代入 F1 score 的计算公式可以得到 $\\frac{4}{15}=0.26666$ ","date":"2021-12-05","objectID":"/zh-cn/f1score/:3:1","tags":["Machine-Learning"],"title":"从混淆矩阵到 F1 score","uri":"/zh-cn/f1score/"},{"categories":["Machine-Learning"],"content":"Micro 的计算方式 将三个表格叠起来（对应位置相加），可以得到如下的表格 class ? Not class ? predict_class? 2 4 predict_not_class? 4 8 代入公式算得 F1 score = $1/3=0.333333$ ","date":"2021-12-05","objectID":"/zh-cn/f1score/:3:2","tags":["Machine-Learning"],"title":"从混淆矩阵到 F1 score","uri":"/zh-cn/f1score/"},{"categories":["Machine-Learning"],"content":"代码验证 from sklearn.metrics import f1_score, confusion_matrix y_true = [0, 1, 2, 0, 1, 2] y_pred = [0, 2, 1, 0, 0, 1] print(confusion_matrix(y_true, y_pred)) # confusion matrix # [[2 0 0] # [1 0 1] # [0 2 0]] print(f1_score(y_true, y_pred, average='macro')) # 0.26666 print(f1_score(y_true, y_pred, average='micro')) # 0.33333 ","date":"2021-12-05","objectID":"/zh-cn/f1score/:4:0","tags":["Machine-Learning"],"title":"从混淆矩阵到 F1 score","uri":"/zh-cn/f1score/"},{"categories":["Machine-Learning"],"content":"参考 sklearn 的 f1_score 介绍 ","date":"2021-12-05","objectID":"/zh-cn/f1score/:5:0","tags":["Machine-Learning"],"title":"从混淆矩阵到 F1 score","uri":"/zh-cn/f1score/"}]