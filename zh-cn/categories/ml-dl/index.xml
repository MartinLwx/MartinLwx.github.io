<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>ML-DL - 分类 - MartinLwx&#39;s blog</title>
        <link>https://martinlwx.github.io/zh-cn/categories/ml-dl/</link>
        <description>ML-DL - 分类 - MartinLwx&#39;s blog</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>martinlwx@163.com (MartinLwx)</managingEditor>
            <webMaster>martinlwx@163.com (MartinLwx)</webMaster><lastBuildDate>Tue, 04 Apr 2023 13:45:48 &#43;0800</lastBuildDate><atom:link href="https://martinlwx.github.io/zh-cn/categories/ml-dl/" rel="self" type="application/rss+xml" /><item>
    <title>反向传播公式推导和理解</title>
    <link>https://martinlwx.github.io/zh-cn/backpropagation-tutorial/</link>
    <pubDate>Tue, 04 Apr 2023 13:45:48 &#43;0800</pubDate>
    <author>MartinLwx</author>
    <guid>https://martinlwx.github.io/zh-cn/backpropagation-tutorial/</guid>
    <description><![CDATA[引言 在深度学习中，模型的优化是通过采用梯度下降法不断更新权重和偏置项，让损失越来越小。其中的核心就是反向传播算法。回忆梯度下降的公式，用 $\theta$ 表]]></description>
</item>
<item>
    <title>线性回归模型指南 - 理论部分</title>
    <link>https://martinlwx.github.io/zh-cn/linear-regression-model-guide-theory/</link>
    <pubDate>Wed, 15 Mar 2023 12:27:40 &#43;0800</pubDate>
    <author>MartinLwx</author>
    <guid>https://martinlwx.github.io/zh-cn/linear-regression-model-guide-theory/</guid>
    <description><![CDATA[引言 最近，重新刷起了吴恩达的机器学习课程，系统性复习了之前学过的知识，发现又有不少收获，打算仔细整理一番👍 要谈论什么是线性回归首先要对什么是]]></description>
</item>
</channel>
</rss>
