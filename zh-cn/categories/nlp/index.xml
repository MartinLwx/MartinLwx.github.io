<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>NLP - 分类 - MartinLwx&#39;s blog</title>
        <link>https://martinlwx.github.io/zh-cn/categories/nlp/</link>
        <description>NLP - 分类 - MartinLwx&#39;s blog</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>martinlwx@163.com (MartinLwx)</managingEditor>
            <webMaster>martinlwx@163.com (MartinLwx)</webMaster><lastBuildDate>Thu, 24 Aug 2023 22:06:37 &#43;0800</lastBuildDate><atom:link href="https://martinlwx.github.io/zh-cn/categories/nlp/" rel="self" type="application/rss+xml" /><item>
    <title>BPE 分词解密 - 实现方法与示例讲解</title>
    <link>https://martinlwx.github.io/zh-cn/the-bpe-tokenizer/</link>
    <pubDate>Thu, 24 Aug 2023 22:06:37 &#43;0800</pubDate>
    <author>MartinLwx</author>
    <guid>https://martinlwx.github.io/zh-cn/the-bpe-tokenizer/</guid>
    <description><![CDATA[BPE 简介 在 NLP 里面，一个核心的问题是，如何对文本进行分词？从分类的角度上面来说，可以分为： Char level Word level Subword level 先看 Char level 分词，顾名思义，就是把文本拆分成一]]></description>
</item>
<item>
    <title>TF-IDF 模型</title>
    <link>https://martinlwx.github.io/zh-cn/an-introduction-of-tf-idf-model/</link>
    <pubDate>Wed, 16 Aug 2023 22:23:26 &#43;0800</pubDate>
    <author>MartinLwx</author>
    <guid>https://martinlwx.github.io/zh-cn/an-introduction-of-tf-idf-model/</guid>
    <description><![CDATA[什么是 TF-IDF 模型 在之前的文章中谈到了词袋模型，也讲到了它的许多不足，在今天的这篇文章中，我们要尝试解决词袋模型的缺点之一：每个词的重要性是一样的]]></description>
</item>
<item>
    <title>词袋模型</title>
    <link>https://martinlwx.github.io/zh-cn/an-introduction-of-bag-of-word-model/</link>
    <pubDate>Fri, 11 Aug 2023 18:55:09 &#43;0800</pubDate>
    <author>MartinLwx</author>
    <guid>https://martinlwx.github.io/zh-cn/an-introduction-of-bag-of-word-model/</guid>
    <description><![CDATA[什么是词袋模型 在 NLP 中，我们需要将文档（document）表示为向量，这是因为机器学习只能够处理数字。也就是说，我们要找到下面这么一个神奇的函]]></description>
</item>
</channel>
</rss>
