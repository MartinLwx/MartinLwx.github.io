<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>All Posts - MartinLwx&#39;s Blog</title>
        <link>https://martinlwx.github.io/en/posts/</link>
        <description>All Posts | MartinLwx&#39;s Blog</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>martinlwx@163.com (MartinLwx)</managingEditor>
            <webMaster>martinlwx@163.com (MartinLwx)</webMaster><copyright>&lt;a rel=&#34;license noopener&#34; href=&#34;https://creativecommons.org/licenses/by-nc-nd/4.0/&#34; target=&#34;_blank&#34;&gt;CC BY-NC-ND 4.0&lt;/a&gt;</copyright><lastBuildDate>Thu, 12 Oct 2023 18:29:31 &#43;0800</lastBuildDate><atom:link href="https://martinlwx.github.io/en/posts/" rel="self" type="application/rss+xml" /><item>
    <title>Lab09 - CS61A of UCB(2021-Fall)</title>
    <link>https://martinlwx.github.io/en/lab09-cs61a-of-ucb/</link>
    <pubDate>Sat, 26 Feb 2022 13:09:24 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/lab09-cs61a-of-ucb/</guid>
    <description><![CDATA[Recursion and Tree Recursion Q1: Subsequences A subsequence of a sequence S is a subset of elements from S, in the same order they appear in S. Consider the list [1, 2, 3]. Here are a few of it&rsquo;s subsequences [], [1, 3], [2], and [1, 2, 3].
Write a function that takes in a list and returns all possible subsequences of that list. The subsequences should be returned as a list of lists, where each nested list is a subsequence of the original input.]]></description>
</item><item>
    <title>A trick to calculating partial derivatives in machine learning</title>
    <link>https://martinlwx.github.io/en/a-trick-to-calculating-partial-derivatives-in-ml/</link>
    <pubDate>Wed, 26 Jul 2023 00:31:50 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/a-trick-to-calculating-partial-derivatives-in-ml/</guid>
    <description><![CDATA[IntroYou may have difficulties when trying to calculate the partial derivatives in machine learning like me. Even though I found a good reference cookbook that could be used to derive the gradients, I still got confused. Today, I want to share a practical technique I recently learned from this video: when calculating partial derivatives in machine learning, you can treat everything as if it were a scalar and then make the shapes match]]></description>
</item></channel>
</rss>
