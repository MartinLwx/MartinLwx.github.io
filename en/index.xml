<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>MartinLwx&#39;s Blog</title>
        <link>https://martinlwx.github.io/en/</link>
        <description>Welcome to my blog :)</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>martinlwx@163.com (MartinLwx)</managingEditor>
            <webMaster>martinlwx@163.com (MartinLwx)</webMaster><copyright>&lt;a rel=&#34;license noopener&#34; href=&#34;https://creativecommons.org/licenses/by-nc-nd/4.0/&#34; target=&#34;_blank&#34;&gt;CC BY-NC-ND 4.0&lt;/a&gt;</copyright><lastBuildDate>Sat, 07 Sep 2024 11:29:44 &#43;0800</lastBuildDate>
            <atom:link href="https://martinlwx.github.io/en/index.xml" rel="self" type="application/rss+xml" />
        <item>
    <title>Tree-sitter and its Query</title>
    <link>https://martinlwx.github.io/en/tree-sitter-and-its-query/</link>
    <pubDate>Sat, 07 Sep 2024 11:29:44 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/tree-sitter-and-its-query/</guid>
    <description><![CDATA[<h2 id="intro" class="headerLink">
    <a href="#intro" class="header-mark" aria-label="Header mark for 'Intro'"></a>Intro</h2><p>Tree-sitter is a parser generator, that is, we can leverage it to generate a specific parser. In addition to that, it also offers other functionality. For example, we can write a Query using S-expression, which will do the pattern matching on the AST. Before we delve into this feature, let&rsquo;s talk about some backgrounds</p>
<h2 id="s-expression" class="headerLink">
    <a href="#s-expression" class="header-mark" aria-label="Header mark for 'S-expression'"></a>S-expression</h2><div class="details admonition info open">
    <div class="details-summary admonition-title">
        <span class="icon"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z"/></svg></span>Info<span class="details-icon"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></span>
    </div>
    <div class="details-content">
        <div class="admonition-content">If you once wrote Lisp (or its dialects, such as Scheme and Racket), you should be familiar with the S-expression</div></div></div>
<p>We can define a S-expression <em>recursively</em>, the definition is</p>]]></description>
</item><item>
    <title>Learn to Use @dataclass in Python</title>
    <link>https://martinlwx.github.io/en/learn-to-use-dataclass-in-python/</link>
    <pubDate>Sat, 17 Aug 2024 14:22:14 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/learn-to-use-dataclass-in-python/</guid>
    <description><![CDATA[<h2 id="intro" class="headerLink">
    <a href="#intro" class="header-mark" aria-label="Header mark for 'Intro'"></a>Intro</h2><p>I like Python&rsquo;s tuple, which allows us to quickly <em>bundle</em> together values of <em>different types</em> as a single entity and manage them in an intuitive and easy-to-use way. However, I find that once the tuple has <em>many fields</em>, I&rsquo;m <em>forced to</em> add a comment to indicate the meaning of each field. For example,</p>
<div class="code-block highlight is-open show-line-numbers  tw-group tw-my-2">
  <div class="
    code-block-title 
    
    tw-flex 
    tw-flex-row 
    tw-justify-between 
    tw-w-full tw-bg-bgColor-secondary
    ">      
    <button 
      class="
        tw-select-none 
        tw-mx-2 
        tw-block
        group-[.is-open]:tw-rotate-90
        tw-transition-[transform] 
        tw-duration-500 
        tw-ease-in-out
        print:!tw-hidden"
      disabled
      aria-hidden="true"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M285.476 272.971L91.132 467.314c-9.373 9.373-24.569 9.373-33.941 0l-22.667-22.667c-9.357-9.357-9.375-24.522-.04-33.901L188.505 256 34.484 101.255c-9.335-9.379-9.317-24.544.04-33.901l22.667-22.667c9.373-9.373 24.569-9.373 33.941 0L285.475 239.03c9.373 9.372 9.373 24.568.001 33.941z"/></svg></button>

    <div class="code-block-title-bar tw-w-full">
      <p class="tw-select-none !tw-my-1">python</p>]]></description>
</item><item>
    <title>Use Github Actions to automate Hugo blog deployment</title>
    <link>https://martinlwx.github.io/en/use-github-actions-to-automate-hugo-build/</link>
    <pubDate>Mon, 29 Jul 2024 23:35:53 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/use-github-actions-to-automate-hugo-build/</guid>
    <description><![CDATA[<h2 id="intro" class="headerLink">
    <a href="#intro" class="header-mark" aria-label="Header mark for 'Intro'"></a>Intro</h2><p>Recently I started learning the GitHub Actions, a feature provided by GitHub that can be used to <em>automate</em> a series of steps. In the process of software development, the most common use of this feature <em>may</em> be the building process. For static-typed programming languages such as C/C++, we are usually required to write the build scripts. The build process involves environment preparation, dependencies download, and build execution. However, <em>automating</em> software builds with GitHub Actions is not the focus of this post. As I was learning this feature, I thought about how I could put it into practice and realized I could use it to <em>automate</em> the build and deployment of my Hugo blog :)</p>]]></description>
</item><item>
    <title>Tail call and Tail-call Optimization (TCO)</title>
    <link>https://martinlwx.github.io/en/tail-call-and-tail-call-optimization/</link>
    <pubDate>Fri, 22 Mar 2024 12:13:53 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/tail-call-and-tail-call-optimization/</guid>
    <description><![CDATA[<h2 id="tail-call--tail-recursion" class="headerLink">
    <a href="#tail-call--tail-recursion" class="header-mark" aria-label="Header mark for 'Tail call &amp; Tail-recursion'"></a>Tail call &amp; Tail-recursion</h2><p>Assume that function <code>A</code> calls function <code>B</code>. We call function <code>A</code> <em>Caller</em> and function <code>B</code> <em>Callee</em>.</p>
<p>The tail call refers to when the Caller <em>only needs to</em> wait for the return value of the Callee, as <em>everything else</em> has already been completed<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<p>If this is a recursive function call(e.g. the Caller and Callee are the same function), then the function is said to be tail-recursive.</p>]]></description>
</item><item>
    <title>Learn to use text-object in Vim&amp;Neovim</title>
    <link>https://martinlwx.github.io/en/learn-to-use-text-objects-in-vim/</link>
    <pubDate>Sun, 03 Mar 2024 19:46:48 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/learn-to-use-text-objects-in-vim/</guid>
    <description><![CDATA[<h2 id="intro" class="headerLink">
    <a href="#intro" class="header-mark" aria-label="Header mark for 'Intro'"></a>Intro</h2><p>You probably do not know what the text-object is in Vim/Neovim. However, you <em>may</em> use it in your daily life. For instance, When you are writing code, you may want to change the arguments of a function. Take the following code as an example, let&rsquo;s say you want to change the function call to <code>bar(3, 2, 1)</code>, and the cursor currently stays on the <code>,</code></p>
<div class="code-block highlight is-open show-line-numbers  tw-group tw-my-2">
  <div class="
    code-block-title 
    
    tw-flex 
    tw-flex-row 
    tw-justify-between 
    tw-w-full tw-bg-bgColor-secondary
    ">      
    <button 
      class="
        tw-select-none 
        tw-mx-2 
        tw-block
        group-[.is-open]:tw-rotate-90
        tw-transition-[transform] 
        tw-duration-500 
        tw-ease-in-out
        print:!tw-hidden"
      disabled
      aria-hidden="true"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M285.476 272.971L91.132 467.314c-9.373 9.373-24.569 9.373-33.941 0l-22.667-22.667c-9.357-9.357-9.375-24.522-.04-33.901L188.505 256 34.484 101.255c-9.335-9.379-9.317-24.544.04-33.901l22.667-22.667c9.373-9.373 24.569-9.373 33.941 0L285.475 239.03c9.373 9.372 9.373 24.568.001 33.941z"/></svg></button>

    <div class="code-block-title-bar tw-w-full">
      <p class="tw-select-none !tw-my-1">python</p>]]></description>
</item><item>
    <title>Neovim Setup for OCaml</title>
    <link>https://martinlwx.github.io/en/neovim-setup-for-ocaml/</link>
    <pubDate>Tue, 23 Jan 2024 12:55:46 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/neovim-setup-for-ocaml/</guid>
    <description><![CDATA[<div class="details admonition info open">
    <div class="details-summary admonition-title">
        <span class="icon"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z"/></svg></span>Info<span class="details-icon"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></span>
    </div>
    <div class="details-content">
        <div class="admonition-content"><p><strong>Updates</strong>:</p>]]></description>
</item><item>
    <title>LLM inference optimization - KV Cache</title>
    <link>https://martinlwx.github.io/en/llm-inference-optimization-kv-cache/</link>
    <pubDate>Thu, 12 Oct 2023 18:29:31 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/llm-inference-optimization-kv-cache/</guid>
    <description><![CDATA[<h2 id="background" class="headerLink">
    <a href="#background" class="header-mark" aria-label="Header mark for 'Background'"></a>Background</h2><p>The secret behind LLM is that it will generate tokens one by one based on all the previous tokens.</p>
<p><em>Let&rsquo;s assume that we have already generated $t$ tokens, denoted by $x_{1:t}$. In the next iteration, the LLM will generate $x_{1:t+1}$. Note that the first $t$ tokens are the same</em>.</p>
<p>$$x_{1:t+1}=\text{LLM}(x_{1:t})$$</p>
<p><em>The next iteration is similar.</em></p>
<p>$$x_{1:t+2}=\text{LLM}(x_{1:t+1})$$</p>
<p>In summary, in each iteration, we will <strong>use the output of the previous round</strong> as a new input for the LLM. Generally, this process will continue until the output reaches the maximum length we predefined or the LLM itself generates a special token, signifying the completion of the generating process.</p>]]></description>
</item><item>
    <title>LoRA fine-tuning</title>
    <link>https://martinlwx.github.io/en/lora-finetuning/</link>
    <pubDate>Thu, 14 Sep 2023 22:57:06 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/lora-finetuning/</guid>
    <description><![CDATA[<h2 id="whats-lora" class="headerLink">
    <a href="#whats-lora" class="header-mark" aria-label="Header mark for 'What&rsquo;s LoRA'"></a>What&rsquo;s LoRA</h2><figure><img src="/img/lora.jpg">
</figure>

<p>Since the era of LLM(large language model) arrived, fine-tuning LLM has become a challenge because the LLM models are extremely large, making it difficult to perform full fine-tuning. There are mainly two approaches: freeze the entire LLM and perform prompt tuning or In-context Learning; freeze the entire LLM <em>but</em> inserting trainable modules. Today, I will introduce the LoRA(<strong>Lo</strong>w-<strong>R</strong>ank <strong>A</strong>daptation), which corresponds to the latter technical approach. This is a work proposed by the Microsoft team<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>]]></description>
</item><item>
    <title>The next lexicographical permutation problem</title>
    <link>https://martinlwx.github.io/en/the-next-lexicographical-permutation-problem/</link>
    <pubDate>Wed, 06 Sep 2023 23:13:52 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/the-next-lexicographical-permutation-problem/</guid>
    <description><![CDATA[<h2 id="intro" class="headerLink">
    <a href="#intro" class="header-mark" aria-label="Header mark for 'Intro'"></a>Intro</h2><p>Occasionally, you may want to <strong>get the next/prev lexicographical permutation of a sequence</strong>. How would you do that? If you are a C++ programmer, you are probably familiar with the <code>next_permutation</code><sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> and <code>prev_permutation</code><sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> APIs. However, Python does not provide the counterparts. So the topic today is how to do this in Python. Since the solutions of prev lexicographical permutation and the next lexicographical permutation are very similar, let us focus on the next lexicographical permutation problem.</p>]]></description>
</item><item>
    <title>BPE Tokenization Demystified: Implementation and Examples</title>
    <link>https://martinlwx.github.io/en/the-bpe-tokenizer/</link>
    <pubDate>Thu, 24 Aug 2023 22:06:37 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/the-bpe-tokenizer/</guid>
    <description><![CDATA[<h2 id="a-taxonomy-of-tokenization-methods" class="headerLink">
    <a href="#a-taxonomy-of-tokenization-methods" class="header-mark" aria-label="Header mark for 'A taxonomy of tokenization methods'"></a>A taxonomy of tokenization methods</h2><p>In NLP, one crux of problems is - how to tokenize the text. There are three methods available:</p>
<ul>
<li>Char-level</li>
<li>Word-level</li>
<li>Subword-level</li>
</ul>
<p>Let&rsquo;s talk about the Char-level tokenizer. That is, we tokenize the text into a char stream. <em>For instance, <code>highest -&gt; h, i, g, h, e, s, t</code></em>. One advantage of the Char-level tokenizer is that the size of Vocab won&rsquo;t be that large. The size of Vocab is equal to the size of the alphabet. So you probably won&rsquo;t meet the infamous Out-of-vocabulary(OOV) problem. However, the downside is that <strong>the char itself does not convey too much information</strong>, and <strong>we will get too many tokens after tokenizing</strong>. <em>Try to imagine that a simple word highest will give us 7 tokens</em>😨</p>]]></description>
</item></channel>
</rss>
