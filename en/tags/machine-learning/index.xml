<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Machine-Learning - Tag - MartinLwx&#39;s Blog</title>
        <link>https://martinlwx.github.io/en/tags/machine-learning/</link>
        <description>Machine-Learning - Tag - MartinLwx&#39;s Blog</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>martinlwx@163.com (MartinLwx)</managingEditor>
            <webMaster>martinlwx@163.com (MartinLwx)</webMaster><copyright>&lt;a rel=&#34;license noopener&#34; href=&#34;https://creativecommons.org/licenses/by-nc-nd/4.0/&#34; target=&#34;_blank&#34;&gt;CC BY-NC-ND 4.0&lt;/a&gt;</copyright><lastBuildDate>Wed, 16 Aug 2023 22:23:26 &#43;0800</lastBuildDate><atom:link href="https://martinlwx.github.io/en/tags/machine-learning/" rel="self" type="application/rss+xml" /><item>
    <title>TF-IDF model</title>
    <link>https://martinlwx.github.io/en/an-introduction-of-tf-idf-model/</link>
    <pubDate>Wed, 16 Aug 2023 22:23:26 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/an-introduction-of-tf-idf-model/</guid>
    <description><![CDATA[<h2 id="what-is-the-tf-idf-model" class="headerLink">
    <a href="#what-is-the-tf-idf-model" class="header-mark" aria-label="Header mark for 'What is the TF-IDF model'"></a>What is the TF-IDF model</h2><p>In previous <a href="https://martinlwx.github.io/en/an-introduction-of-bag-of-word-model/" rel="">post</a>, we talked about the bag-of-word model, which has many limitations. Today we take a step further to see if we can try to fix <strong>one of the limitations - Each word has the same importance</strong>.</p>
<blockquote>
<p>üí° The crux of the problem - <strong>How to define the word importance</strong>?</p>]]></description>
</item><item>
    <title>Bag-of-Word model</title>
    <link>https://martinlwx.github.io/en/an-introduction-of-bag-of-word-model/</link>
    <pubDate>Fri, 11 Aug 2023 18:55:09 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/an-introduction-of-bag-of-word-model/</guid>
    <description><![CDATA[<h2 id="what-is-the-bag-of-word-model" class="headerLink">
    <a href="#what-is-the-bag-of-word-model" class="header-mark" aria-label="Header mark for 'What is the bag-of-word model?'"></a>What is the bag-of-word model?</h2><p>In NLP, we need to represent each document as a vector because machine learning can only accept input as numbers. That is, we want to find a <em>magic</em> function that:
$$
f(\text{document}) = vector
$$</p>
<p>Today&rsquo;s topic is <strong>bag-of-word(BoW) model</strong>, which can transform a document into a vector representation.</p>]]></description>
</item><item>
    <title>A trick to calculating partial derivatives in machine learning</title>
    <link>https://martinlwx.github.io/en/a-trick-to-calculating-partial-derivatives-in-ml/</link>
    <pubDate>Wed, 26 Jul 2023 00:31:50 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/a-trick-to-calculating-partial-derivatives-in-ml/</guid>
    <description><![CDATA[<h2 id="intro" class="headerLink">
    <a href="#intro" class="header-mark" aria-label="Header mark for 'Intro'"></a>Intro</h2><p>You may have difficulties when trying to calculate the partial derivatives in machine learning like me. Even though I found a good reference <a href="https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf" target="_blank" rel="noopener noreferrer">cookbook</a> that could be used to derive the gradients, I still got confused. Today, I want to share a practical technique I recently learned from this <a href="https://youtu.be/JLg1HkzDsKI" target="_blank" rel="noopener noreferrer">video</a>: <strong>when calculating partial derivatives in machine learning, you can treat everything <strong>as if</strong> it were a scalar and then make the shapes match</strong></p>]]></description>
</item><item>
    <title>Linear Regression Model Guide - theory part</title>
    <link>https://martinlwx.github.io/en/linear-regression-model-guide-theory/</link>
    <pubDate>Wed, 15 Mar 2023 12:37:52 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/linear-regression-model-guide-theory/</guid>
    <description><![CDATA[<h2 id="introduction" class="headerLink">
    <a href="#introduction" class="header-mark" aria-label="Header mark for 'Introduction'"></a>Introduction</h2><p>Recently, I review the machine learning course of Andrew ng in Coursera. Surprisingly, I can still learn a lot, so I decided to write some postsüëç.</p>
<p>To talk about linear regression, we must first have a basic understanding of what is machine learning. What is machine learning? abstractly speaking, <strong>machine learning is learning a function</strong>:
$$
f(input) = output
$$
where $f$ refers to the specific machine learning model. <strong>Machine learning is a methodology for automatically mining the relationship between input and output</strong>. Sometimes we find it hard to define a specific algorithm to solve some problems, and this is where machine learning shines, we can let it learn and summarize some patterns from data and make predictions. This is also where it differs from traditional algorithms (binary search, recursive, etc.). One has to admit that machine learning is fascinating by definition, and it <em>seems</em> to provide a viable framework for solving all intractable problems. It just so happens that many real-life problems are so hard that solving them with traditional algorithms is impossible.</p>]]></description>
</item></channel>
</rss>
