<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Deep-Learning - Tag - MartinLwx&#39;s Blog</title>
        <link>https://martinlwx.github.io/en/tags/deep-learning/</link>
        <description>Deep-Learning - Tag - MartinLwx&#39;s Blog</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>martinlwx@163.com (MartinLwx)</managingEditor>
            <webMaster>martinlwx@163.com (MartinLwx)</webMaster><copyright>&lt;a rel=&#34;license noopener&#34; href=&#34;https://creativecommons.org/licenses/by-nc-nd/4.0/&#34; target=&#34;_blank&#34;&gt;CC BY-NC-ND 4.0&lt;/a&gt;</copyright><lastBuildDate>Thu, 12 Oct 2023 18:29:31 &#43;0800</lastBuildDate><atom:link href="https://martinlwx.github.io/en/tags/deep-learning/" rel="self" type="application/rss+xml" /><item>
    <title>LLM inference optimization - KV Cache</title>
    <link>https://martinlwx.github.io/en/llm-inference-optimization-kv-cache/</link>
    <pubDate>Thu, 12 Oct 2023 18:29:31 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/llm-inference-optimization-kv-cache/</guid>
    <description><![CDATA[<h2 id="background" class="headerLink">
    <a href="#background" class="header-mark" aria-label="Header mark for 'Background'"></a>Background</h2><p>The secret behind LLM is that it will generate tokens one by one based on all the previous tokens.</p>
<p><em>Let&rsquo;s assume that we have already generated $t$ tokens, denoted by $x_{1:t}$. In the next iteration, the LLM will generate $x_{1:t+1}$. Note that the first $t$ tokens are the same</em>.</p>
<p>$$x_{1:t+1}=\text{LLM}(x_{1:t})$$</p>
<p><em>The next iteration is similar.</em></p>]]></description>
</item><item>
    <title>LoRA fine-tuning</title>
    <link>https://martinlwx.github.io/en/lora-finetuning/</link>
    <pubDate>Thu, 14 Sep 2023 22:57:06 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/lora-finetuning/</guid>
    <description><![CDATA[<h2 id="whats-lora" class="headerLink">
    <a href="#whats-lora" class="header-mark" aria-label="Header mark for 'What&rsquo;s LoRA'"></a>What&rsquo;s LoRA</h2><figure><img src="/img/lora.jpg">
</figure>

<p>Since the era of LLM(large language model) arrived, fine-tuning LLM has become a challenge because the LLM models are extremely large, making it difficult to perform full fine-tuning. There are mainly two approaches: freeze the entire LLM and perform prompt tuning or In-context Learning; freeze the entire LLM <em>but</em> inserting trainable modules. Today, I will introduce the LoRA(<strong>Lo</strong>w-<strong>R</strong>ank <strong>A</strong>daptation), which corresponds to the latter technical approach. This is a work proposed by the Microsoft team<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>]]></description>
</item><item>
    <title>A trick to calculating partial derivatives in machine learning</title>
    <link>https://martinlwx.github.io/en/a-trick-to-calculating-partial-derivatives-in-ml/</link>
    <pubDate>Wed, 26 Jul 2023 00:31:50 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/a-trick-to-calculating-partial-derivatives-in-ml/</guid>
    <description><![CDATA[<h2 id="intro" class="headerLink">
    <a href="#intro" class="header-mark" aria-label="Header mark for 'Intro'"></a>Intro</h2><p>You may have difficulties when trying to calculate the partial derivatives in machine learning like me. Even though I found a good reference <a href="https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf" target="_blank" rel="noopener noreferrer">cookbook</a> that could be used to derive the gradients, I still got confused. Today, I want to share a practical technique I recently learned from this <a href="https://youtu.be/JLg1HkzDsKI" target="_blank" rel="noopener noreferrer">video</a>: <strong>when calculating partial derivatives in machine learning, you can treat everything <strong>as if</strong> it were a scalar and then make the shapes match</strong></p>]]></description>
</item><item>
    <title>Demystifying Pytorch&#39;s Strides Format</title>
    <link>https://martinlwx.github.io/en/how-to-reprensent-a-tensor-or-ndarray/</link>
    <pubDate>Fri, 14 Jul 2023 15:22:02 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/how-to-reprensent-a-tensor-or-ndarray/</guid>
    <description><![CDATA[<h2 id="intro" class="headerLink">
    <a href="#intro" class="header-mark" aria-label="Header mark for 'Intro'"></a>Intro</h2><p>Even though I have been using Numpy and Pytorch for a long time, I never really knew how they implemented the underlying tensors and why they are <strong>so efficient</strong>. Recently, while studying the course <a href="https://dlsyscourse.org/" target="_blank" rel="noopener noreferrer">Deep Learning Systems</a>, I finally got the opportunity to try implementing tensors on my own. After going through the process, my understanding of tensors is much better üßê</p>]]></description>
</item><item>
    <title>Understanding GAT throught MPNN</title>
    <link>https://martinlwx.github.io/en/understanding-graph-attention-network-through-mpnn/</link>
    <pubDate>Sun, 21 May 2023 15:20:50 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/understanding-graph-attention-network-through-mpnn/</guid>
    <description><![CDATA[<h2 id="whats-mpnn" class="headerLink">
    <a href="#whats-mpnn" class="header-mark" aria-label="Header mark for 'What&rsquo;s MPNN'"></a>What&rsquo;s MPNN</h2><p>Justin Gilmer proposed the MPNN (Message Passing Neural Network) framework <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> for describing graph neural network models used in supervised learning on graphs. I found this to be a useful framework that provides a clear understanding of how different GNN models work and facilitates a quick grasp of the differences between them. Considering a node $v$ on the graph $G$, the update procedure for its vector representation $h_v$ is as follows:</p>]]></description>
</item><item>
    <title>How to understand the backpropagation algorithm</title>
    <link>https://martinlwx.github.io/en/backpropagation-tutorial/</link>
    <pubDate>Tue, 04 Apr 2023 13:45:48 &#43;0800</pubDate><author>
        <name>MartinLwx</name>
    </author><guid>https://martinlwx.github.io/en/backpropagation-tutorial/</guid>
    <description><![CDATA[<blockquote>
<p>Update: Backpropagation in matrix form could be found <a href="https://martinlwx.github.io/en/a-trick-to-calculating-partial-derivatives-in-ml/" rel="">here</a></p>
</blockquote>
<h2 id="intro" class="headerLink">
    <a href="#intro" class="header-mark" aria-label="Header mark for 'Intro'"></a>Intro</h2><p>In the field of deep learning, optimizing the network involves a crucial process of continuously updating the weights and bias items. This is achieved by implementing the gradient descent method, which progressively minimizes the loss function. At the heart of this process lies the backpropagation algorithm, which facilitates efficient computation of gradients across the network</p>]]></description>
</item></channel>
</rss>
